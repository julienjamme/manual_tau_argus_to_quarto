## Sensitive cells in magnitude tables^[^5]^

The well-known **dominance rule** is often used to find the sensitive cells in tables, i.e. the cells that cannot be published as they might reveal information on individual respondents. More particularly, this rule states that a cell of a table is unsafe for publication if a few ($n$) major (largest) contributors to a cell are responsible for acertain percentage ($k$) of the total of that cell. The idea behind this rule is that in that case at least the major contributors themselves can determine with sufficient precision the contributions of the other contributors to that cell. The choice $n=3$ and $k=70$% is not uncommon, but $\tau$-Argus will allow the users to specify their own values of $n$ and $k$.  

As an alternative the **prior-posterior rule** has been proposed. The basic idea is that a contributor to a cell has a better chance to estimate competitors in a cell than an outsider, and also that these kind of intrusions can occur rather often. The precision with which a competitor can estimate is a measure of the sensitivity of a cell. The worst case is that the second largest contributor will be able to estimate the largest contributor. If this precision is more than $p$%, the cell is considered unsafe. An extension is that also the global knowledge about each cell is taken into account. In that case we assume that each intruder has a basic knowledge of the value of each contributor of $q$%. Note, that it is actually the ratio $p/q$ that determines which cells are considered safe, or unsafe. In this version of $\tau$-Argus, the $q$‑parameter is fixed to $100$. Literature refers to this rule as **(minimum protection of) $p$%‑rule**. If the intention is to state a prior-posterior rule with parameters $p_0$ and $q_0$, where $q_0 < 100$, choose the parameter $p$ of the $p$%‑rule as $p = p_0/q_0 \times 100$. See Loeve (2001)^[^6]^  

With these rules as a starting point it is easy to identify the sensitive cells, provided that the tabulation package has the facility not only to calculate the cell totals, but also to calculate the number of contributors and the $n$ individual contributions of the major contributors. Tabulation packages like ABACUS (from Statistics Netherlands) and the package 'SuperCross' developed in Australia by Space-Time Research have that capacity. In fact $\tau$-Argus not only stores the sum of the $n$ major contributions for each cell, but the individual major contributions themselves. The reason for this is that this is very handy in case rows and columns etc. in a table are combined. By merging and sorting the sets of individual contributions of the cells to be combined, one can quickly determine the major contributions of the new cell, without going back to the original file. This implies that one can quickly apply the dominance rule or the $p$%-rule to the combined cells. Combining rows and columns (table redesign) is one of the major tools for reducing the number of unsafe cells.  

This too is the reason why $\tau$-Argus can read microdata files and build the tables itself. However due to continuous demands from users we have now also provide the option to read ready-made tables, but with the restriction that the options for table redesign will not be available in that case.  

A problem, however, arises when also the marginals of the table are published. It is no longer enough to just suppress the sensitive cells, as they can be easily recalculated using the marginals. Even if it is not possible to exactly recalculate the suppressed cell, it is possible to calculate an interval that contains the suppressed cell. This is possible if some constraints are known to hold for the cell values in a table. A commonly found constraint is that the cell values are all nonnegative.

If the size of such an interval is rather small, then the suppressed cell can be estimated rather precisely. This is not acceptable either. Therefore it is necessary to suppress additional information to achieve sufficiently large intervals.  

Several solutions are available to protect the information of the sensitive cells:

-   Combining categories of the spanning variables (table redesign). Larger cells tend to protect the information about the individual contributors better.

-   Suppression of additional (secondary) cells to prevent the recalculation of the sensitive (primary) cells.  

The calculation of the optimal set (with respect to the loss of information) of secondary cells is a complex OR-problem. $\tau$-Argus has been built around this solution, and takes care of the whole process. A typical $\tau$-Argus session will be one in which the users will first be presented with the table containing only the primary unsafe cells. The user can then choose how to protect these cells. This can involve the combining of categories, equivalent to the global recoding of $\mu$-Argus. The result will be an update of the table with fewer unsafe cells(certainly not more) if the recoding has worked. At a certain stagethe user requests the system to solve the remaining unsafe cells by finding secondary cells to protect the primary cells.

At this stage the user can choose between several options to protect the primary sensitive cells. Either they choose the hypercube method or the optimal solution. In this case they also has to select the solver to be used, Xpress or cplex or the free solver soplex. After this, the table can be stored for further processing if necessary, and eventual publication.

