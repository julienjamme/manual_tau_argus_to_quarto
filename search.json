[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manual of Tau-Argus",
    "section": "",
    "text": "1 \\(\\tau\\)-ARGUS User’s Manual\nVersion 4.1 (revised)\n\n\n\n\n\n\nProject: Argus Open Source-project\n\n\nStatistics Netherlands, P.O. Box 24500\n\n\n\n\nDate: January 2020\n\n\n2490 HA The Hague, The Netherlands\n\n\n\n\n\nemail: argu s@cbs.nl\n\n\n\n\n\n\n\n\n\n\n\n\nContributors:\n\n\nPeter-Paul de Wolf (Modular), Anco Hundepool, Sarah Giessing (ghmiter, audit), Juan-José Salazar (Optimisation methods), Jordi Castro (Network solutions, CTA)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>$\\tau$-ARGUS User's Manual</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html",
    "href": "01_Introduction.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 Preface\nThis is the user's manual for \\(\\tau\\)-Argus version 4.1. \\(\\tau\\)-Argus is a software tool designed to assist a data protector in producing safe tables. This manual describes the first Open Source version of \\(\\tau\\)-Argus. After a long history of development at Statistics Netherlands(CBS) as closed software, CBS has decided to convert \\(\\tau\\)-Argus towards Open Source. This process coincides with the formal retirement of the main developer, Anco Hundepool. With the financial support of Eurostat we have been able to do this transformation and we hope that thefuture of \\(\\tau\\)-Argus is secured. The main aim of this transition project was to port the current (version 3.5) of \\(\\tau\\)-Argus to an open environment. So this version 4.1 does not contain many new extensions.The whole user-interface has been rewritten in java, replacing the old Visual Basic version. The aim of this transition is to be in an open environment and also be platform independent. So also a unix versionis possible now.\nNevertheless with respect to the previous release of \\(\\tau\\)-Argus we have made a few steps forward, and \\(\\tau\\)-Argus now has facilities to protect tables via Controlled Tabular Adjustment (CTA). These routines for this have been developed by Jordi Castro of the Polytechnic Universityof Catalonia.\nWe have also added the option to use a free open solver (soplex) in addition to the classical commercial solvers like cplex and Xpress. However we expect that these commercial solvers are still very much needed, when we want to protect large serious tables. The purpose of \\(\\tau\\)-Argus is to protect tables against the risk of disclosure, i.e. the accidental or deliberate disclosure of information related to individuals from a statistical table. This is achieved by modifying the table so that it contains less detailed information. \\(\\tau\\)-Argus allows for several modifications of a table: a table can be redesigned, meaning that rows and columns can be combined; sensitive cells can be suppressed and additional cells to protect these can be found in some optimum way (secondary cell suppression). Also rounding and CTA can be used to protect sensitive tables.\nThe purpose of the present manual is to give a potential user enough information so that he can understand the general principles on which \\(\\tau\\)-Argus is based, and also allow him to use the package. So it contains both general background information and detailed program information. For a more in-depth theoretical background we refer to the handbook “Statistical Disclosure Control” by Anco Hundepool, Josep Domingo-Ferrer, Luisa Franconi, SarahGiessing, Eric Schulte Nordholt, Keith Spicer and Peter-Paul de Wolf(ISBN: 978-1-119-97815-2, Wiley, 2012).\n\\(\\tau\\)-Argus is one of a twin set of disclosure control packages. For the protection of microdata - \\(\\mu\\)-Argus - has been developed, which is the twin brother of \\(\\tau\\)-Argus1. Also \\(\\mu\\)-Argus has been ported to OpenSource.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#about-the-name-argus",
    "href": "01_Introduction.html#about-the-name-argus",
    "title": "2  Introduction",
    "section": "2.2 About the name ARGUS",
    "text": "2.2 About the name ARGUS\nSome what jokingly the name Argus can be interpreted as the acronym of ‘Anti-Re-identification General Utility System’2. As a matter of fact, the name Argus was inspired by a myth of the ancient Greeks. In this myth Zeus has a girl friend named Io. Hera, Zeus’ wife, did not approve of this relationship and turned Io into a cow. She let the monster Argus guard Io. Argus seemed to be particularly well qualified for this job, because it had a hundred eyes that could watch over Io. If it would fall asleep only two of its eyes were closed. That would leave plenty of eyes to watch Io. Zeus was eager to find a way to getIo back. He hired Hermes who could make Argus fall asleep by the enchanting music on his flute. When Hermes played his flute to Argus this indeed happened: all its eyes closed, one by one. When Hermes had succeeded in making Argus fall asleep, Argus was decapitated. Argus’ eyes were planted onto a bird’s tail - a type of bird that we now know under the name of peacock. That explains why a peacock has these eye-shaped marks on its tail. This also explains the picture on the cover of this manual. It is a copper plate engraving of Gerard de Lairesse (1641-1711) depicting the process where the eyes of Argus are being removed and placed on the peacock’s tail3.\nLike the mythological Argus, the software is supposed to guard something, in this case data. This is where the similarity between the myth and the package is supposed to end, as we believe that the package is a winner and not a loser as the mythological Argus is.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#contact",
    "href": "01_Introduction.html#contact",
    "title": "2  Introduction",
    "section": "2.3 Contact",
    "text": "2.3 Contact\nFeedback from users will help improve future versions of \\(\\tau\\)-Argus and is therefore greatly appreciated. The authors of this manual can be contacted directly for suggestions that may lead to improved versions of \\(\\tau\\)-Argus in writing or otherwise; e-mail messages can also be sent to argus@cbs.nl.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#open-source",
    "href": "01_Introduction.html#open-source",
    "title": "2  Introduction",
    "section": "2.4 Open Source",
    "text": "2.4 Open Source\nIn the open source world the responsibility for the software is different. The idea behind open source is that the software code is no longer owned by one institute (Statistics Netherlands), but the source is available for anybody. Anybody can also contribute to the code and make his own extensions. Nevertheless we do not want to have many different versions of the software and many diversions. Therefore there will always be one official version of \\(\\tau\\)-Argus. In order to achieve this we need a body to make decisions about further developments and extensions for the official \\(\\tau\\)-Argus. This responsibility will be in the hands of a small committee. This committee will be a sub-group of the Eurostat technical working group on Statistical Confidentiality. They will make decisions on whether a new extension/correction will be allowed in the official versions of \\(\\tau\\)-Argus, and also make recommendations for future extensions.\nNevertheless the above mentioned email address (argus@cbs.nl) will remain open for questions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#acknowledgments",
    "href": "01_Introduction.html#acknowledgments",
    "title": "2  Introduction",
    "section": "2.5 Acknowledgments",
    "text": "2.5 Acknowledgments\n\\(\\tau\\)-Argus was started as part of the EU \\(4^{th}\\) framework SDC-project and became a mature software tool as part of the CASC project that was partly sponsored by the EU under contract number IST-2000-25069. This support is highly appreciated. The CASC (Computational Aspects of Statistical Confidentiality) project is part of the Fifth Framework ofthe European Union. The main part of \\(\\tau\\)-Argus has been developed at Statistics Netherlands by Aad van de Wetering and Ramya Ramaswamy (who wrote the kernel) and Anco Hundepool (who wrote the interface). However this software would not have been possible without the contributions of several others, both partners in the CASC-project and outsiders. Recent extensions of \\(\\tau\\)-Argus have been made possible during the European CENEX-SDC-project (grant agreement 25200.2005.001-2005.619), the ESSNet-SDC project (grant agreement 25200.2005.003-2007.670.) and the ESSnet SDC harmonisation (61102.2010.004-2010.579).\nThe Open Source transition was supported by a Eurostat grant (61102.2012.001-2012.102).\nThe German partners Statistisches Bundesamt (Sarah Giessing and Dietz Repsilber) have contributed the GHMITER software, which offers a solution for secondary cell suppression based on hypercubes. Peter-Paul de Wolf has built a search algorithm based on non-hierarchical optimal solutions. This algorithm breaks down a large hierarchical table into small non-hierarchical subtables, which are then individually protected. A team led by JJ Salazar of the University La Laguna Tenerife, Spain, has developed the optimisation routines. Additionally Jordi Castro, Universitat Politècnica de Catalunya, Barcelona, has developed a solution based on networks. Jordi Castro also developed the CTA solution. The controlled rounding procedure has been developed by JJ Salazar in a project sponsored by ONS. In order to enhance the usability \\(\\tau\\)-Argus now also can handle SPSS-system files. Forusing \\(\\tau\\)-Argus in combination with SAS, several reports have been produced during the ESSnet projects. These reports and also the SAS-tools are available from the CASC/ESSNet website.The audit routine was first developed by Karl Luhn of the University of Ilmenau and further developed by Destatis.\nFor solving these optimisation problems, \\(\\tau\\)-Argus traditionally uses commercial LP-solvers. Traditionally we use Xpress as an LP-solver. This package is kindly made available for users of \\(\\tau\\)-Argus in a special agreement between the \\(\\tau\\)-Argus-team and FICO, the developers of Xpress. Alternatively \\(\\tau\\)-Argus can also use the cplex-package. Users can choose either solver to link to \\(\\tau\\)-Argus (provided, of course, they purchase a license for the solver chosen). However users already having a licence for one of these packages for other applications can use their current licence for \\(\\tau\\)-Argus as well. Starting with this Open Source version also free and open solver(Soplex) can now be used to solve the optimisation models behind Cell Suppression, rounding and CTA.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#latest-improvements",
    "href": "01_Introduction.html#latest-improvements",
    "title": "2  Introduction",
    "section": "2.6 Latest improvements",
    "text": "2.6 Latest improvements\nThe latest extensions in version 4.1 of τ‑argus are :\n\nNew structure of the interface, making the table it self the central window.\nControlled Tabular Adjustment.\nRewritten Open Source Code in JAVA.\nC++ dlls for data manipulation and the modular approach have been adapted for the Open Source compilers.\nThe use of free Open Solvers complementary to the commercial solvers.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#the-structure-of-this-manual",
    "href": "01_Introduction.html#the-structure-of-this-manual",
    "title": "2  Introduction",
    "section": "2.7 The structure of this manual",
    "text": "2.7 The structure of this manual\nThe remaining part of this manual consists of four chapters and an index. In Chapter 3 we will give a short introduction to the theory and methodology. However for a more fundamental description we refer to the Wiley handbook on Statistical Disclosure Control4. This handbook is the result of the joined work of the SDC specialists in Europe working together for a long period.\nIn Chapter 4 a short tour of \\(\\tau\\)-Argus will be given as a first impression of the program. Chapter 5 is the reference manual of \\(\\tau\\)-Argus. It will describe in detail the program. This chapter is organized by the menu items of \\(\\tau\\)-Argus. Chapter 6 gives details of files used by \\(\\tau\\)-Argus. The manual is concluded with an index (Chapter 7).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_Introduction.html#footnotes",
    "href": "01_Introduction.html#footnotes",
    "title": "2  Introduction",
    "section": "",
    "text": "See Anco Hundepool et al. 2014, \\(\\mu\\)-Argus version 5.1 user’s lanual, Statistics Netherlands, The Hague, The Netherlands.↩︎\nThis interpretation is due to Peter Kooiman, former head of the methodology department at Statistics Netherlands.↩︎\nThe original copy of this engraving is in the collection of ‘Het Leidsch Prentenkabinet’ in Leiden, The Netherlands.↩︎\nAnco Hundepool, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Eric Schulte Nordholt, Keith Spicer, Peter-Paul de Wolf (2012), Statistical Disclosure control, ISBN: 978-119-97815-2, Wiley.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html",
    "href": "02_Producing_Safe_tables.html",
    "title": "3  Producing Safe Tables",
    "section": "",
    "text": "3.1 Introduction\nThe growing demands from researchers, policy makers and others for more and more detailed statistical information lead to a conflict. Statistical offices collect large amounts of data for statistical purposes. The respondents are only willing to provide the statistical offices with the required information if they can be certain that these statistical offices will treat their data with the utmost care. This implies that respondents' confidentiality must be guaranteed. This imposes limitations on the amount of detail in the publications. Practice and research have generated insights into how to protect tables, but the problem is not yet definitively solved.\nBefore we go into more details of the basic ideas on which \\(\\tau\\)-Argus is based, we give a sketch of the general ideas. At first sight one might find it difficult to understand that information presented in tabular form presents a disclosure risk. After all, one might say that the information is presented only in aggregate form.\nSafe tables are produced from unsafe ones by applying certain SDC measures to the tables. These SDC measures - as far as they are implemented in \\(\\tau\\)-Argus - are discussed in the present section. Some key concepts such as sensitive cells, information loss and the like are discussed as well.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#sensitive-cells-in-magnitude-tables5",
    "href": "02_Producing_Safe_tables.html#sensitive-cells-in-magnitude-tables5",
    "title": "3  Producing Safe Tables",
    "section": "3.2 Sensitive cells in magnitude tables1",
    "text": "3.2 Sensitive cells in magnitude tables1\nThe well-known dominance rule is often used to find the sensitive cells in tables, i.e. the cells that cannot be published as they might reveal information on individual respondents. More particularly, this rule states that a cell of a table is unsafe for publication if a few (\\(n\\)) major (largest) contributors to a cell are responsible for acertain percentage (\\(k\\)) of the total of that cell. The idea behind this rule is that in that case at least the major contributors themselves can determine with sufficient precision the contributions of the other contributors to that cell. The choice \\(n=3\\) and \\(k=70\\)% is not uncommon, but \\(\\tau\\)-Argus will allow the users to specify their own values of \\(n\\) and \\(k\\).\nAs an alternative the prior-posterior rule has been proposed. The basic idea is that a contributor to a cell has a better chance to estimate competitors in a cell than an outsider, and also that these kind of intrusions can occur rather often. The precision with which a competitor can estimate is a measure of the sensitivity of a cell. The worst case is that the second largest contributor will be able to estimate the largest contributor. If this precision is more than \\(p\\)%, the cell is considered unsafe. An extension is that also the global knowledge about each cell is taken into account. In that case we assume that each intruder has a basic knowledge of the value of each contributor of \\(q\\)%. Note, that it is actually the ratio \\(p/q\\) that determines which cells are considered safe, or unsafe. In this version of \\(\\tau\\)-Argus, the \\(q\\)‑parameter is fixed to \\(100\\). Literature refers to this rule as (minimum protection of) \\(p\\)%‑rule. If the intention is to state a prior-posterior rule with parameters \\(p_0\\) and \\(q_0\\), where \\(q_0 &lt; 100\\), choose the parameter \\(p\\) of the \\(p\\)%‑rule as \\(p = p_0/q_0 \\times 100\\). See Loeve (2001)2\nWith these rules as a starting point it is easy to identify the sensitive cells, provided that the tabulation package has the facility not only to calculate the cell totals, but also to calculate the number of contributors and the \\(n\\) individual contributions of the major contributors. Tabulation packages like ABACUS (from Statistics Netherlands) and the package ‘SuperCross’ developed in Australia by Space-Time Research have that capacity. In fact \\(\\tau\\)-Argus not only stores the sum of the \\(n\\) major contributions for each cell, but the individual major contributions themselves. The reason for this is that this is very handy in case rows and columns etc. in a table are combined. By merging and sorting the sets of individual contributions of the cells to be combined, one can quickly determine the major contributions of the new cell, without going back to the original file. This implies that one can quickly apply the dominance rule or the \\(p\\)%-rule to the combined cells. Combining rows and columns (table redesign) is one of the major tools for reducing the number of unsafe cells.\nThis too is the reason why \\(\\tau\\)-Argus can read microdata files and build the tables itself. However due to continuous demands from users we have now also provide the option to read ready-made tables, but with the restriction that the options for table redesign will not be available in that case.\nA problem, however, arises when also the marginals of the table are published. It is no longer enough to just suppress the sensitive cells, as they can be easily recalculated using the marginals. Even if it is not possible to exactly recalculate the suppressed cell, it is possible to calculate an interval that contains the suppressed cell. This is possible if some constraints are known to hold for the cell values in a table. A commonly found constraint is that the cell values are all nonnegative.\nIf the size of such an interval is rather small, then the suppressed cell can be estimated rather precisely. This is not acceptable either. Therefore it is necessary to suppress additional information to achieve sufficiently large intervals.\nSeveral solutions are available to protect the information of the sensitive cells:\n\nCombining categories of the spanning variables (table redesign). Larger cells tend to protect the information about the individual contributors better.\nSuppression of additional (secondary) cells to prevent the recalculation of the sensitive (primary) cells.\n\nThe calculation of the optimal set (with respect to the loss of information) of secondary cells is a complex OR-problem. \\(\\tau\\)-Argus has been built around this solution, and takes care of the whole process. A typical \\(\\tau\\)-Argus session will be one in which the users will first be presented with the table containing only the primary unsafe cells. The user can then choose how to protect these cells. This can involve the combining of categories, equivalent to the global recoding of \\(\\mu\\)-Argus. The result will be an update of the table with fewer unsafe cells(certainly not more) if the recoding has worked. At a certain stage the user requests the system to solve the remaining unsafe cells by finding secondary cells to protect the primary cells.\nAt this stage the user can choose between several options to protect the primary sensitive cells. Either they choose the hypercube method or the optimal solution. In this case they also has to select the solver to be used, Xpress or cplex or the free solver soplex. After this, the table can be stored for further processing if necessary, and eventual publication.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#sensitive-cells-in-frequency-count-tables",
    "href": "02_Producing_Safe_tables.html#sensitive-cells-in-frequency-count-tables",
    "title": "3  Producing Safe Tables",
    "section": "3.3 Sensitive cells in frequency count tables",
    "text": "3.3 Sensitive cells in frequency count tables\nIn the simplest way of using \\(\\tau\\)-Argus, sensitive cells in frequency count tables are defined as those cells that contain a frequency that is below a certain threshold value. This threshold value is to be provided by the data protector. This way of identifying unsafe cells in a table is the one that is implemented in the current version of \\(\\tau\\)-Argus. It should be remarked, however, that this is not always an adequate way to protect a frequency count table3. Yet it is applied a lot. Applying a dominance rule or a \\(p\\)% rule is useless in this context. One should think about possible disclosure risks that a frequency count table poses and possible disclosure scenarios in order to simulate the behaviour of an intruder. Such an analysis would probably come up with different insights than using a simple thresholding rule, e.g. like the one sketched in the reference just mentioned. We just mention here the risks of group-disclosure; when a(small) group of respondents have all the same score on a certain category. This risk is often also referred to as the problem of \\(100\\)%-cells. Further research on this topic is being carried out at Statistics Netherlands.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#table-redesign",
    "href": "02_Producing_Safe_tables.html#table-redesign",
    "title": "3  Producing Safe Tables",
    "section": "3.4 Table redesign",
    "text": "3.4 Table redesign\nIf a large number of sensitive cells are present in a table, it might be an indication that the spanning variables are too detailed. In that case one could consider combining certain rows and columns in the table. (This might not always be possible because of publication policy.) Otherwise the number of secondary cell suppressions might just be too enormous. The situation is comparable to the case of microdata containing many unsafe combinations. Rather than eliminating them with local suppressions one can remove them by using global recodings. For tabular data we use the phrase “table redesign” to denote an operation analogous to global recoding in microdata sets. The idea of table redesign is to combine rows, columns etc., by adding the cell contents of corresponding cells from the different rows, columns etc. It is a property of the sensitivity rules that a joint cell is safer than any of the individual cells. So as a result of this operation the number of unsafe cells is reduced. One can try to eliminate all unsafe combinations in this way, but that might lead to an unacceptably high information loss. Instead, one could stop at some point, and eliminate the remaining unsafe combinations by using other techniques such as cell suppression.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#secondary-cell-suppression",
    "href": "02_Producing_Safe_tables.html#secondary-cell-suppression",
    "title": "3  Producing Safe Tables",
    "section": "3.5 Secondary cell suppression",
    "text": "3.5 Secondary cell suppression\nOnce the sensitive cells in a table have been identified, possibly following table redesign it might be a good idea to suppress these values. In case no constraints on the possible values in the cells of a table exist this is easy: one simply removes the cell values concerned and the problem is solved. In practice, however, this situation hardly ever occurs. Instead one has constraints on the values in the cells due to the presence of marginals and lower bounds for the cell values (typically 0). The problem then is to find additional cells that should be suppressed in order to protect the sensitive cells. The additional cells should be chosen in such a way that the interval of possible values for each sensitive cell value is sufficiently large. What is “sufficiently large” can be specified by the data protector in \\(\\tau\\)-Argus by specifying the protection intervals.\nIn general the secondary cell suppression problem turns out to be a hard problem, provided the aim is to retain as much information in the table as possible, which, of course, is a quite natural requirement. The optimisation problems that will then result are quite difficult to solve and require expert knowledge in the area of combinatorial optimisation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#information-loss-in-terms-of-cell-costs8",
    "href": "02_Producing_Safe_tables.html#information-loss-in-terms-of-cell-costs8",
    "title": "3  Producing Safe Tables",
    "section": "3.6 Information loss in terms of cell costs4",
    "text": "3.6 Information loss in terms of cell costs4\nIn case of secondary cell suppression it is possible that a data protector might want to differentiate between the candidate cells for secondary suppression. It is possible that they would strongly prefer to preserve the content of certain cells, and are willing to sacrifice the values of other cells instead. A mechanism that can be used to make such a distinction between cells in a table is that of cell costs. In \\(\\tau\\)-Argus it is possible to associate different costs with the cells in a table. The higher the cost the more important the corresponding cell value is considered and the less likely it will be suppressed. We shall interpret this by saying that the cells with the higher associated costs have a higher information content.\nThe aim of secondary cell suppression can be summarised by saying that a safe table should be produced from an unsafe one, by minimising the information loss, expressed as the sum of the costs associated with the cells that have secondarily been suppressed.\n\\(\\tau\\)-Argus offers several ways to compute these costs. The first option is to compute the costs as the sum of the contributions to a cell. Alternatively another variable in the data file can be used as the cost function. Secondly this cost can be the frequency of the contributors to a cell, and finally each cell can have cost \\(= 1\\), minimising the number of suppressed cells.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#series-of-tables",
    "href": "02_Producing_Safe_tables.html#series-of-tables",
    "title": "3  Producing Safe Tables",
    "section": "3.7 Series of tables",
    "text": "3.7 Series of tables\nIn \\(\\tau\\)-Argus it is possible to specify a series of tables that will be protected one by one, and independently of each other. It is more efficient to choose this option since \\(\\tau\\)-Argus requires only a single run through the microdata in order to produce the tables. But also for the user it is often more attractive to specify a series of tables and let \\(\\tau\\)-Argus protect them in a single session, rather than have several independent sessions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#the-hypercubeghmiter-method9",
    "href": "02_Producing_Safe_tables.html#the-hypercubeghmiter-method9",
    "title": "3  Producing Safe Tables",
    "section": "3.8 The Hypercube/GHMITER method5",
    "text": "3.8 The Hypercube/GHMITER method5\nIn order to ensure tractability also of big applications, \\(\\tau\\)‑argus interfaces with the ghmiter hypercube method of R. D. Repsilber of the Landesamt für Datenverarbeitung und Statistik in Nordrhein-Westfalen/Germany, offering a quick heuristic solution. The method has been described in depth in Repsilber (1994), Repsilber (1999) and Repsilber (2002), for a briefer description see Giessing and Repsilber (2002).\n\n3.8.1 The hypercube method\nThe approach builds on the fact that a suppressed cell in a simple \\(n\\)‑dimensional table without substructure cannot be disclosed exactly if that cell is contained in a pattern of suppressed, nonzero cells, forming the corner points of a hypercube.\nThe algorithm subdivides n-dimensional tables with hierarchical structure into a set of \\(n\\)-dimensional sub-tables without substructure.These sub-tables are then protected successively in an iterative procedure that starts from the highest level. Successively, for each primary suppression in the current sub-table, all possible hypercubes with this cell as one of the corner points are constructed.\nIf protection against inferential disclosure is requested, for each hypercube, a lower bound for the width of the suppression interval forthe primary suppression that would result from the suppression of all corner points of the particular hypercube will be estimated. To estimate that bound, it is not necessary to implement the time consuming solution to the corresponding Linear Programming problem. Only if it turns out that the bound is sufficiently large, the hypercube becomes a feasible solution.\nIf no protection against inferential disclosure is requested, any hypercube will be considered feasible. This may of course lead to somecases of under protection.\nFor any of the feasible hypercubes, the loss of information associated with the suppression of its corner points is computed. The particular hypercube that leads to minimum information loss is selected, and all its corner points are suppressed.\nNote that the information loss concept of the hypercube method is slightly different from the one of the other, linear programming based methods for secondary cell suppression offered by \\(\\tau\\)-Argus it operates rather like a two-stage concept. In the first way, the algorithm will look at the number of additional suppressions (additional to those that are already suppressed because they a primary unsafe, or because they were selected as secondary suppression in another subtable) that would be caused by the selection of a particular candidate hypercube. If there is more than one hypercube that would result in the same, smallest number of additional secondary suppressions, at second priority the method will select the one with the smallest sum of costs associated to the suppression of the corresponding additional secondary suppressions. Cell costs associated to a cell are indeed a logarithmic transformation of the cell value plus eventually a large constant, if the cell is a marginal cell of the current sub-table.\nAfter all sub-tables have been protected once, the procedure is repeated in an iterative fashion. Within this procedure, when cells belonging to more than one sub-table are chosen as secondary suppressions in one of these sub-tables, in further processing they will be treated like sensitive cells in the other sub-tables they belong to. The same iterative approach is used for sets of linked tables.\nIt should be mentioned here that the ‘hypercube criterion’ is a sufficient but not a necessary criterion for a ‘safe’ suppression pattern. Thus, for particular subtables the ‘best’ suppression patternmay not be a set of hypercubes – in which case, of course, thehypercube method will miss the best solution and lead to some over-protection. Other simplifications of the heuristic approach that add to this tendency for over‑suppression are the following: when assessing the feasibility of a hypercube to protect specific target suppressions against interval disclosure, the method\n\nis not able to consider protection maybe already provided by other cell suppressions (suppressed cells that are not corner points of this hypercube) within the same sub‑table,\ndoes not consider the sensitivity of multi‑contributor primary suppressions properly, that is, it does not consider the protection already provided in advance of cell suppression through aggregation of these contributions,\nattempts to provide the same relative ambiguity to (eventually large) secondary suppressions that have been selected to protect cells in a linked sub‑table, as if they were single‑respondent primary suppressions, while actually it would be enough to provide the same absolute ambiguity as required by the corresponding primary suppressions.\n\n\n\n3.8.2 The ARGUS implementation of GHMITER\n\nIn the implementation offered by argus, ghmiter makes sure that a single respondent cell will never appear to be corner point of one hypercube only, but of two hypercubes at least. Otherwise it could happen that a single respondent, who often can be reasonably assumed to know that he is the only respondent, could use his knowledge on the amount of his own contribution to recalculate the value of any other suppressed corner point of this hypercube.\nAs explained above, ghmiter uses an elaborate internal cost assignment mechanism which is essential to achieve an optimal performance (given the natural restrictions of the simple heuristic approach, of course). This mechanism should not be cast out of balance. Therefore, the user’s choice of the cell costs (c.f. [3.1.4], [4.4.4]) does not have any impact, when using the hypercube method.\nFor tables presenting magnitude data, if protection against inferential disclosure is requested (see the upper part of the pop-up window below) \\(\\tau\\)-Argus will ensure that ghmiter selects secondary suppressions that protect the sensitive cells properly. Only cells will be considered feasible as secondary suppressions that are large enough to give enough protection to the target sensitive cell as explained in Giessing (2003).\n\n\n\nThe standard implementation of the hypercube is that extra protection is given to singleton cells, i.e. cells with only one contributor. As this contributor knows exactly the cell value he might be able to undo the protection. But this extra protecting can be disabled.\nIn order to achieve this, \\(\\tau\\)-Argus computes a suitable sliding protection ratio (for explanation see Giessing (2003), \\(\\tau\\)-Argus will display the value of this ratio in the report file) to be used by ghmiter. If in the screen above the option “Protection against inferential disclosure required” is inactivated, ghmiter will not check whether secondary suppressions are sufficiently large.\nAs mentioned above, ghmiter is unable to 'add' the protection given by multiple hypercubes. In certain situations, it is not possible to provide sufficient protection to a particular sensitive cell (or secondary suppression) by suppression of one single hypercube. In such a case, ghmiter is unable to confirm that this cell has been protected properly, according to the specified sliding protection ratio. It will then reduce the sliding protection ratio automatically, and individually, step by step for those cells, the protection of which the program cannot confirm otherwise. In steps \\(1\\) to \\(9\\) we divide the original ratio by \\(k\\), values of \\(k\\) from \\(2\\) to \\(10\\), and if this still does not help, in step 10 we divide by an extremely large value, and finally, if even that does not solve the problem, step 11 will set the ratio to zero). The \\(\\tau\\)-Argus report file will display the number of cases where the sliding protection range was reduced by finally confirmed sliding protection ratio.\nNote, that that the number of cases with range reduction reported by this statistic in the report file is very likely to exceed the actual number of cells concerned, because cells belonging to multiple (sub-) tables are counted multiple times. In our experience this concerns particularly the cases, where the protection level was reduced to an‚ ‘infinitely’ small (positive) value (in step 10, see above). Step 10 is usually required to confirm protection of large, high level secondary suppressions, which are likely to appear in multiple tables, especially in processing of linked tables. By the way, terms “reduction of the sliding protection ratio” and “reduction of the protection level” are used synonymously in the report file.\nNote that step 11 will make cells eligible for secondary suppression that \\(\\tau\\)-Argus considers as ‘protected’ (so called ‘frozen’ cells, for discussion of this option see for instance Giessing (2003).\n\nAs this is inconsistent with the current view on protected cells in \\(\\tau\\)-Argus this will lead to the following error message:\n\nThe cell value and the codes of those suppressed frozen cells are then displayed by \\(\\tau\\)-Argus : This information is also written in the file “frozen.txt” in the temp-directory.\n\nWhen the status of these cells is changed into ‘unprotected’ before re-running the hypercube method, the solution will be a feasible solution for \\(\\tau\\)-Argus. Zero cells are consider to be frozen as well inthe hypercube. Those frozen cells can be ignored.\nNegative values\nThe hypercube method has no problems when certain cells are negative.\n\n\n3.8.3 References on GHMITER\n\nRepsilber, R. D. (1994), ‘Preservation of Confidentiality in Aggregated data’, paper presented at the Second International Seminar on Statistical Confidentiality, Luxembourg, 1994\nRepsilber, D. (1999), ‘Das Quaderverfahren’ - in Forum der Bundesstatistik, Band 31/1999: Methoden zur Sicherung der Statistischen Geheimhaltung, (in German)\nRepsilber, D. (2002), ‘Sicherung persönlicher Angaben in Tabellendaten’ - in Statistische Analysen und Studien Nordrhein-Westfalen, Landesamt für Datenverarbeitung und Statistik NRW, Ausgabe 1/2002 (in German)\nGiessing, S. and Repsilber, D. (2002), ‘Tools and Strategies to Protect Multiple Tables with the GHQUAR Cell Suppression Engine’, in ’Inference Control in Statistical Databases’ Domingo-Ferrer (Editor), Springer Lecture Notes in Computer Science Vol. 2316.\nGiessing, S. (2003), ‘Co-ordination of Cell Suppressions: strategies for use of GHMITER’, Proceedings of the Joint ECE/Eurostat work session on statistical data confidentiality (Luxembourg, 7-9 April 2003)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#optimisation-models-for-secondary-cell-suppression10",
    "href": "02_Producing_Safe_tables.html#optimisation-models-for-secondary-cell-suppression10",
    "title": "3  Producing Safe Tables",
    "section": "3.9 Optimisation models for secondary cell suppression6",
    "text": "3.9 Optimisation models for secondary cell suppression6\n\\(\\tau\\)-Argus applies different approaches to find optimal and near-optimal solutions. One of these approaches is based on a Mathematical Programming technique which consists of solving Integer Linear Programming programs modelling the combinatorial problems under different methodologies (Cell Suppression and Controlled Rounding).The main characteristic of these models is that they share the same structure, thus based only on a \\(0\\)-\\(1\\) variable for each cell. In the Cell Suppression methodology, the variable is \\(1\\) if and only if the cell value must be suppressed. In the Controlled Rounding methodology, the variable is \\(1\\) if and only if the cell value must be rounded up. Noother variables are necessary, so the number of variables in the model is exactly the number of cells in the table to be protected. In addition, the model also imposes the protection level requirements(upper, lower and sliding) in the same way for the different methodologies (Cell Suppression and Controlled Rounding). These requirements ask for a guarantee that an attacker will not get too narrow an interval of potential values for a sensitive cell, whichhe/she will compute by solving two linear programming programs (calledattacker problems). Even if a first model containing this two-attacker problem would lead to a bi-level programming model, complex to be solved in practice, a Benders' decomposition approach allows us to convert the attacker problems into a set of linear inequalities. This conversion provides a second model for each methodology that can be efficiently solved by a modern cutting-plane approach. Since the variables are 0-1, a branching phase can be necessary, and the whole approach is named \"branch-and-cut algorithm\".\nBranch-and-cut algorithms are modern techniques in Operations Research that provide excellent results when solving larger and complicated combinatorial problems arising in many applied fields (like routing, scheduling, planning, telecomunications, etc.). Shortly, the idea isto solve a compact \\(0-1\\) model containing a large number of linear inequalities (as the ones above mentioned for the Cell Suppression andfor the Controlled Rounding) through an iterative procedure that does not consider all the inequalities at the same time, but generates the important ones when needed. This dynamic procedure of dealing with large models allows the program to replace the resolution of a hugelarge model by a short sequence of small models, which is termed a \"decomposition approach\". The on-line generation of the linear inequalities (rows) was also extended in this work to the variables (columns), thus the algorithm can also works on tables with a large number of cells, and the overall algorithm is named \"branch-and-cut-and-price\" in the Operations Research literature.\nTo obtain good performance, the implementation has also considered many other ingredients, standard in branch-and-cut-and-price approaches. For example, it is fundamentally the implementation of a pre-processing approach where redundant equations defining the table are eliminated, where variables associated to non-relevant cells are removed, and where dominated protection levels are detected. Thepre-processing is fundamental to make the problem as small as possible before starting the optimization phase. Another fundamental ingredient is the heuristic routine, which allows the algorithm to start with an upper bound of the optimal loss of information. This heuristic routine ensures the production of a protected pattern if the algorithm is interrupted by the user before the end. In other words, thanks to the heuristic routine, the implemented algorithm provide a near-optimal solution if the execution is cancelled before having a proof of optimality. During the implicit enumeration approach (i.e., the branch-and-cut-and-price) the heuristic routine is called several times, thus providing different protected patterns, and the best one will be the optimal solution if its loss of information is equal tothe lower bound. This lower bound is computed by solving a relaxed model, which consists of removing the integrability condition on the integer model. Since the relaxed model is a linear program, a linear programming solver must be called.\nWe have not implemented our own linear programming solver, but used a commercial solver which is already tested by other programmers for many years. A robust linear programming solver is a guarantee that no numerical trouble will appear during the computation.\nThat is the reason to requires either cplex (from ILOG) or Xpress(from FICO). Because the model to be solved can be applied to all type of table structures (2-dim, 3-dim, 4-dim, etc), including hierarchical and linked tables, we cannot use special simplex algorithm implementations, like the min-cost flow computation which would required to work with tables that can be modelled as a network (e.g., 2-dimensional tables or collections of 2-dim tables linked by onelink). On this special table, ad-hoc approaches (solving network flowsor short path problems) could be implemented to avoid using general linear programming solvers.\nSince \\(\\tau\\)-Argus has been transformed to an open source project we have also included an open source solver Soplex as an alternative for Xpress and cplex. We have obtained a licence that is included in the software that grants to the European National Statistical Institutes a non-exclusive, non-transferable, non-sub-licensable, perpetual right to use Soplex version 2.0.x and SCIP version 3.1.x, linked to the \\(\\tau\\)-Argus software. This enables you to use the \\(\\tau\\)-Argus software withou tbuying a licence for the commercial solvers. However it should benoted that commercial solvers are more powerful and might be needed to solve larger instances.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#sec-modularapproach",
    "href": "02_Producing_Safe_tables.html#sec-modularapproach",
    "title": "3  Producing Safe Tables",
    "section": "3.10 The Modular approach7",
    "text": "3.10 The Modular approach7\nThe modular (HiTaS) solution is a heuristic approach to cell suppression in hierarchical tables. Hierarchical tables are specially linked tables: at least one of the spanning variables exhibits a hierarchical structure, i.e. contains (many) sub-totals.\nIn Fischetti and Salazar (1998) a theoretical framework is presented that should be able to deal with hierarchical and generally linked tables. In what follows, this will be called the mixed integer approach. In this framework, additional constraints to a linear programming problem are generated. The number of added constraints however, grows rapidly when dealing with hierarchical tables, since many dependencies exist between all possible (sub-)tables containing many (sub-)totals. The implemented heuristic approach (HiTaS) deals with a large set of (sub)-tables in a particular order. A non hierarchical table can be considered to be a hierarchical table with just one level. In that case, the approach reduces to the original mixed integer approach and hence provides the optimal solution. In case of a hierarchical table, the approach will provide a sub-optimal solution that minimises the information loss per sub-table, but not necessarily the global information loss of the complete set of hierarchically linked tables.\nIn the following section, a short description of the approach is given. For a more detailed description of the method, including some examples, see e.g., De Wolf (2002).\nHiTaS deals with cell suppression in hierarchical tables using a top-down approach. The first step is to determine the primary unsafe cells in the base-table consisting of all the cells that appear when crossing the hierarchical spanning variables. This way all cells, whether representing a (sub-)total or not, are checked for primary suppression. Knowing all primary unsafe cells, the secondary cell suppressions have to be found in such a way that each (sub-)table of the base-table is protected and that the different tables cannot be combined to undo the protection of any of the other (sub-)tables. The basic idea behind the top-down approach is to start with the highest levels of the variables and calculate the secondary suppressions for the resulting table. The suppressions in the interior of the protected table is then transported to the corresponding marginal cells of the tables that appear when crossing lower levels of the two variables. All marginal cells, both suppressed and not suppressed, are then’fixed’ in the calculation of the secondary suppressions of that lower level table, i.e., they are not allowed to be (secondarily) suppressed. This procedure is then repeated until the tables that are constructed by crossing the lowest levels of the spanning variables are dealt with.\nA suppression pattern at a higher level only introduces restrictions on the marginal cells of lower level tables. Calculating secondary suppressions in the interior while keeping the marginal cells fixed, is then independent between the tables on that lower level, i.e., all these (sub)-tables can be dealt with independently of each other. Moreover, added primary suppressions in the interior of a lower level table are dealt with at that same level: secondary suppressions can only occur in the same interior, since the marginal cells are kept fixed.\nHowever, when several empty cells are apparent in a low level table,it might be the case that no solution can be found if one is restricted to suppress interior cells only. Unfortunately,backtracking is then needed.\nObviously, all possible (sub)tables should be dealt with in a particular order, such that the marginal cells of the table under consideration have been protected as the interior of a previously considered table. To that end, certain groups of tables are formed in a specific way (see De Wolf (2002)). All tables within such a group are dealt separately, using the mixed integer approach. The number of tables within a group is determined by the number of parent-categories the variables have one level up in the hierarchy. A parent-category is defined as a category that has one or more sub-categories. Note that the total number of (sub)-tables that have to be considered thus grows rapidly.\nSingletons\nSingleton cells should be treated with extra care. The single respondent in this cell could easily undo the protection if no extra measures were taken. The most dangerous situation is that there are only two singletons in a row, or one and one other primary unsafe cell. These singletons could easily disclose the other cell.\nWe have added options for extra singleton protection in the followingsituations.\n\nIf on a row or column of a subtable there are only two singletons and no other primary suppressions.\nIf there is only one singleton and one multiple primary unsafe cell.\nIf a frequency rule is used, it could happen that two cells on a row/column are primary unsafe, but the sum of the two cells could still be unsafe. In that case it should be prevented that these two cells protect each other.\n\nCells within a table sometimes consist of exactly one contributor. Such a cell is called a singleton. Linear sensitivity rules will usually label this cell as (primary) unsafe. When cell suppression is used to protect a table with unsafe cells, these singletons need to be taken care of in a special way.\nWithin a suppression pattern, contributors in singletons may be able to recalculate other suppressed cells. Obviously, a contributor could always insert its own contribution and thereby recalculate its ownsuppressed cell. This could in turn lead to the possibility of recalculating other suppressed cells in the same suppression pattern. Whenever such a recalculated cell is (primary) unsafe, this means disclosure.\nWithin the current models used to determine suppression patterns, it is not possible to take all possible situations into account when singletons are part of a suppression pattern. However, an important group of instances of disclosure by singletons, is when a singleton is part of a row with exactly one additional (also primary) suppression.\n\nIf on a row or column of a subtable there are only two singletons and no other primary suppressions.\nIf there is only one singleton and one multiple primary unsafe cell.\nIf a frequency rule is used, it could happen that two cells on a row/column are primary unsafe, but the sum of the two cells could still be unsafe. In that case it should be prevented that these two cells protect each other.\n\nNote that the last situation is not really a singleton problem, but this problem is handeled in the same way.\nTo prevent this kind of disclosure, it would be sufficient to force an additional (third) suppression in the same row. In prior versions of \\(\\tau\\)-Argus this was accomplished by increasing the protection levels of one of the (primary) unsafe cells in the row. In short, the protection level of one of the primary suppressed cells was raised in such a way that the other primary suppression would not be able to give sufficient protection. The largest primary unsafe cell in the row got the cell value of the other unsafe cell in the row, plus a small value, as protection level. Indeed, this forces a third suppression inthe row.\nHowever, since the cell value of one of the suppressed cells was involved, this meant that the increased protection level of this cell could become quite large, which would have an effect on the suppression pattern in one of the other dimensions. In certain situations this led to oversuppression.\nTo circumvent this problem, the newly implemented approach adds a virtual cell to the table. That virtual cell is assigned a value equal to the sum of the two primary suppressed cells in the row, and is given the status '(primary) unsafe'. That virtual cell then only has to be protected against exact disclosure, i.e., it suffices to imposea small protection interval.\nThe table below shows an example table, displaying the singleton problem. In the first table the values of the cells are given, with inbold, italic the (primary) unsafe cells. The second table shows the names of the cells, where cij stands for the cell with coordinates (i, j).\n\nExample table to explain Singleton Problem. Bold and italic means (primary) unsafe.\n\n\n\nTotal\nX1\nX2\nX3\nX4\n\n\n\n\nTotal\n227\n73\n33\n93\n25\n\n\nA\n146\n52\n15\n62\n17\n\n\nB\n81\n24\n18\n31\n8\n\n\n\n\nNames of the cells\n\n\n\n\n\n\n\n\n\n\n\nTotal\nX1\nX2\nX3\nX4\n\n\n\n\nTotal\n\\(c_{00}\\)\n\\(c_{01}\\)\n\\(c_{02}\\)\n\\(c_{03}\\)\n\\(c_{04}\\)\n\n\nA\n\\(c_{10}\\)\n\\(c_{11}\\)\n\\(c_{12}\\)\n\\(c_{13}\\)\n\\(c_{14}\\)\n\n\nB\n\\(c_{20}\\)\n\\(c_{21}\\)\n\\(c_{22}\\)\n\\(c_{23}\\)\n\\(c_{24}\\)\n\n\n\nNow assume that cell \\(c_{12} = (A,X2)\\) is a singleton and cell \\(c_{14} = (A,X4)\\) is unsafe according to a \\(p\\)%-rule with \\(p=10\\). Hence,cell \\(c_{14}\\) is the only other (primary) unsafe cell in that row. To protect cell \\(c_{14}\\) against disclosure by the contributor of singleton \\(c_{12}\\), a virtual cell \\(c_{v}\\) is defined with value \\(32\\). Moreover, that virtual cell is given a small protection interval, \\((32,33)\\) say. The relations that define the table structure, including the virtual cell, are given below:\n\nTable showing the relations defining table structure of table above\n\n\n\\(c_{00} = c_{01} +  c_{02} +  c_{03} +  c_{04}\\)\n\n\n\\(c_{10} = c_{11} +  c_{12} +  c_{13} +  c_{04}\\)\n\n\n\\(c_{20} = c_{21} +  c_{22} +  c_{23} +  c_{24}\\)\n\n\n\\(c_{00} = c_{10} +  c_{20}\\)\n\n\n\\(c_{01} = c_{11} +  c_{21}\\)\n\n\n\\(c_{02} = c_{12} +  c_{22}\\)\n\n\n\\(c_{03} = c_{13} +  c_{23}\\)\n\n\n\\(c_{04} = c_{14} +  c_{24}\\)\n\n\n\\(c_{v} = c_{12} +  c_{14}\\)\n\n\n\nWithin \\(\\tau\\)-Argus, this procedure is implemented in both the optimal approach as well as in the modular approach. For the modular approach, this procedure is applied to each subtable separately, whenever a subtable is dealt with within the modular approach.\nThis special attention to singletons is only given when the other suppressed cell in the same row is a 'true' primary suppression. This is natural, since it has to be done prior to the search for secondary suppressions. In the modular approach, a hierarchical table is divided into many, non-hierarchical, subtables. Secondary suppressions in one table sometimes temporarily become primary suppressions in other tables during the process. I.e., those suppression are not 'true' primary suppressions. It is therefore also natural not to construct virtual cells in case a singleton is in the same row with exactly one other primary suppression that was originally a secondary suppression. This is indeed the way it is implemented in the modular approach.\nIn previous versions of \\(\\tau\\)-Argus a similar procedure was available. But then the additional protection was achieved by increasing the protection level of the singleton cell. This would lead however also in additional protection in other dimensions and would create over-protection\nNegative values\nThe implementation by Fischetti and Salazar does not allow for negative values. However it is not uncommon, that some cells in a table have negative values. Therefore additional measures have been taken. If in a subtable during the process negative values are found ,all cell values are increased such that the lowest value becomes positive. Of course the margins have to be recalculated, but a safe protection pattern will be found.\n\n3.10.1 References on the modular method\n\nFischetti, M. and J.J. Salazar-González (1998). Models and Algorithmsfor Optimizing Cell Suppression in Tabular Data with LinearConstraints. Technical Paper, University of La Laguna, Tenerife.\nP.P. de Wolf (2002). HiTaS: a heuristic approach to cell suppressionin hierarchical tables. Proceedings of the AMRADS meeting inLuxembourg (2002).\nAdditional reading on the optimisation models can be found at theCASC-website(http://research.cbs.nl/casc/Related/99wol-heu-r.pdf)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#sec-modularlinkedtables",
    "href": "02_Producing_Safe_tables.html#sec-modularlinkedtables",
    "title": "3  Producing Safe Tables",
    "section": "3.11 The modular approach for linked tables",
    "text": "3.11 The modular approach for linked tables\nWhen tables are linked through simple linear constraints, cell suppressions must obviously be coordinated between tables. The most typical case is when tables share common cells (usually marginals),i.e., when they are linked through constraints saying literally that cell \\(X\\) of table A is identical to cell \\(Y\\) of table B.\nSuppose a set of \\(N\\) tables, \\(\\{T_{1},\\dots,T_{N}\\}\\), need to be protected. These tables are assumed to be linked. Each table has a hierarchical structure that may differ from the hierarchical structures of the other tables. However, it is assumed that tables using the same spanning variables have hierarchies that can becovered. Loosely speaking this means that a single hierarchy can be constructed such that all hierarchies of the same variable in the \\(N\\) tables are a sub hierarchy of the cover hierarchy. See De Wolf and Giessing (2009) for more details. In the context of pre-planned table production processes which are typically in place in statistical agencies for the production of certain sets of pre-specified standard tabulations, it is normally no problem to satisfy these conditions. Literally speaking, the assumption is that tables in a set of linked tables may present the data in a breakdown by the same spanning variable at various amounts of detail. But only under the condition that, if in one of the tables some categories of a spanning variable are grouped into a certain intermediate sum category, during SDC processing this intermediate sum category is considered in any other table presenting the data in a breakdown of the same spanning variable and at that much detail.\nThe idea is then as follows. Suppose that the \\(N\\) tables\\(\\{T_{1},\\dots,T_{N}\\}\\) that need to be protected simultaneously, contain \\(M\\) different spanning variables. Since the hierarchies are supposed to be coverable, an \\(M\\)-dimensional table exists having all the specified tables as subtables. The spanning variables will benumbered 1 up to \\(M\\).\nEach spanning variable can have several hierarchies in the specified tables. Denote those hierarchies for spanning variable \\(i\\) by \\(\\mathcal{H}_{1}^{i},\\dots,\\mathcal{H}_{I_{i}}^{i}\\) where \\(I_{i}\\) is the number of different hierarchies of variable \\(i\\).\nDefine the \\(M\\)-dimensional table by the table with spanning variables according to hierarchies \\(G_{1},\\dots,G_{M}\\) such that, for each \\(i = 1,\\dots,M\\) hierarchy \\(G_{i}\\) covers the set of hierarchies \\(\\{\\mathcal{H}_{j}^{i}\\}\\) with \\(j = 1,\\dots,I_{i}\\). This \\(M\\)-dimensional table will be called the cover table. See De Wolf and Giessing (2009) for more details.\nThen use the Modular approach (see Section 3.10) on the cover table \\(T_{C}\\), but only consider those subtables that are alsosubtables of at least one of the specified tables \\(T_{1},\\dots,T_{N}\\) and disregard the other subtables. I.e., the procedure of the Modular approach is followed, but during that process any simple subtable that is not a subtable of any of thetables in the set \\(\\{T_{1},\\dots,T_{N}\\}\\) is skipped. I.e., the orderthe simple subtables will be protected, is the same as in the ‘complete’ Modular approach, only some subtables will be skipped.\nSee De Wolf and Hundepool (2010) for a practical application of the Adjusted Modular Approach.\n\n3.11.1 References on the modular approach for linked tables\n\nDe Wolf, P.P. and S. Giessing (2009), Adjusting the \\(\\tau\\)-Argus modularapproach to deal with linked tables, Data & Knowledge Engineering,Volume 68, Issue 11, pp. 1160-1174.\nDe Wolf, P.P. and A. Hundepool (2010), Three ways to deal with a setof linked SBS tables using \\(\\tau\\)-Argus, Privacy in Statistical Databases,J. Domingo-Ferrer and E. Magkos (Eds.), Springer 2010, LNCS 6344 pp.66-74.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#network-solution-for-large-2-dimensional-tables-with-one-hierarchy",
    "href": "02_Producing_Safe_tables.html#network-solution-for-large-2-dimensional-tables-with-one-hierarchy",
    "title": "3  Producing Safe Tables",
    "section": "3.12 Network solution for large 2 dimensional tables with one hierarchy",
    "text": "3.12 Network solution for large 2 dimensional tables with one hierarchy\n\\(\\tau\\)-Argus also contains a solution for the secondary cell suppression based on network flows. This contribution is by Jordi Casto of the Universitat Politècnica de Catalunya in Barcelona. The network flows solution for cell suppression implements a fast heuristic for the protection of statistical data in two-dimensional tables with one hierarchical dimension (1H2D tables). This new heuristic sensibly combines and improves ideas of previous approaches for the secondary cell suppression problem in two-dimensional general, see Castro(1994)and positive tables, see Kelly(1992) and Castro(2003) tables. Details about the heuristic can be found in Castro(1996) and Cox(1995).Unfortunately this approach is only possible for two-dimensional tables with only one hierarchy, due to the limitations of the network flows. Note that the hierarchical variable should be the first variable.\nThe heuristic is based on the solution of a sequence of shortest-path subproblems that guarantee a feasible pattern of suppressions (i.e.,one that satisfies the protection levels of sensitive cells). Hopefully, this feasible pattern will be close to the optimal one.\nThe current package is linked with three solvers: CPLEX7.5/8.0 seeILOG(2000) pprn see Castro(1996), and an efficient implementation of the bidirectional Dijkstra’s algorithm for shortest-paths (that will be denoted as “Dijkstra”) see Ahuja(1993). Later releases of cplex will also work if the interface routines are the same than for version 8.0. The heuristic can use any of the three solvers for the solution of the shortest path subproblems, although Dijkstra is recommended (and the default one) for efficiency reasons. cplex is needed if alower bound of the optimal solution want to be computed. The auditing phase can be performed with either cplex or pprn.\npprn and Dijkstra were implemented at the Dept. of Statistics and Operations Research of the Universitat Politècnica de Catalunya, and are included in NF CSP. pprn was originally developed during 1992–1995, but it had to be significantly improved within the CASC project to work with NF CSP. Dijkstra was completely developed in the scope of CASC. The third solver, cplex, is a commercial tool, and requires purchasing a license. However, pprn is a fairly good replacement —although not so robust— for the network flows routines of cplex. Therefore, in principle, there is no need for an external commercial solver, unless lower bounds want to be computed.\nEven though two of the three solvers are included in the distribution of NF CSP, this document only describes the features of the heuristic,and from the user’s point of view. A detailed description of pprn and Dijkstra’s solvers can be found in Castro(1996) and Ahuja(1993), respectively.\nThe current implementation in \\(\\tau\\)-Argus however only uses the Dijkstra and the pprn solvers. We have restricted ourselves from commercial solvers here as the network flows give already a very fast solution.\n\n3.12.1 References on the network solution\n\nAhuja, R.K, Magnanti, T.L., Orlin, J.B., Network Flows, Prentice Hall(1993).\nCastro, J., pprn 1.0, User’s Guide, Technical report DR 94/06 Dept. ofStatistics and Op-erations Research, Universitat Politècnica deCatalunya, Barcelona, Spain, 1994.\nCastro, J., Network flows heuristics for complementary cellsuppression: an empirical evaluation and extensions, in LNCS 2316,Inference Control in Statistical Databases, J. Domingo-Ferrer (Ed),(2002) 59–73.\nCastro, J., Nabona, N. An implementation of linear and nonlinearmulticommodity network flows. European Journal of Operational Research92, (1996) 37–53.\nCox, L.H., Network models for complementary cell suppression. J. Am.Stat. Assoc. 90, (1995) 1453–1462.\nILOG CPLEX, ILOG CPLEX 7.5 Reference Manual Library, ILOG, (2000).\nKelly, J.P., Golden, B.L, Assad, A.A., Cell Suppression: disclosureprotection for sensitive tabular data, Networks 22, (1992) 28–55.\nCastro, J. User’s and programmer’s manual of the network flowsheuristics package for cell suppression in 2D tables Technical ReportDR 2003-07, Dept. of Statistics and Operations Research, UniversitatPolitècnica de Catalunya, Barcelona, Spain,2003;\nSeehttp://research.cbs.nl/casc/deliv/41D5-NF-Tau-Argus.pdf",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#controlled-tabular-adjustment12",
    "href": "02_Producing_Safe_tables.html#controlled-tabular-adjustment12",
    "title": "3  Producing Safe Tables",
    "section": "3.13 Controlled Tabular Adjustment8",
    "text": "3.13 Controlled Tabular Adjustment8\nThe purpose of controlled tabular adjustment (also known as minimum-distance controlled tabular adjustment or simply CTA) is to find the closest safe table to the original one. Since CTA is a perturbative method, this goal is achieved by publishing a table where the values of sensitive cells have been modified according to some predefined protection levels, and the remaining non-sensitive cells are minimally changed to guarantee the table additivity.\nThe example illustrates CTA on a small two-dimensional table with one sensitive cell in bold face, with lower and upper protection levelsequal to five (table (a) of the example). Depending on the 'protection direction' of the sensitive cell, either 'lower' or'upper', which has to be decided, the value to be published for this cell will be respectively less or equal than the original cell value minus the lower protection level, or greater or equal than the original cell value plus the upper protection level. In the example,if the protection direction is 'lower', then the value published orthe sensitive cell should be less or equal than 35; the optimal adjusted table for this case is shown in table (b) of the example. If the protection direction is 'upper', then the value must be great eror equal than 45, as shown in table (c) of the example. In a larger and more complex table, with many sensitive cells, the obtention of the protection directions that provide the minimal changes tonon-sensitives cells is not as easy as in the example. CTA has thus tobe formulated and solved as an optimization problem, in particular as a mixed integer linear problem (MILP).\nExample of a CTA solution: The cell (M2P3) is a sensitive cell with lower and upper protection level 5. Protected tables with 'lower protection direction' and 'upper protection direction' (i.e., value of sensitive is respectively reduced and increased byfive units).\n\nOriginal table (a)\n\n\n\nP1\nP2\nP3\n\n\n\n\n\nM1\n20\n24\n28\n72\n\n\nM2\n38\n38\n40\n116\n\n\nM3\n40\n39\n42\n121\n\n\n\n98\n101\n110\n309\n\n\n\n\n\n\n\n\n\n\nAdjusted table - lower protection direction (b)\n\n\n\nP1\nP2\nP3\n\n\n\n\n\nM1\n15\n24\n33\n72\n\n\nM2\n43\n38\n35\n116\n\n\nM3\n40\n39\n42\n121\n\n\n\n98\n101\n110\n309\n\n\n\n\n\n\nAdjusted table - upper protection direction (c)\n\n\n\nP1\nP2\nP3\n\n\n\n\n\nM1\n25\n24\n23\n72\n\n\nM2\n33\n38\n45\n116\n\n\nM3\n40\n39\n42\n121\n\n\n\n98\n101\n110\n309\n\n\n\n\n\n\n\n\n\nCTA was introduced in the manuscript Dandekar and Cox(2002) and, independently and in an extended form, in Castro(2006) (in the latter it was named minimum-distance controlled perturbation method). CTA has shown to have both a small disclosure risk see Castro(2012) and small information loss see Castro and González(2014).\nThe parameters that define any CTA instance are:\n\nA general table \\(a_{i}\\), \\(i=1,\\dots,n\\), with \\(m\\) linear relations \\(Aa=b\\).\nUpper and lower bounds \\(u\\) and \\(l\\) for the cell values, assumed to be known by any attacker: \\(l \\leq a \\leq u\\).\nVector of nonnegative weights associated to the cell perturbations \\(w_{i}\\), \\(i=1,\\dots,n\\).\nSet \\(P \\subseteq \\{1,\\dots,n\\}\\) of sensitive cells.\nLower and upper protection levels for each primary cell \\(lpl_{p}\\) and \\(upl_{p}\\), \\(p \\in P\\)\n\nCTA finds the safe table x closest to \\(a\\), using some distance \\(l{(w)}\\)\n\n\n\nProblem (3) has \\(|P|\\) binary variables, \\(2n\\) continuous variables and \\(m + 4|P|\\) constraints.The size of (3) is much less than that of the cell suppression problem. For instance, for a table of \\(8,000\\) cells, \\(800\\) primaries, and \\(4,000\\) linear relations, CTA formulates a MILP of 800 binary variables, \\(16,000\\) continuous variables and \\(7,200\\) constraints (these figures would be \\(8,000\\), \\(12,800,000\\) and \\(32,000,000\\) for cell suppression).\nThe benefits of CTA are not limited to a smaller size of the resulting MILP problem. CTA can be easily extended with constraints to meet some data quality criteria see Cox et al (2005). It has also been experimentally observed that the information loss of CTA solutions iscomparable (in some instances even better) to that of cell suppression see Castro and Giessing(2006).\n\n3.13.1 References on the controlled tabular adjustment solution\n\nL.H. Cox, J.P. Kelly and R. Patil (2005), Computational aspects ofcontrolled tabular adjustment: algorithm and analysis. B. Golden, S.Raghavan, E. Wassil, eds. The Next wave in Computer,Optimization and Decision Technologies, Kluwer, Boston, MA,45–59.\nJ. Castro, Minimum-distance controlled perturbation methods forlarge-scale tabular data protection, European Journal ofOperational Research, 171 (2006) 39–52.\nJ. Castro (2012), On assessing the disclosure risk of controlledadjustment methods for statistical tabular data, InternationalJournal of Uncertainty, Fuzziness and Knowledge-Based Systems, 20921–941.\nJ. Castro and S. Giessing (2006), Testing variants of minimumdistance controlled tabular adjustment, in Monographs of OfficialStatistics. Work session on Statistical Data Confidentiality,Eurostat-Office for Official Publications of the European Communities,Luxembourg, 2006, 333–343. ISBN 92-79-01108-1.\nJ. Castro and J.A. González (2014), Assessing the information lossof controlled tabular adjustment in two-way tables, Lecture Notesin Computer Science, 8744, 11–23.\nR.A. Dandekar and L.H. Cox (2002), Synthetic tabular data: Analternative to complementary cell suppression, manuscript, EnergyInformation Administration, US Department of. Energy.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#controlled-rounding13",
    "href": "02_Producing_Safe_tables.html#controlled-rounding13",
    "title": "3  Producing Safe Tables",
    "section": "3.14 Controlled rounding9",
    "text": "3.14 Controlled rounding9\nControlled rounding is a rounding procedure that, differently from other rounding methods, yields additive rounded tables. That is to say that the rounded values add up to the rounded totals and sub-totals shown in the table. This property not only permits the release of realistic tables but also makes it impossible to reduce the protection by “unpicking” the original values by exploiting the differences in the sums of the rounded values. The Controlled Rounding Procedure (CRP) implemented in \\(\\tau\\)-Argus also allows the specification hierarchical tables.\nControlled rounding is a SDC method that is most effective for frequency tables. In fact, this method gives adequate protection to small frequencies by creating uncertainty also with respect to zero values (i.e. empty cells). The same cannot be said for suppression in the way it is implemented now in \\(\\tau\\)-Argus.\n\n3.14.1 Restricted and non-restricted controlled rounding\nIn Zero-restricted Controlled Rounding the rounded values are chosen leaving unaltered the original values that are already multiples of the rounding base, while rounding the others to one of the adjacent multiples of this base. The modified values are chosen so that the sum of the absolute differences between the original values and the rounded ones is minimized under the additivity constraint. Therefore, some values will be rounded up or down to the most distant multiple of the base in order to satisfy the constraints. In most cases such a solution can be found but in some cases it cannot. The zero-restriction constraint in CRP can be relaxed allowing the values to be rounded to a non adjacent multiple of the base. This relaxation is controlled by allowing a maximum number of steps. For example, consider rounding the value \\(7\\) when the base equals \\(5\\). In zero-restricted rounding, the solution can be either \\(5\\) or \\(10\\). If \\(1\\) step is allowed, the solution can be \\(0, 5, 10\\) or \\(15\\). In general, let \\(z\\) be the integer to be rounded in base \\(b\\), then this number can bewritten as \\[{z = {\\mathit{ub} + r}},\\]\nwhere \\(ub\\) is the lower adjacent multiple of \\(b\\) (hence \\(u\\) is the floor value of \\(z/b\\)) and \\(r\\) is the remainder. In the zero-restricted solution the rounded value, \\(a\\), can take values: \\[\\left\\{ \\begin{matrix}{{a = \\mathit{ub}}\\mathit{if}{r = 0};} \\\\{{a = \\left\\{ \\begin{matrix}\\mathit{ub} \\\\{{({u + 1})}b}\\end{matrix} \\right.}\\mathit{if}{r \\neq 0.}}\\end{matrix} \\right.\\]\nIf \\(K\\) steps are allowed, then \\(a\\), can take values:\n\\[\\left\\{ \\begin{matrix}{{a = \\mathit{\\max}}{\\{{0,{({u + j})}}\\}}b,{j = {- K}},\\ldots,K,\\mathit{if}{r = 0};} \\\\{{a = \\mathit{\\max}}{\\{{o,{({u + j})}}\\}}b,{j = {- K}},\\ldots,{({K + 1})},\\mathit{if}{r \\neq 0.}}\\end{matrix} \\right.\\]\n\n\n3.14.2 Optimal, first feasible and RAPID solutions10\nFor a given table there could exist more than one controlled rounded solutions; any of these solutions is a feasible solution. The Controlled Rounding Program embedded in \\(\\tau\\)-Argus determines the optimal solution by minimising the sum of the absolute distances of the rounded values from the original ones. Denoting the cell values, including the totals and sub-totals, with \\(z_{i}\\) and the correspondingrounded values with \\(a\\)i, the function that is minimised is \\[{\\sum\\limits_{i = 1}^{N}{\\mid {z_{i} - a_{i}} \\mid}},\\]\nwhere \\(N\\) is the number of cells in a table (including the marginalones). The optimisation procedure for controlled rounding is a rather complex one (NP-complete program), so finding the optimal solution may take a long time for large tables. In fact, the algorithm iteratively builds different rounded tables until it finds the optimal solution. In order to limit the time required to obtain a solution,the algorithm can be stopped when the first feasible solution is found. In many cases, this solution is quite close to the optimal one and it can be found in significantly less time.\nThe RAPID solution is produced by CRP as an approximated solution when not even a feasible one can be found. This solution is obtained by rounding the internal cells to the closest multiple of the base and then computing the marginal cells by addition. This means that the computed marginal values can be many jumps away from the original value. However, a RAPID solution is produced at each iteration of the search for an optimal one and it will improve (in terms of the loss function) over time. \\(\\tau\\)-Argus allows to stop CRP after the first RAPID is produced, but this solution is likely to be very far away from the optimal one.\n\n\n3.14.3 Protection provided by controlled rounding\nThe protection provided by controlled rounding can be assessed by considering the uncertainty about the disclosive true values achieved releasing rounded values; that is the existence interval that an intruder can compute for the rounded value. We assume that also the values of the rounding base, \\(b\\), and the number of steps allowed, \\(K\\), are released together with the rounded table. Furthermore, we assume that it is known that the original values are frequencies (hence nonnegative integers).\n\n3.14.3.1 Zero-restricted rounding\nGiven a rounded value, \\(a\\), an intruder can compute the following existence intervals for the true value, \\(z\\): \\[\\begin{matrix}{{z \\in {\\lbrack{0,{b - 1}}\\rbrack}}\\mathit{if}{a = 0}} \\\\{{z \\in {\\lbrack{{{a - b} + 1,}{{a + b} - 1}}\\rbrack}}\\mathit{if}{a \\neq 0.}}\\end{matrix}\\]\nFor example, if the rounding base is \\(b=5\\) and the rounded value is \\(a=0\\), a user can determine that the original value is between \\(0\\) and \\(4\\). If the rounded value is not \\(0\\), then users can determine that thetrue value is between plus or minus 4 units from the published value.\n\n\n3.14.3.2 K-step rounding\nAs mentioned before, it is assumed that the number of steps allowed is released together with the rounded table. Let \\(K\\) be the number of steps allowed, then an intruder can compute the following existence intervals for the true value \\(z\\): \\[\\begin{matrix}{{z \\in {\\lbrack{0,{({K + 1})}{b - 1}}\\rbrack}}\\mathit{if}{a &lt; {({K + 1})}}b} \\\\{{z \\in {\\lbrack{{a - {({K + 1})}}{b + 1,}{a + {({K + 1})}}{b - 1}}\\rbrack}}\\mathit{if}{a \\geq {({K + 1})}}\\mathit{b.}}\\end{matrix}\\]\nFor example, assume that for controlled rounding with \\(b=5\\) and \\(K=1\\), \\(a=15\\), then a user can determine that \\[{z \\in {\\lbrack{6,24}\\rbrack}}.\\]\n\n\n\n3.14.4 Choosing the parameters for Controlled Rounding\nThe parameters that can be chosen for rounding are the rounding base, \\(b\\), and the number of steps allowed. If their value is released,users (including potential intruders) will be able to compute existence intervals for the true values according to the formulae given above. Then, the choice of the parameters’ values depends on the protection required for the disclosive values. Of course, the larger the existence interval the greater the protection but also the damage caused to the data. The choice of the rounding base, then, should be made by the data protector considering the protection requirements and the damage caused to the data. A discussion on how existence intervals can be related to protection requirements can be found, for example, in Willenborg and de Waal (2001). Below we give some general considerations on the effect of different choices of the rounding base.\nFrequencies are disclosive if their values are not larger than a chosen threshold, say \\(f\\). In \\(\\tau\\)-Argus the minimal rounding base is \\(b=f\\). When this value is chosen, disclosive values can be rounded either to \\(0\\) or to \\(b\\). Hence, an intruder would know that all published zeros are disclosive values, while he or she could not determine if a published value equal to \\(b\\) is a disclosive value or a larger, safe, one. In some cases this protection can be considered insufficient because it is required that the existence interval for values rounded to zero contains at least one safe value. Then the value of \\(b\\) must be chosen to be greater than \\(f\\) or the number of steps allowed must be greater than zero. It must be stressed, however, that the larger the base and the greater the damage inflicted to the data (including safe values). In some cases, data protector may be happy with a base that is less than the minimum frequency threshold. For example, it could be decided that the width of the existence interval must be not less than the minimum frequency. In this case, the base should be chosen to be the minimal integer not smaller than \\(f/2\\). Using a smaller base than the minimum safe frequency can be achieved in \\(\\tau\\)-Argus by lowering the threshold before computing the table. This “trick” is allowed in rounding because the procedure does not change if the disclosive cells are changed (unlike secondary suppression).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#audit",
    "href": "02_Producing_Safe_tables.html#audit",
    "title": "3  Producing Safe Tables",
    "section": "3.15 Audit",
    "text": "3.15 Audit\nWhen a table is protected by cell suppression, by making use of the linear relation between published and suppressed cell values in atable (including its margins), it is always possible for any particular suppressed cell of a table to derive upper and lower bounds for its true value. This holds for either tables with non-negative values, and those tables containing negative values as well, when itis assumed that instead of zero, some other (possibly tight) lower bound for any cell is available to data users in advance of publication. The interval given by these bounds is called the ‘feasibility interval’. The example below illustrates the computation of the feasibility interval in the case of a simple two-dimensional table where all cells may only assume non-negative values:\n\nExample\n\n\n\n1\n2\nTotal\n\n\n\n\n1\n\\(X_{11}\\)\n\\(X_{12}\\)\n7\n\n\n2\n\\(X_{21}\\)\n\\(X_{22}\\)\n3\n\n\n3\n3\n3\n6\n\n\nTotal\n9\n7\n16\n\n\n\nFor this table the following linear relations hold: \\[\\begin{matrix}{{{X_{11} + X_{12}} = 7}{(\\mathit{R1})}} \\\\{{{X_{21} + X_{22}} = 3}{(\\mathit{R2})}} \\\\{{{X_{11} + X_{21}} = 6}{(\\mathit{C1})}} \\\\{{{X_{12} + X_{22}} = 4}{(\\mathit{C2})}} \\\\ \\text{with }{X_{\\mathit{ij}} \\geq 0}, \\forall (i,j) \\end{matrix}\\]\nUsing linear programming methodology, it is possible to derive systematically for any suppressed cell in a table a upperbound \\((X^{\\mathit{\\max}})\\) and a lower bound \\((X_{11}^{\\mathit{\\min}})\\) for the set of feasible values. In the example above, for cell (1,1) these bounds are \\((X_{11}^{\\mathit{\\min}}) = 3\\) and \\((X_{11}^{\\mathit{\\max}}) = 6\\).\nA general mathematical statement for the linear programming problem to compute upper and lower bounds for the suppressed entries of a table is given in Fischetti and Salazar (2000)11.\nNote that in the current implementation the \\(\\tau\\)-Argus audit routine computes upper and lower bounds (i.e. the feasibility intervals) for the suppressed entries of a hierarchical table considering the full set of table relations – even, if the table is a hierarchical table.After obtaining these feasibility intervals, they are compared to the protection intervals (c.f. subsection on protection levels in section 4.3.2. Protection level of the SDC-Handbook, Hundepool et al(2012)) and the result of this comparison will be reported to the user. When a table has been protected properly, the feasibility interval of each primary sensitive cell should cover the protection interval. These intervals will be shown by \\(\\tau\\)-Argus.\n\n3.15.1 Auditing a hierarchical table\nIt should be noted that secondary cell suppression algorithms like Modular and Hypercube relying on a backtracking procedure (c.f. the subsection on linked and hierarchical tables in section 4.4.4.Secondary cell suppression in hierarchical and linked tables of theSDC-Handbook, Hundepool et all(2012)) assign secondary suppressions considering only a part of the table relations at a time, e.g. those referring to the ‘current’ subtable. These methods are able to protect each subtable properly in the sense that the feasibility intervals of the sensitive cells indeed cover the protection intervals. But this holds only, if the feasibility intervals are computed considering only the table relations of the particular subtable. But for a hierarchical table, feasibility intervals computed on basis of the set of relations for the full table normally tend to be closer than those computed on basis of separate sets of relations corresponding to individual sub-tables. Hence, in a hierarchical table, it is not unlikely that the Audit routine discovers that some cells were not protected properly.\n\n\n3.15.2 Discovering singleton problems\nMaking use of the additional knowledge of a respondent, who is the single respondent to a cell (a so called ‘singleton’), it is possible to derive intervals that are much closer than without this knowledge. The audit routine could be used to identify problems in this respect in the following way: in advance of running the audit routine, set the status of a particular singleton cell from “unsafe” to “safe”.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#functional-design-of-tau-argus",
    "href": "02_Producing_Safe_tables.html#functional-design-of-tau-argus",
    "title": "3  Producing Safe Tables",
    "section": "3.16 Functional design of \\(\\tau\\)-Argus",
    "text": "3.16 Functional design of \\(\\tau\\)-Argus",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "02_Producing_Safe_tables.html#footnotes",
    "href": "02_Producing_Safe_tables.html#footnotes",
    "title": "3  Producing Safe Tables",
    "section": "",
    "text": "See section 4.2 Disclosure risk assessment I: primary sensitive cells of the SDC-Handbook (Hundepool et al. (2012)).↩︎\nLoeve, Anneke, 2001, Notes on sensitivity measures and protection levels, Research paper, Statistics Netherlands. Available at http://neon.vb.cbs.nl/casc/related/marges.pdf ↩︎\nSee section 5.2 Disclosure risks of the SDC-Handbook (Hundepool et al. (2012)).↩︎\nSee section 4.6 Information loss measures for tabular data of the SDC-Handbook (Hundepool et al. (2012)).↩︎\nThe section on GHMiter has been contributed by Sarah Giessing, Federal Statistical Office of Germany 65180 Wiesbaden; E-mail: sarah.giessing@destatis.de.↩︎\nThe optimisation models have been built by a team of researchers headed by Juan-José Salazar-Gonzalez of the University La Laguna, Tenerife, Spain. Other members of the team were: G Andreatta, M. Fischetti, R. Betancort Villalva, M.D. Montesdeoca Sanchez and M. Schoch.↩︎\nSee section 4.4.4 Secondary cell suppression in hierarchical and linked tables of the SDC Handbook Hundepool et al. (2012).↩︎\nSee section 4.5.2 A post-tabular method: Controlled tabular adjustment of the SDC Handbook Hundepool et al. (2012).↩︎\nSee section 5.4.3 Rounding of the SDC Handbook Hundepool et al. (2012).↩︎\nFor further details see Salazar, Staggermeier and Bycroft (2005 Controlled rounding implementation, UN-ECE Worksession on SDC, Geneva)↩︎\nFischetti, M., Salazar Gonzales, J.J. (2000), Models and Algorithms for Optimizing Cell Suppression Problem in Tabular Data with Linear COnstraints, in Journal of the American Statistical Association, Vol. 95, pp.916↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Producing Safe Tables</span>"
    ]
  },
  {
    "objectID": "03_A_tour_of_τ-ARGUS.html",
    "href": "03_A_tour_of_τ-ARGUS.html",
    "title": "4  A tour of \\(\\tau\\)-Argus",
    "section": "",
    "text": "4.1 Preparation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>A tour of $\\tau$-Argus</span>"
    ]
  },
  {
    "objectID": "03_A_tour_of_τ-ARGUS.html#preparation",
    "href": "03_A_tour_of_τ-ARGUS.html#preparation",
    "title": "4  A tour of \\(\\tau\\)-Argus",
    "section": "",
    "text": "First steps. Before using τ‑argus for the first time, some options &gt; should be set to make τ‑argus better usable in your environment. &gt; E.g. you can select the solver you want to use in secondary cell &gt; suppression. See section [3.1.1]\nOpen Microdata. This involves selecting both the microdata and the &gt; associated metadata. See section [3.1.2]\nSpecify Metafile. This shows how the metafile can be entered when &gt; there in no metafile available, or can be edited after being read &gt; in but before any tables are being specified. This includes &gt; options such as declaring variables to be explanatory or response, &gt; and setting up the hierarchical structure of the data and the &gt; location of the variables in the file. See section &gt; [3.1.3]\nSpecify Tables. Declare the tables for which protection is &gt; required, along with the safety rule and minimum frequency rule on &gt; which the primary suppressions will be based. When this has been &gt; finished the tables will be computed or read in. See section &gt; [3.1.4]\nProcess of Disclosure Control. The main window of τ‑argus will &gt; show the table that we have computed or read in and when all the &gt; safety rules for primary suppressions have been applied.\nYou can inspect the table; get information about the number of &gt; unsafe cells etc. It contains options to modify the table using &gt; global recoding. There are several options to make the table safe &gt; via secondary cell suppression and rounding. Also an audit &gt; procedure is available to check quality of any secondary &gt; suppression pattern. See section [3.2]\nSave Table. The user can save the ‘safe’ table in a number of &gt; formats as will be seen in section [3.3]. &gt;\n\n\n4.1.1 First steps\nVia (Help|Options) you can open the options window. Before starting the process of protecting a table, you can customise\\(\\tau\\)-Argus. Some methods for secondary suppression (the modular and theoptimal), but also the audit procedure require an external linearprogramming solver. For the complex problems of \\(\\tau\\)-Argus we haveconcluded that the use of high quality commercial solvers can beefficient. However also a free solver can be chosen as a goodalternative. Although \\(\\tau\\)-Argus is freeware software these solvers arecommercial packages and you have to acquire a licence for themseparately. More information can be found on the casc-website(https://research.cbs.nl/casc/) Thechoice of this solver must be made before protecting a table. Thechoices are either Xpress or cplex or the free solver soplex, thedifferent LP_solvers supported by \\(\\tau\\)-Argus. See also section[2.9] for more details. For cplex the name of the licence file mustspecified. Once this window has been opened details of the solver can be entered.Also the maximum time the solver is allowed to spend on each sub-tablein Modular can be specified. However always a feasible solution issought. And the name of the logbook, by default taulogbook.txt in thetemp-directory can be chosen.\n\n\n4.1.2 Open a microdata file\nIn this tour we only deal with how to open a fixed format microdatafile (see sections [3.1.2] to [3.1.4]). If analready constructed table is to be used, then go to the Referencechapter (section [4.3.2]). To start disclosure controlwith \\(\\tau\\)-Argus there are three possible options:\n\nOpen a ascii microdata file from which a table can be constructed,\nOpen an already completed table,\nOpen a SPSS systemfile containing the microdata Opening an already completed table is not part of this tour. Seesection [4.3.2], Also the SPSS-option (see section[4.3.1]) is not part of this tour, Both a microdata file and the metadata file describing this microdatafile are required. The microdata file must be either a fixed formatascii file or a free format file with a specified separator. Byclicking (File|Open Microdata) you can specify both the name of themicrodata file and the name of the file containing the metadata.  \\(\\tau\\)-Argus, expects the microdata and metadata file to be stored inseparate files. The simplest way to use the program is to use theextension .ASC for the (fixed format) datafile and .RDA (RecordDescription for Argus) for the metadata file. If the name of themetadata file is the same as the datafile, except for the extension,and it already exists in the same directory, \\(\\tau\\)-Argus will fill in thename of this metadata file automatically in the second textbox. If nometadata file is specified, the program has the facility to specifythe metadata interactively via the menu option (Specify|Metafile).This is also the place to make changes to the metadata file. Insubsection [3.1.3] we will give a description of themetadata file for \\(\\tau\\)-Argus.\n\n\n\n4.1.3 Specify metafile\nWhen you enter or change the metadata file interactively using \\(\\tau\\)-Argusthe option (Specify|Metafile) will bring you to the following screen:  The key elements of this window are the definitions for each variable.Most variables will be defined as one of the following.\n\nExplanatory Variable: a variable to be used as a categorical &gt; (spanning) variable when defining a table.\nResponse Variable: a numerical variable to be used as a cell item in &gt; a table.\nWeight variable: a variable containing the sampling weighting &gt; scheme. More details on these variables along with the others options can befound in the Reference chapter (subsection [4.4.1]). Other important features of this window are as follows.\nCodelist: \\(\\tau\\)-Argus will always automatically build the codelists for &gt; the explanatory variables from the datafile. However you can &gt; enhance the presentation of the information if you can specify a &gt; codelist file (a list-of-codes of the explanatory variables) as &gt; follows.\n\nAutomatic: The codelist is created from the categories in the &gt; variable.\nCodelist file: The codes can be read in from an external file. &gt; Each category can contain a label. The codelist is only used &gt; for enhancing the presentation but always \\(\\tau\\)-Argus will build a &gt; codelist from the datafile itself.\n\nMissing values: this gives information on the missing values which &gt; are attached to a codelist. Two distinct missing value indicators &gt; can be set (the reason for this is for the purposes of indicating &gt; different reasons for missing values: for example perhaps &gt; non-responses of different forms: maybe one code for the response &gt; ‘don't know’, and another for’refusal’). Missing values &gt; however are not required.\nHierarchical codes: The hierarchy can be derived from\n\nthe digits of the individual codes in the data file or\na specified file containing the hierarchical structure. See &gt; section [5.2] Examples are shown in the metafile information below. The Metafile The metafile describes the variables in the microdata file, both therecord layout and some additional information necessary to perform theSDC-process. Each variable is specified on one main line, followed byone or more option lines. The options ine always start with an optionname enclosed in \"&lt;\" and \"&gt;\".An example is shown here. Theleading spaces shown only serve only to make the file more readable;they have no other meaning. Year 1 2 \" x\" &lt;RECODEABLE&gt; &lt;TOTCODE&gt; \"Total\" IndustryCode 4 5 \"99999\" &lt;RECODEABLE&gt; &lt;TOTCODE&gt; \"Total\" &lt;DISTANCE&gt; 1 3 5 7 9 &lt;HIERARCHICAL&gt; &lt;HIERLEVELS&gt; 3 1 1 Size 9 2 \"99\" &lt;RECODEABLE&gt; &lt;TOTCODE&gt; \"Alles\" Region 12 2 &lt;RECODEABLE&gt; &lt;TOTCODE&gt; \"Total\" &lt;DISTANCE&gt; 2 4 4 4 4 &lt;CODELIST&gt; \"REGION.CDL\" &lt;HIERARCHICAL&gt; &lt;HIERCODELIST&gt; \"D:\\TauJava3\\Datata\\region2.hrc\" &lt;HIERLEADSTRING&gt; \"@\" Wgt 15 4 &lt;WEIGHT&gt; &lt;DECIMALS&gt; 1 Var1 19 9 &lt;NUMERIC&gt; Var2 28 10 &lt;NUMERIC&gt; &lt;DECIMALS&gt; 2 Var3 38 10 &lt;NUMERIC&gt; Var4 48 10 &lt;NUMERIC&gt; Var5 58 10 &lt;NUMERIC&gt; Var6 68 10 &lt;NUMERIC&gt; Var7 78 10 &lt;NUMERIC&gt; Var8 88 10 &lt;NUMERIC&gt; Request 99 1 &lt;NUMERIC&gt; Details of the variables ‘Year’ : For this variable begins on position 1 of each record , is2 characters long and missing values are represented by 99. It is alsorecodeable implicitly stating that it is an explanatory or spanningvariable used to create the tables. ‘IndustryCode’: For this variable begins on position 4 of eachrecord and is 5 characters long. Missing values are represented by99999. As well as being recodeable this variable is hierarchical andthe hierarchy structure is specified. The first 3 characters are inthe top hierarchy level, the 4th character in the second level andthe 5th character in the lowest level. ‘Size’: For this variable begins on position 9 of each record and is2 characters long, and missing values are represented by 99. It isalso recodeable. ‘Region’: For this variable begins on position 12 of each record andis 2 characters long. There is no missing value. There is a codelistfile region.cdl and of a hierarchical codelist file region2.hrc.Examples of these files are shown here. Note: the codelist file is not essential; the content is only usedto enhance some information on the screen. The hierarchicalinformation however plays an essential role as it describes thestructure of the table and the relation between the cells. Note: In both files the code for Total is not specified. \\(\\tau\\)-Argusalways explicitly assumes that there will be a total in each dimensionof the table. Without totals there are no additivity constrains andhence there is no problem of Secondary Cell Suppression. The file region.cdl: 1,Groningen 2,Friesland 3,Drenthe 4,Overijssel 5,Flevoland 6,Gelderland 7,Utrecht 8,Noord-Holland 9,Zuid-Holland 10,Zeeland 11,Noord-Brabant 12,Limburg Nr,North Os,East Ws,West Zd,South The file region.hrc: Nr @ 1 @ 2 @ 3 Os @ 4 @ 5 @ 6 @ 7 Ws @ 8 @ 9 @10 Zd @11 @12 Additional details of these coding files can be found in the sections[5.3] and [5.2].\n\n\n\n\n4.1.4 Specify tables\nWhen the metadata file is ready, the tables to be protected can bespecified. This is achieved via Specify|Tables. A window to specifythe tables is presented. In the example here we have a 2 dimensionaltable (2 explanatory variables; Size x Region) and a response variable(Var2). A safety rule (p%-rule) has been defined.  The key elements of this window are as follows. Explanatory variables On the left is the listbox with the explanatory variables. Click on ‘&gt;&gt;’ moves the selected variables to the next box in whichthe selected explanatory variables can be seen. From the box on theleft hand side, containing explanatory variables, the variables thatwill be used in the row or the column of the table, in a 2-way tablecan be selected. Up to six explanatory variables can be selected tocreate a table, but higher dimensions will restrict the options toprocess a table. Cell items The ‘cell items’ box contains the variables, which were declared as’response variables’ in the metafile. By using the ‘&gt;&gt;’ button theycan be moved to the ‘response variable’ box to be used in the definedtable. Response variable Any variable in the cell items box can be chosen as the responsevariable. Also the implicit variable &lt;freq&gt; for making a frequencytable. Shadow variable The shadow variable is the variable which is used to apply the safetyrule. By default this is the response variable. More details on theShadow variable can be found in section [4.4.4] in theReference chapter. Cost variable This variable describes the cost of each cell. These are the coststhat are minimised when the pattern of secondary suppressed cells arecalculated (see section [2.6] in the Theory chapter forthe further details). By default this is the response variable butother choices are possible. If the response or any other explicitlyspecified variable is used for this purpose, the radio button'variable' should be selected. Then, any variable name can betransferred from the cell items to the cost variable window. Howeverif the name is empty by default the response variable will be chosen.It is also possible to use the frequency of the cells as acost-function. This will suppress cells minimising the number ofcontributors to each cell. A third option is that the number of cellsto be suppressed is minimised, irrespective of the size of theircontributions (unity option – cost variable is set to 1 for eachcell). However this tends to the suppression of totals and marginals.Also a distance function is available. More details will be given inthe Reference Chapter along with an example (section[4.4.4]). Note that choice of the cost variable does nothave any impact when using the hypercube method for secondarysuppression. Weight If the data file has a sample weight, specified in the metadata file,the table can be computed taking this weight into account. In thiscase, the 'apply weights' box should be ticked. More details will begiven in the Reference Chapter along with an example (section[4.4.4]). The safety rule The concept of safety rules is explained in section [2.2]in the chapter on Theory. In this window the left side of the windowallows the type of rule to be selected, this is usually either thedominance rule or p% rule, along with the necessary parameter values.Several rules together can be set for any particular table. Additionally, the minimum number of contributors (threshold rule) canbe chosen. In the window this is referred to as the ‘MinimumFrequency’ Now for the readability of this chapter, brief summaries are providedof the Dominance and p% rules. Dominance rule This is sometimes referred to as the (n,k) rule. The rule states thatif the sum of contributions of the largest n contributors to a cell ismore than k%, the cell is considered disclosive. This is the traditional rule; however we recommend to use the p% ruleas a better alternative. The p%-rule focusses more on the individualcontributors to a cell. p% rule The p% rule says that if the value of a cell x1 can be estimatedto an accuracy of better than p% of the true value then it isdisclosive where x1 is the largest contributor to a cell. This rule can be written as: \\[{{\\sum\\limits_{\\mathit{ii} = 3}^{c}x_{i}} \\geq \\frac{p}{100}}x_{1}\\]for the cell to be non-disclosive where c is the total number ofcontributors to the cell and the intruder is a respondent in the cell. It is important to know that when entering this rule in \\(\\tau\\)-Argus thevalue of n refers to the number of intruders in coalition (who wishto group together to estimate the largest contributor). In general n =1. A typical example would be that the sum of all reporting unitsexcluding the largest two must be at least 10% of the value of thelargest. Therefore, in \\(\\tau\\)-Argus set p=10 and n =1 as there is just oneintruder in the coalition, respondent x2. Note: we only consider the situation for the largest contributor, asthis is the worst case. If the largest is safe all contributors aresafe. The choice of safety rule is specified by the user and the chosenparameters can then be entered. From these parameters symmetric safetyranges are computed automatically prior to the secondary suppressions. For the minimum frequency rule, a safety range is calculated from theuser given range. This is usually a small positive value and isrequired to enable secondary suppression to be carried out. A manual safety range is also required for cells that can be madeunsafe by intervention of the user. Other options such as the ‘Request Rule’ or the ‘Holding Rule’ will belooked at in more detail in the Reference chapter (section[4.4.4]). When everything has been filled in, click '˅' to transport all thespecified parameters describing the table to the ‘listwindow’ on thebottom. As many tables as you want may be specified, only limited bythe memory of the computer. If a table is to be modified press the’^’ button. Creating the Table Pressing the ‘Compute tables’ button will invoke \\(\\tau\\)-Argus to actuallycompute the tables requested and the process to start disclosurecontrol may be invoked. \\(\\tau\\)-Argus will come back showing the (first)table in a spreadsheet like view number of unsafe cells per variable,per dimension, as explained in the next section [3.2].",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>A tour of $\\tau$-Argus</span>"
    ]
  },
  {
    "objectID": "03_A_tour_of_τ-ARGUS.html#the-process-of-disclosure-control",
    "href": "03_A_tour_of_τ-ARGUS.html#the-process-of-disclosure-control",
    "title": "4  A tour of \\(\\tau\\)-Argus",
    "section": "4.2 The process of disclosure control",
    "text": "4.2 The process of disclosure control\nWhen the table(s) have been calculated, the main-window of \\(\\tau\\)-Arguswill show the (first) table.  Safe cells are shown in black, whilst cells failing the safety ruleand/or minimum frequency rule are displayed in red. Only the top2 levels of a hierarchy are shown initially. But at thebottom of the window there are options to open more levels. Alsoclicking on the '+'before a code will open a level of the hierarchy.In the example we have opened the 3rd level of the region variable. The user now has to decide whether to carry out secondary suppressionsimmediately or to perform some recoding first. There are other optionssuch as changing the status of individual cells manually, this will bediscussed further in the Reference chapter (see section[4.2]).\n\n4.2.0.1 Cell information\nCells can be selected in the table by clicking with the cursor on aspecific cell. In that case, information about the selected cell isshown on the right top part of the window. The status of the cell can be one of the following. Some of the termswill be explained later in this section but others are expanded uponin the Reference section [4.2].\n\nSafe: Does not violate the safety rule\nSafe (from manual): manually made safe during this session\nUnsafe: According to the safety rule\nUnsafe (request): Unsafe according to the Request rule.\nUnsafe (frequency): Unsafe according to the minimum frequency rule.\nUnsafe (zero cell) Unsafe because the zero-cells are considered &gt; unsafe.\nUnsafe (from manual): Manually made unsafe during this session.\nProtected: Cannot be selected as a candidate for secondary cell &gt; suppression.\nSecondary: Cell selected for secondary suppression.\nSecondary (from manual): Unsafe due to secondary suppression after &gt; primary suppressions carried out manually.\nZero: Value is zero and cannot be suppressed.\nEmpty: No records contributed to this cell and the cell cannot be &gt; suppressed. ****Change Status**** The second pane (‘Change Status’) on the right will allow the user tochange the cell–status.\nSet to Safe: A cell, which has failed the safety rules, can be &gt; declared safe by the user.\nSet to Unsafe: A cell, which has passed the safety rules, can be &gt; declared to be unsafe by the user.\nSet to Protected: A safe cell is set so that it cannot be selected &gt; for secondary suppression.\nSet Cost: Change the value of the Cost-value for this cell\nUse 'a priori' information (see below). A Priori Info This option is an a priori option to be mainly used for microdatawhich allows the user to feed \\(\\tau\\)-Argus a list of cells where the statusof the standard rules can be overruled i.e. the status of the cells isalready specified. The associated file specifying this information isfree format. The format will be: Code of first spanning variable, Code of second spanning variable,Status of cell (u = unsafe, p = protected (not to be suppressed),s = safe). Also the cost-function can be changed here for a cell. This will makethe cell more likely to become secondary cell suppression, when thevalue is low or less likely when the value is high. Nr, 4, u Zd, 6, p 5, 5, c, 1 A full description of the aproiri file can be found in section[5.6]\n\n\n\n4.2.0.2 Recode\nThe recode button will bring the user to the recoding system. Recodingis a very powerful method of protecting a table. Collapsed cellsusually have more contributors and therefore tend to be much safer. Hierarchical Recoding The first window shows the variables available for recoding In this example, the ‘Region’ variable has been selected for recoding.As ‘Region’ is a hierarchical variable, the codes are shown in ahierarchical tree. The user can either fold or unfold the branches byclicking on the ‘+’ or ‘-’ boxes which results in showing or omittingcodes from the table, or by choosing an overall maximum hierarchicallevel. (See the following windows for details). Pressing the ‘Apply’button followed by ’Close’ will actually apply the selected recodingand show the resulting table. Press the undo-button – it is nowpossible to go back to the original recoding scheme. Below this thereare two windows, one showing the recode window prior to applying therecoding for the hierarchical variable ‘Region’ and the second afterthe folding of the tree.  The next window shows the new hierarchical codes after collapsing allsecond level categories  By clicking 'Apply' and 'Close', we go back to the main windowwhich shows the table after recoding:  Non Hierarchical Recoding In this example the non-hierarchical ‘Size’ variable has been selectedto be recoded. The user can either write the required recodings in theedit box or import them from a previously written file. In the examplethe line 2:2-6 results that categories 2,3,4,5,and 6 will be recodedinto a new category 2. Note that τ‑argus will give a warning that somecodes have not been recoded. They will remain unchanged. The user willknow whether this is harmful or not. Once the recoding has been applied (both forhierarchical and non hierarchical data) the table can again bedisplayed. If there are now no cells, which fail the safety rules, thetable can be saved as a protected table. However, if there are still anumber of unsafe cells, secondary suppression needs to be carried out.This is necessary as the table is not yet safe. If only the cellsfailing the safety rules are suppressed, other cell values could beobtained by differencing.\n\n\n4.2.0.3 Secondary Suppression\nThe Suppress button is an important button. It will activate themodules for computing the necessary secondary suppressions asdescribed above. There are a number of options here.\n\nHypercube\nModular\nNetwork\nOptimal Hypercube This is also known as the ghmiter method. The approach builds on thefact that a suppressed cell in a simple n‑dimensional table withoutsubstructure cannot be disclosed exactly if that cell is contained ina pattern of suppressed, nonzero cells, forming the corner points of ahypercube. Modular This partial method will break the hierarchical table down to severalnon-hierarchical tables, protect them and compose a protected tablefrom the smaller tables. As this method uses the optimisationroutines, an LP-solver is required: this will be either Xpress orcplex, or the free solver The routine used can be specified in theOptions window, this will be discussed later. Optimal This method protects the hierarchical table as a single table withoutbreaking it down into smaller tables. As this method uses theoptimisation routines, an LP-solver is required: this will be eitherXpress or cplex. The routine used can be specified in the Optionswindow; see section [4.7.3]. Network This is a Network Flow approach for large unstructured 2 dimensionaltables or a 2 dimensional table with one hierarchy (the first variablespecified). This method is also based on optimisation techniques, butdoes not require an external solver like Xpress or cplex. As alternatives for cell suppression we can also apply rounding andControlled Tabular Adjustment (CTA) Rounding The controlled rounding procedure can be applied. The user has tospecify the rounding base. Note that this option requires the Xpresssolver or the cplex solver or the free solver. See section[4.2.5] Controlled Tabular Adjustment (CTA) This method will modify a table such that the unsafe cells arereplaced by their upper or lower protection level and the remainingcells are modified such that the table is still additive. See section[4.2.4] Choose the suppression method ****The radio-buttons at the right lower part of the window allowselecting the desired suppression method. Clicking on the Suppressbutton will then start the process of calculating the secondarysuppressions. When this process has finished the protected table willbe displayed and also the user will be informed about the number ofcells selected for secondary suppression and the time taken to performthe operation. The secondary suppressed cells will be shown in blue.**** \n\n\n\n4.2.0.4 Summary Window\nBy clicking on 'Table Summary', the summary window is obtained. Thesummary window gives an overview of the cells according to theirstatus.\n\nFreq: The number of cells in each category\n# rec: The number of observations in each category\nSum Resp: Total cell value in each category\nSumCost: The sum of the cost variable. Here it is equal to the &gt; response variable.  By clicking on 'Close', we return to the table window. The table can now be written to an output file in the required format.Any cells which have been selected for suppression will be replaced by'X', unless another option is chosen.. The safe table can be savedby using 'Output|Save table' menu on the main menu. See section[4.6.1].",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>A tour of $\\tau$-Argus</span>"
    ]
  },
  {
    "objectID": "03_A_tour_of_τ-ARGUS.html#save-the-safe-table",
    "href": "03_A_tour_of_τ-ARGUS.html#save-the-safe-table",
    "title": "4  A tour of \\(\\tau\\)-Argus",
    "section": "4.3 Save the safe table",
    "text": "4.3 Save the safe table\nWhen the table is safe it may be written to the hard disk of thecomputer. The user has six options:\n\nAs a CSV file. This Comma separated file can easily be read into &gt; Excel. Please note that \\(\\tau\\)-Argus uses the ‘,’ as the &gt; field-separator in this CSV-file. This might influence opening the &gt; CSV file in Excel. A solution for this is to change the settings &gt; in the Windows control-panel or use the 'Data|Text to Columns' &gt; option of Excel. This is a typical tabular output maintaining the &gt; appearance of the table in \\(\\tau\\)-Argus.\nA CSV-file for a pivot table. This offers the opportunity to make &gt; use of the facilities of pivot tables in Excel. The status of each &gt; cell can be added here as an option (Safe, Unsafe or Protected for &gt; example). The information for each cell is displayed on a single &gt; line unlike standard csv format.\nA text file in the format code-value, separated by commas. Here, the &gt; cell status is again an option. Also empty cells can be suppressed &gt; from the output file if required. The information for each cell is &gt; displayed on a single line similar to the CSV file for a pivot &gt; table.\nSBS format. This is a special format required for sending data to &gt; Eurostat.\nA file in intermediate format for possible input into another &gt; program. This contains protection levels and external bounds for &gt; each cell. This table could even be read back into \\(\\tau\\)-Argus.\nA file in the JJ-format. This format has been introduced by JJ &gt; Salazar as an intermediate between the normal table and the &gt; structures required in the optimisation routines.  Finally, a report will be generated to a user specified directory.This report will also be displayed on the screen when the table hasbeen written. It will contain details such as table structure, safetyrules (and number of cells failing), secondary suppression method (andnumber of cell failing) and details of any recodes. An example isshown in the Reference section [4.6.2]. As this is anHTML-file it can be viewed easily later or printed.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>A tour of $\\tau$-Argus</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html",
    "title": "5  Description of the Menu Items",
    "section": "",
    "text": "5.1 Menu structure\nThere are five menu headings:\nBelow is a list of the menu items which are shown under each of themenu headings. As some of the items are context specific they will notall be always available. Overview of the menu-items\nThe most important items of the menu can also be reached via thecorresponding icons:\nThese menu items will be explained in detail in the sections followingthe description of the main window. The Main window Starting with the Open Source version (4.0) the main window of \\(\\tau\\)-Argushas been changed completely. In the previous versions an overview waspresented of the number of unsafe combinations for each explanatoryvariable and each code. However this information was hardy used andthe focus of the user is on the table(s) itself. So from now on thetable itself is the central point (the main window) of \\(\\tau\\)-Argus. Assoon as the table has been completed, the table is presented here andthe process of disclosure control is controlled from this main window.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#menu-structure",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#menu-structure",
    "title": "5  Description of the Menu Items",
    "section": "",
    "text": "File\n\n\nUnder File either a microdata file or tabular data file can be opened together with the meta data file describing the data; also a set of tables for the linked table procedure can be opened.\n\n\nIn addition there is the option to open a Batch process file and to Exit.\n\n\n\n\nSpecify\n\n\nSpecify allows the metadata to be entered or edited and the user can specify the tables to be protected along with primary sensitivity rules. When tabular data is the starting point the details about the table can be specified\n\n\n\n\nModify\n\n\nUnder Modify, the table to be protected can be selected and the linked tables procedure can be carried out.\n\n\n\n\nOutput\n\n\nOutput allows the suppressed table to be saved. In addition there is also view report and write a batchfile. Also a tool to generate a‑priory information can be found here.\n\n\n\n\nHelp\n\n\nFinally, there is a Help menu, with contents, news, options and about-box of the program.\n\n\n\n\n\n\n\n\n\n****File ****\n\n\n Specify \n\n\n Modify **\n\n\n Output **\n\n\n****Help ****\n\n\n\n\n****Open Microd ata****\n\n\n ****Metafil e****\n\n\n  ****Select Ta ble****\n\n\n**\n[**Save\nTable****]( #Output|_ Save_Table)\n\n\n Contents **\n\n\n\n\n**\n******Open Table****\n\n\n ****Specify Tables ****\n\n\n****Linked Tables ****\n\n\n**\n******View Re port****\n\n\n****Ne ws****\n\n\n\n\n****Open Table Set ****\n\n\n\n\n Generate apriori ** \n\n\n Options \n\n\n\n\n**\n******Open Batch Process **\n\n\n\n\n****Write Batch File **\n\n\n****Abou t****\n\n\n\n\n ****Ex it****\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{ | png){ | png){ | png){ | B.png | png){ | png){ width | width | width | width | ){wid | width | width =“0.6 | =”0.6 | =“0.6 | =”0.6 | th=“0 | =”0.6 | =“0.6 99cm | 99cm | 99cm | 99cm | .7cm | 99cm | 99cm | 99cm he | &gt; he | &gt; he | &gt; he | &gt; | &gt; he | &gt; he ight= | ight= | ight= | ight= | heigh | ight= | ight=”0.63 | “0.63 |”0.63 | “0.63 | t=”0. | “0.63 |”0.69 9cm} | 9cm} | 9cm} | 9cm} | 7cm} | 9cm} | 9cm} | 9cm}\n\n\n{ width =“0.6\n\n\nhe ight= “0.63\n\n\n\n\nOpen\nMicro\ndata\n\n\nOpen\nTable\n\n\nOpen Tab leset\n\n\nOpen\nBatch Pr ocess\n\n\nSp ecify Met adata\n\n\nSp ecify T ables\n\n\nS elect\nTable\n\n\nL inked T ables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | &gt;      | &gt;      | &gt;      | &gt;      | &gt;      |    |\n{wid | | th=“0. | th=”0. | th=“0. | th=”0. | th=“0. | th=”0. | | 699cm | 699cm | 699cm | 699cm | 699cm | 699cm | | | | &gt; | &gt; | &gt; | &gt; | &gt; | | heigh | heigh | heigh | heigh | heigh | heigh | | t=“0.6 | t=”0.6 | t=“0.6 | t=”0.6 | t=“0.6 | t=”0.6 | | 39cm} | 39cm} | 39cm} | 39cm} | 39cm} | 39cm} | | |\n\n\n\n\nSave\nTable\n\n\nView\nReport\n\n\nGe nerate A priori\n\n\nHelp\n\n\nO ptions\n\n\nAbout",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#viewing-the-table",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#viewing-the-table",
    "title": "5  Description of the Menu Items",
    "section": "5.2 Viewing the table",
    "text": "5.2 Viewing the table\nOn the left side the table itself is shown in a spreadsheet view. Safecells are black, unsafe cells (those failing the primary suppressionrule) are red. In this example there are 12 unsafe cells and byviewing the table the user can now see the actual cells that areunsafe. Any secondary suppressed cells are shown in blue (there are none atthis stage, in this example) and empty cells have a hyphen (-). Thetwo check-boxes on the left-bottom give some control over the layout.\n\nIf the 3-digit separator box at the bottom is checked, the window &gt; will show the cell-values, using the 3 digits separator to give a &gt; more readable format.\nThe Output view shows the table, with all the suppressed cells &gt; replaced by an ‘X’; this is how the safe table will be published, &gt; but without the colours distinguishing between primary and &gt; secondary suppressions.  For some windows, the complete table cannot be seen on the screen. Inthese cases there will be scrollbars at the bottom and the right ofthe table above, which can be used to display the unseen columns. For large tables one does not want to see the whole table on thescreen, which is virtually impossible. Therefore \\(\\tau\\)-Argus will showonly the first two levels of the hierarchal structures. If you want tosee more you can open and close certain parts of the table by clickingon the codes with a ‘+’ or “-”sign. This works similar to the way youopen and close certain parts in the Windows explorer. Via ‘ChangeView’ at the bottom of the screen you can also select the level ofeach hierarchy you want to see both horizontally and vertically. Example of a 3-dimensional table 3-dimensional tables cannot be displayed as a whole. \\(\\tau\\)-Argus can onlyshow a 2-dimensional layer of the table. So for higher dimensionaltable two variables are selected to be show. For the other variablescombo-boxes are shown. These combo-boxes allow for the selection of aspecific layer of the table. Just select the corresponding code andthat layer will be shown. If you want to see another combination of two explanatory variables,go to “Select view” at the bottom of the window. See section[4.2.7].   ****Additional information in the View Table window**** Clicking on a cell in the main body of the table makes informationabout this cell visible in the Cell Information**** pane****.**** Here, the following information can be seen:\n\n\nthe cell-value\nthe cell status\nthe value of cost variable\nthe value of the shadow variables\nthe number of contributors\nthe values of the largest contributors of the shadow variable ****In addition for a primary unsafe cell also the required lower andupper protection levels are shown. If you put your mouse over thisvalue, also the lower and upper protection as a distance to the cellvalue is shown together with the same value as a percentage. **** Information about the Holding level and the Request protectionvariable are also displayed here. The status of the cell can be:\n\n\nSafe: Does not violate the safety rule\nSafe (from manual): manually made safe during this session\nUnsafe: According to the safety rule\nUnsafe (request): Unsafe according to the Request rule.\nUnsafe (frequency): Unsafe according to the minimum frequency rule.\nUnsafe (from manual): manually made unsafe during this session (see &gt; ‘Change Status’ below).\nProtected: Cannot be selected as a candidate for secondary cell &gt; suppression (see ‘Change Status’ below).\nSecondary: Cell selected for secondary suppression.\nSecondary (from manual): Unsafe due to secondary suppression after &gt; primary suppressions carried out manually (see ‘Change Status’ and &gt; ‘Secondary suppressions’ below).\nEmpty: No records contributed to this cell and the cell cannot be &gt; suppressed. Change Status The second pane (‘Change Status’) on the right will allow the user tochange the cell–status.\nSet to Safe: A cell, which was unsafe, e.g. due to the safety rules &gt; is made safe by the user.\nSet to Unsafe: A cell, which has passed the safety rules is made &gt; unsafe by the user. Hence the manual safety margin is applied\nSet to Protected: A safe cell is set so that it cannot be selected &gt; for secondary suppression. Note: use this option with care as &gt; the result might be that no solution can be found. Alternatively &gt; consider to set the cost-variable to a very high value.\nSet Cost: Change the cost function for a cell.\n\n\n5.2.1 A priori info\nThis option allows you to feed \\(\\tau\\)-Argus a list of cells where thestatus of the standard rules can be overruled. E.g. a cell must bekept confidential or not for other reasons that just because of thesensitivity rules. By modifying the cost-function you can influencethe selection of the secondaries. E.g. the cells suppressed last yearcan get a preference for the suppression this year by giving this cella small value for the cost-function. The option ‘Expand trivial levels’ is important. Often in a table withhierarchies, some levels in a hierarchy break down in only one lowerlevel. This implies that there are different cells in a table whichare implicitly the same. Changing the status of one of them might leadto inconsistencies and serious problems. E.g. one if the two is unsafeand the other is protected, the solution is impossible. If you selectthe option ‘Expand trivial levels’, τ‑argus will always modify allcells that are the same if you modify one of them. The format of the file is free format. The separator can be chosen. The format is: Code of first spanning variable, Code of second spanning variable,…,Status of cell (u = unsafe, p = protected (not to be suppressed), s =safe). Also the cost-function can be changed here for a cell. This will makethe cell more likely to become secondary cell suppression, when thevalue is low, or less likely when the value is high. Normally the sensitivity rules will also give the required protectionlevels for unsafe cells. But sometimes, e.g. in the case of ‘manualunsafe cells’ the user might want to specify the required protectionlevel different for a standard percentage. After the keyword ‘pl’, thelower and upper protection levels can be given for a specific cell.Note that the protection levels will always have to be positive, asthey are considered as distances from the cell-value. A full description of the apriori file is given in section[5.6]. Nr, 4, u Zd, 6, p 5, 5, c, 1 Zd, 5, pl, 100, 200 When the apriori file has been applied \\(\\tau\\)-Argus will show an overviewof the changes that have been made to the table. \n\n\n5.2.2 Global recoding\nThe recode button will open the recoding options. Recoding is a verypowerful method of protecting a table. Collapsed cells tend to havemore contributors and therefore tend to be much safer. Recoding a variable always starts with the original codes. It is notpossible to refine a recoding. If required you must start with acomplete new recoding. ****Recoding a non-hierarchical variable**** There is a clear difference in recoding a hierarchical variablecompared to a non-hierarchical variable. In the non-hierarchical case the user can specify a global recodingmanually. Either enter the recoding described below manually or readit from a file. The default extension for this file is .GRC. Detailscan also be found in section [5.4].  There are some standards about how to specify a recode scheme. Always the new code is specified first followed by a colon (`:`).After that the set of old codes to be collapsed into the new code isspecified. All codelists are treated as alphanumeric codes. This means thatcodelists are not restricted to numerical codes only. However, thisalso implies that the codes '01' and ' 1' are considered differentcodes and also 'aaa' and 'AAA' are different. In a recoding schemethe user can specify individual codes separated by a comma (,) orranges of codes separated by a hyphen (-). The range is determined bytreating the codes as strings and using the standard stringcomparison. E.g. `0111`&lt; `11` as the `0` precedes the `1` and`ZZ’&lt; `a` as the uppercase `Z` precedes the lowercase `a`.Special attention should be paid when a range is given without a leftor right value. This means every code less or greater than the givencode. In the first example, the new category 1 will contain all thecodes less than or equal to 49 and code 4 will contain everythinglarger than or equal to 150. Example:a variable with the categories 1,…,182 a possible recode isthen: 1: - 49 2: 50 - 99 3: 100 – 149 4: 150 – for a variable with the categories 01 till 10 a possible recode is: 1: 01 , 02 2: 03 , 04 3: 05 – 07 4: 08 , 09 , 10 An important point is not to forget the colon (:) if it is forgotten,the recode will not work.: 05,06,07 can be shortened to 3: 05-07. Additionally, changing the coding for the missing values can beperformed by entering these codes in the relevant textboxes. Also a new codelist with the labels for the new coding scheme can bespecified. This is entered by means of a codelist file. An example isshown here. (note, there are no colons is this file) 1,Groningen 2,Friesland 3,Drenthe 4,Overijssel 5,Flevoland 6,Gelderland 7,Utrecht 8,Noord-Holland 9,Zuid-Holland 10,Zeeland 11,Noord-Brabant 12,Limburg Nr,North Os,East Ws,West Zd,South Pressing the ‘Apply’ button will actually restructure the table. Thevariable concerned will be displayed in red and additionally an x isshown in front of the variable. If required, recoding can easily beundone by pressing 'undo recoding'. The window will return to theoriginally coding structure. If there is any error in the recodingsuch as certain codes not being found when pressing the ‘Apply’button, an error message will be shown at the bottom of the screen.Alternatively, a warning could be issued; e.g. if the user did notrecode all original codes, \\(\\tau\\)-Argus will inform the user. This may havebeen the intention of the user, therefore the program allows it. Inthe above example a \\(\\tau\\)-Argus message informs the user that 4 codes havenot been changed. At the end of the operation τ‑argus will ask you whether or not amodified recoding scheme must be saved or not.  Once the ’Close’ button has been pressed, \\(\\tau\\)-Argus will present thetable with the recoding applied. Recoding a hierarchical variable   In the hierarchical case the code scheme is typically a tree. Toglobal recode a hierarchical variable requires a user to manipulate atree structure. The standard Windows tree view is used to present ahierarchical code. Certain parts of a tree can be folded and unfoldedwith the standard Windows actions (clicking on ‘+’ and ‘-’). The maximum level box at the top of the screen offers the opportunityto fold and unfold the tree to a certain level. Pressing the ‘Apply’ button will actually restructure the table. Ifrequired, a recoding may always be undone.\n\n\n5.2.3 Secondary suppression\nWhen the table is ready, the most commonly used method to protect atable is secondary cell suppression With suppress the table will be protected by causing additional cellsto be suppressed. This is necessary to make a safe table. Suppression Options There are a number of suppression options, which can be seen on thebottom right hand side of the window.\n\nHypercube\nModular\nOptimal\nNetwork \n\n\n5.2.3.1 Hypercube\nThis is also known as the ghmiter method. The approach builds on thefact that a suppressed cell in a simple n‑dimensional table withoutsubstructure cannot be disclosed exactly if that cell is contained ina pattern of suppressed, nonzero cells, forming the corner points of ahypercube. Selecting the hypercube method will lead to the followingwindow being showed by \\(\\tau\\)-Argus. ghmiter will select secondary suppressions that protect the sensitivecells properly against the risk of inferential disclosure, to someextent, if the user activates the option “Protection againstinferential disclosure required”. If the option is inactivated, onthe other hand, ghmiter will not check secondary suppressions to besufficiently large. For more explanation, and detailed information on the hypercube seesection [2.8]. The lower part of the window above enables the user to affect thesetting of two parameters, “Max sub-codelist size” and “Max sub-tablesize” that GHMITER uses for memory allocation. If the option ‘normal size’ is active, the default values mentionedbelow will be used. Ticking the option ‘large size’ will lead to asetting of 250 and 25000, respectively. “Max sub-codelist size” must exceed the largest maximum sub-codelistsize of all explanatory variables of the table. The maximumsub-codelist size of a (hierarchical) variable is the largest numberof categories on the same (hierarchical) level that contribute to thesame category on the (hierarchical) level just above. The defaultvalue for “Max sub codelist size” is 200. “Max sub-table size” must exceed the number of cells in the largestsubtable, e.g. the product of the maximum sub-codelist sizes takenover all explanatory variables. The default value is 6000. Note that we strongly recommend designing tables so that they fit the’normal’ setting, e.g. better think about restructuring the tablerather than using the ‘large’ option. The better approach (instead ofusing the ‘large’ option) would be to introduce a (more detailed)hierarchical structure into the table, because in this way the tablewill provide more information to the user. The Cancel button will bring you back to the main window, withoutprotecting the table.\n\n\n5.2.3.2 Modular\nThis partial method will break down the hierarchical table intoseveral non-hierarchical tables, protect them and compose a protectedtable from the smaller tables. As this method uses the optimisationroutines, an LP-solver is required: this can be either Xpress or cplexor a free solver. The routine used can be specified in the Optionsbox, this will be discussed later. After starting the modular procedure a little window will be shown.This allows to select three additional rules to be applied. At the endof section [2.10] more information on these three rulescan be found. \n\n\n5.2.3.3 Optimal\nThis method protects the (hierarchical) table as a single tablewithout breaking it down into smaller tables. As this method uses theoptimisation routines, an LP-solver is required: this can be eitherXpress or cplex or a free solver. The routine used can be specified inthe Options box, this will be discussed later. It is the responsibility of the users of \\(\\tau\\)-Argus to apply for alicence for one of these commercial packages themselves. Informationon obtaining one of these licences will be found in a ‘read.me’ filesupplied with the software or on the CASC website. Almost the same window as in Modular is shown to select the 3additional rules; see above.  But a further question is asked. The question is ‘How much time do youallow the system to compute the optimal solution’. When the specified time limit has been reached τ‑argus will ask youwhat to do. This can be twofold, you allow τ‑argus to continue for anew amount of time, or not. The window below allows you to specifythis. Note that τ‑argus will check only at a specific location in a cyclewhether or not the time has elapsed. \n\n\n5.2.3.4 Network\nThis is a Network Flow approach for large unstructured 2 dimensionaltables with only one hierarchy (the first variable specified). Theuser has the option of selecting an optimisation method (pprn andDykstra). Both optimisation methods are available free of anadditional licence. By default the Dykstra solution is advised.  As the network solution is a heuristic to find an approximation of thereal optimal solution, it cannot be expected that always an optimalsolution is found. Nevertheless it is guaranteed that at least a goodfeasible solution is found in a relatively short time. The order inwhich the primaries are provided to the network algorithm couldinfluence the solution found. Therefore three options are available toorder the primaries.\n\n\n5.2.3.5 After the suppression\nAfter selecting one of the options and after clicking the Suppressbutton, \\(\\tau\\)-Argus will run and display a protected table after informingthe user of the number of cells selected for secondary suppression andthe time taken to perform the operation.  The secondary suppressed cells will be shown in blue.  When the user is satisfied with the table it can be saved (see section[4.6.1] for the possible formats). Via the menuOutput|Save table you can specify the format and start the process ofsaving a table.\n\n\n\n5.2.4 Controlled Tabular Adjustment\nA method new in version 4.0 of \\(\\tau\\)-Argus is a method called ControlledTabular Adjustment. Instead of suppressing a set of cells, a selectedset of cells is modified. The aim is to change the sensitive cellssuch that the cells are replaced by a value larger that the upperprotection level or smaller than the lower protection level. i.e. farenough away from the unsafe value.. And a set of safe cells ismodified such that the resulting table is additive again. Of course wetry to minimise the information loss. More information can be found in section [2.13]. We have implemented two variants. A standard version, suitable forgeneral cases, and an expert version for the specialists.  The standard version will run CTA without any further questions. The expert version will show the following window: You can e.g. selectthe solver and the type of CTA. We further refer to the detailed CTAdocumentation. \n\n\n5.2.5 Controlled rounding\nControlled rounding (see Section [2.14] for details onthis method) requires a solver that allows you using the Mixed IntegerModel (MIP). Already in version 3 of τ‑argus we had access to MIP inXpress, thanks to the friendly cooperation of Dash Inc and later FICO.However the restricted version of the cplex licence we used in version3 of \\(\\tau\\)-Argus did not have access to MIP. But from now on you can buy alicence for cplex including MIP. This allows you to use ControlledRounding with a new cplex licence. Also the free solver, soplex, can be used for Controlled Rounding. In general, rounding is more appropriate for frequency tables than formagnitude tables. The next figure shows the simple frequency table obtained from thetest data using the variable Size and Region.  Rounding can be applied also to tables with no unsafe cells. Thechoice of the minimum threshold and whether zeros are safe or not hasan effect on the minimal possible rounding base, as it will beexplained in the Option paragraph. When rounding has been chosen and the round-button has been pressed,the following window will be shown. You can enter a few parameters. Rounding Options  The controlled rounding window allows to set the following parameters:\n\nRounding Base\n&gt; Cell values will be changed to multiples of the base. The minimum &gt; rounding base is equal to the maximum between the minimum &gt; frequency threshold and twice the highest Protection Level set for &gt; an unsafe cell (with the Dominance or p-q rule). See the Section &gt; [2.2] for details on safety rules and section &gt; [2.6] protection levels. If no rule is specified the &gt; minimum base is 1. Rounding can be used to round a table for &gt; “cosmetic” motives.\nNumber of steps allowed\n&gt; This value specifies the maximum number of steps allowed in &gt; order to find a feasible solution when a zero-restricted one does &gt; not exist. The default value is 0, i.e. zero-restricted. Higher &gt; values can be chosen by selecting the value from the drop-down &gt; menu. Note that the higher the number of steps allowed the &gt; lengthier is the search, hence the greater the risk of hitting the &gt; time constraint. At any rate, if a zero-restricted solution &gt; exists, this is the solution provided, whatever the number of &gt; steps allowed.\nMax computing time\n&gt; This value determines the time after which the user is prompted &gt; for a decision about continuing or stopping the search. The &gt; default value is 20 minutes. When the maximum time is hit the user &gt; is prompted to enter a new maximum time or to choose to terminate &gt; the search.\nPartitions\n&gt; This option enables the partitioning of the table into sub-tables &gt; corresponding to each category of the first spanning variable. &gt; This option is recommended for tables with more than approximately &gt; 150,000 cells. Partitioning can only be used in this version when &gt; the first variable is non-hierarchical. The first variable should &gt; be such that the sub-tables have maximum size of about 150,000 &gt; cells and also trying to keep their number low; performance may be &gt; improved by wisely choosing the partitioning variable. See Section &gt; (rounding theory) for further details.\nStopping Rule These options allow to control the quality of the rounded solution.The user can choose:\nFirst Rapid\n&gt; The solution is obtained by rounding conventionally (to the &gt; closest multiple of the base) the internal cells and then the &gt; marginal values are obtained by addition. This solution is likely &gt; to present several values that have a large distance from the &gt; original values. This option should be used with extreme care and, &gt; likely, when everything else fails;\nFirst feasible\n&gt; The solution provided is the first rounded one that has the &gt; specified number of jumps, regardless of its optimality. This &gt; means that there could exist other solutions that have a lower &gt; overall distance from the original table. In many cases, when &gt; optimality is not crucial, this solution is quite close to the &gt; optimal one and it can be found in a shorter time;\nOptimal\n&gt; This option provides the fully optimal controlled rounded &gt; solution.  The rounded table The next figure shows the rounded table with the values rounded tomultiples of 5. Note that the values that were originally zero (henceempty cells denoted with a dash) are still shown as a dash while thevalues that have been rounded down to zero are shown as zeros. \n\n\n\n5.2.6 The audit procedure\nAfter the secondary cell suppression procedure has been carried outall cells should have been properly protected. Cell suppressionguarantees that unsafe cells cannot be estimated to a narrowerinterval that the required protection interval. The realised upper andlower bounds can be computed by solving two linear programmingproblems for each unsafe cell. This can be rather an effort doing itall manually, but the audit procedure will do this. Note that theModel solved by the audit procedure will check only for the requiredprotection levels, but not for the additional singleton protection.See also section [2.15]. The Audit option will only be active after secondary cell suppression.By activating the procedure all the linear programming problems forall unsafe (both primary and secondary) cell will be computed. Whencompleted a message will be showing whether all cells were protectedcorrectly.  If in the unfortunate case the protection was not optimal according tothe audit procedure a list of problems will be shown. Also theproblematic cells will be highlighted. For each unsafe cell the realised lower and upper bounds will beshown. If you put your mouse on the value also the distance to thereal value and the corresponding percentage will be shown \n\n\n5.2.7 The Options at the Bottom of the table\nAt the bottom of this window there are a few additional options. Theseoptions will be described here. Select View By clicking on Select View a dialog box below pops up. The user canspecify which variable is preferred in the row and the column. In thetwo-dimensional case, the table can only be transposed. In the higherdimensional case, the remaining variables will be in the layer. Forthese layer variables a combo-box will appear at the top of the table,where the user can select a code. This will show the correspondingslice of the table.  For a 3 dimensional table, this window is as follows:  Table summary Pressing 'table summary' provides a table summary giving an overviewof the number of cells according to their status. The example shownhere refers to the case after secondary suppression has beenperformed.  The headings in the summary window are as follows: Freq: The number of cells in each category # rec: The number of observations in each category Sum resp: Total cell value in each category Sum cost: The sum of the cost variable. Hor. Levels and Vert. levels A large (hierarchical) table can never be showncompletely on the screen. Therefor \\(\\tau\\)-Argus will start by showing onlythe top-2 levels of the hierarchy. With these options you can specifythat more levels of the table must be shown. Alternatively you can click on the + and – symbols ofthe hierarchical codes in the table to fold and unfold parts of thetable. ****3 dig separator**** This removes or inserts the character separating the thousands for thevalues in the table. Output View This option allows the table to be shown as it will be output, withsuppressed cells (primary and secondary) replaced by a X.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-file-menu",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-file-menu",
    "title": "5  Description of the Menu Items",
    "section": "5.3 The File menu",
    "text": "5.3 The File menu\n\\(\\tau\\)-Argus can read data in two ways. The first option is that \\(\\tau\\)-Arguswill read the data from a microdata file (fixed format, free formatand a SPSS_systemfile), which is explained in section[4.3.1]. From this microdata \\(\\tau\\)-Argus can then build oneor more tables and during this tabulation process compute allnecessary additional information, needed to fully protect a table.This is the most flexible way allowing using all the functionality of\\(\\tau\\)-Argus. The second option is the input and treatment of a pre-tabulated dataand is dealt with in section [4.3.2]. Only one of theseoptions can be used at one time, a pre-tabulated table and tablescomputed from microdata cannot be read in \\(\\tau\\)-Argus simultaneously. A set of pre-tabulated tables can be read into \\(\\tau\\)-Argus and via thelinked tables procedure be protected. See section[4.3.3]. \\(\\tau\\)-Argus can also be used in batch, see section [4.3.4]. Finally the \\(\\tau\\)-Argus can be closed.\n\n5.3.1 File | Open Microdata\nThe File|Open microdata menu allows the user to specify the microdatafile (both fixed and free format or a SPSS-system file) and optionallythe metadata file. Note that a valid licence for SPSS must be available on your PC, atτ‑argus will use the functionality of SPSS to extract the microdatafrom SPSS to a scratch file. This file will then be used to constructthe tables to be protected.  In this dialog box the user can select the microdata-file or the SPSSsystem file and optionally the corresponding metadata file By default the microdata-file has extension .asc and the metafile.rda. .(Note, the user may use any file extension, but is advised touse default names). When the user clicks on he will get the traditionalopen file dialog box.  This box enables searching for the required files. Otherfile-extensions can be chosen when clicking on the files of typelistbox. When the user has selected the microdata file a suggestionfor the metafile (with the same name but with the extension .rda) isgiven but only when this file exists. Note, both files do notnecessarily have to have the same name. If a user selects a data file with another extension,\\(\\tau\\)-Argus willremember this and will suggest this extension in a future use of\\(\\tau\\)-Argus. A full description of the metadata file can be found in section[5.1]. When the data file has been selected and optionally the meta datafile, you can proceed to the menu options Specify|Metafile toedit/modify the meta data file and to Specify|Tables to specify thetables required. See section [4.4] and[4.4.4].\n\n\n5.3.2 File | Open Table\nThis is the option allowing the input of tabular data into \\(\\tau\\)-Argus. Inthis case, an already-constructed table is read in. This is reached byselecting ‘Open Table’ in the file menu of \\(\\tau\\)-Argus.  The name of the file containing the table to be opened (in the formatgiven below) needs to be specified in the first line. Optionally thename of the file containing the metadata is entered in the secondline. Later on you will be offered the option of adapting the metadataor even enter the metadata from scratch. There is a great flexibility with this option. The structure of the file is that each line/record describes one cellin free format. The separator is to be specified in the metadata. Themore detail is given for each cell, the more \\(\\tau\\)-Argus can do for you. In any case for each cell the codes of the explanatory variables andthe cell value need to be given. Optionally the following informationcan be specified:\n\nFrequency\nStatus\nCost variable\nShadow variable\nTop-n variables\nLower and upper protection levels The more details are given for each cell to more flexibility \\(\\tau\\)-Argusoffers in a later stage to apply sensitivity rules etc. If only the cell status is provided, \\(\\tau\\)-Argus can only use that andgive each unsafe cell a fixed protection level of some percentage tobe specified. If also the largest say 2 contributors are provided,\\(\\tau\\)-Argus can apply most of the sensitivity rules, like a p% rule of adominance rule (up to n=2). It is important\n\n\nTo stress that all the cells of a table have to be specified as &gt; \\(\\tau\\)-Argus will not compute any (sub-)totals. In most situations this &gt; is simply impossible.\nA table has to be additive. Theoretically this is trivial, but many &gt; methods to protect a table even require strict additivity. After clicking ‘OK’ you can either proceed by adapting the metadatavia Specify|Metafile or by specifying the table details viaSpecify|Table. This (artificially generated) datafile shows 2 explanatory variables,cell value, cell frequency and the top 3 values in each cell. Withthis information τ‑argus is still able to apply the primarysensitivity rules, like p% rule. An example of a 2 dimensional table T, T, 2940 ,48, 200,200,200 T, A, 745 ,12, 200,100,100 T, B, 810 ,12, 200,100,100 T, C, 685 ,12, 200,100,100 T, D, 700 ,12, 200,100,100 1, T, 795 ,12, 200,100,100 1, A, 350 ,3, 200,100,50 1, B, 190 ,3, 100,50,40 1, C, 150 ,3, 100,40,10 1, D, 115 ,3, 50,40,25 2, T, 670 ,12, 200,100,100 2, A, 115 ,3, 50,40,25 2, B, 340 ,3, 200,100,40 2, C, 115 ,3, 50,40,25 2, D, 120 ,3, 100,10,10 3, T, 785 ,12, 200,100,100 3, A, 190 ,3, 100,50,40 3, B, 115 ,3, 50,40,25 3, C, 325 ,3, 200,100,25 3, D, 165 ,3, 100,40,25 4, T, 690 ,12, 200,100,100 4, A, 100 ,3, 50,25,25 4, B, 175 ,3, 100,50,25 4, C, 115 ,3, 50,40,25 4, D, 310 ,3, 200,100,10 Alternatively if only the status is given to τ‑argus , there is noother option than to use the status and treat all unsafe cells as’manually’ unsafe and apply the manual safety margin. T, T, 2940 ,u T, A, 745 ,s T, B, 810 ,s T, C, 685 ,s T, D, 700 ,s 1, T, 795 ,s 1, A, 350 ,s 1, B, 190 ,s 1, C, 150 ,s 1, D, 115 ,s 2, T, 670 ,s 2, A, 115 ,s 2, B, 340 ,s 2, C, 115 ,u 2, D, 120 ,u 3, T, 785 ,s 3, A, 190 ,s 3, B, 115 ,s 3, C, 325 ,s 3, D, 165 ,s 4, T, 690 ,s 4, A, 100 ,s 4, B, 175 ,s 4, C, 115 ,s 4, D, 310 ,s For tables of dimension 3 or higher, additional columns for theexplanatory variables need to be added as well as additional rows toallow for the increased depth of the table. The next step will be to optionally edit the metadata and then readthe table.\n\n\n\n5.3.3 File | Open Table Set\nWhen the linked tables procedure will be used in combination withtabular input, the option “Open Table Set” must be used to read a setof tables in τ‑argus. The “Open Table” option as described above([4.3.2]) allows for only one single individual table. In this option a set of tables with the corresponding metadata files(*.rda) is specified. Search for the tables in the familiar way and press “Add” to add thetable to the det of linked tables being build. When the set is complete, press the OK-button.  After pressing the OK-button, you will be guided automatically to theSpecify Tables window. This is described in section[4.4.5]. In the linked tables approach it is no longer possible to modify themetadata. As the same rules will be applied to each individual table, you willbe guided to the Specify Tables window only once. The choices will beapplied to each table. This implies that all tables in a linked set should have the sameadditional variables, as described in the previous section[4.3.2]. Please note that it is advisable to read each table individually inτ‑argus before. This to be sure that the specification of the tablesand the metadata is correct, before starting the linked tablesprocedure.\n\n\n5.3.4 File | Open Batch Process\nThis option allows the user to run the commands in batch mode fromopening the microdata and metadata, protecting the table and creatingthe output of the final table(s). If the last line of the batch-file is &lt;GOINTERACTIVE&gt; \\(\\tau\\)-Argus willfirst perform all the actions as specified in the batch-file and thenopen the main menu and giving the control to the user to continue thework in the interactive modus. The lay-out of the batch-file is described in section[5.7]. Note that a log file is maintained of all actions. This is the placeto look if something might go wrong, as a batch-process typically doesnot report to a GUI. By default the log file is “Logbook.txt” in thetemp-directory, but in the batch-file a different file can be chosen.Also from the command-line a log file name can be specified. See alsosection [5.7].\n\n\n5.3.5 File | Exit\nExits the \\(\\tau\\)-Argus-session.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-specify-menu",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-specify-menu",
    "title": "5  Description of the Menu Items",
    "section": "5.4 The Specify menu",
    "text": "5.4 The Specify menu\nThemetadata structure is different for describing microdata and tabulardata. Therefor the structure of the metadata file (RDA-file) isdifferent and also the window to specify and modify the metadata isdifferent. The version presented depends on the type of data that hasbeen selected. We will first describe the situation for microdata(section [4.4.1]) and then for tabular data (section[4.4.3]).\n\n5.4.1 Specify | Metafile [for microdata]\nClicking on ‘Specify|Metafile’ gives the user the opportunity toeither edit a metafile already read in or to enter the metadatainformation directly at the computer from scratch. In this dialog box all attributes of the variables can be specified.This is a good alternative to manually edit the rda-file outside\\(\\tau\\)-Argus. \\(\\tau\\)-Argus does a moderate checking of the rda-file, but noguarantee can be given for a proper functioning of a manually editedrda-file. The rda-file has been explained in detail in section[5.1]. Here, the editing of a rda-file within \\(\\tau\\)-Argus islooked at.  If under File|Open Microdata an rda-file has been specified, thisdialog box shows the contents of this file. If no .rda-file has beenspecified the information can be specified in this dialog box afterpushing the New button. As default \"New\" is substituted as thevariable name, but the user is expected to fill in a correct name.Apart from defining a new variable, an existing one can be modified ordeleted. In the left top field the file type (fixed, free format or SPSS) canbe specified. The following attributes for each variable can be specified or edited:\n\nname of the variables\nits first position in the data file (for fixed format)\nits field-length\nthe number of decimals (for numerical variables).\nFurthermore, the role of variable can be specified or edited (more &gt; detail on these can be seen in section [4.3.1]):\nexplanatory variable: This can be used as a spanning variable in &gt; the row or column of the table\nresponse variable: This can be used as a cell-item\nweight variable: This specifies the sampling-weight of the record &gt; and is based on the sampling design used. The following are special variable types and have not been previouslydescribed. As they are specific to designating safety rules, moredetail is given in section [4.4.4]. Holding Indicator The Holding indicator: sometimes groups of records belong together.E.g. if a set of records describe the contributions of one business tovarious cells. So it could be better to apply the confidentialityprotection at the business level in all cells of the table, especiallythe marginal cells. This variable is the group identifier. \\(\\tau\\)-Argusexpects the records of a group to be together in the input datafile.An example is shown in section [4.4.4]. Request Protection The Request protection option is used if the Request Rule under’Specify tables’ is to be applied. This variable indicates whether ornot a record asked for protection. This is further explained insection [4.4.4]. Additionally the codes specifying whethera respondent asked for asking protection is to be specified; twodifferent codes are possible, corresponding to two different sets ofparameters in the sensitivity rule. This rule is often used in ForeignTrade Statistics. Distance function When finding a pattern of secondary suppressions, most methods try tominimalize some kind of cost function. Often the costs are some valuelinked to each cell.users like to group the secondaries close to the primaries. Theadvantage is that loss of information is grouped in certain parts ofthe table. This can be achieved by used the distance function. The costs for eachcell depend on the number of steps the cell is apart from a primary.For each step the cost can be specified, with a maximum of 5. The distance function can only be applied in combination with themodular suppression method. Total code Optionally a code for the total can be chosen; the default is\"Total\". Additional Specifications Other attributes, which may be edited or specified are missing valueoptions, (optional, not required) codelist files, (optional, notrequired) hierarchies. Details on these options have been given in section[4.3.1]. In summary, for codelist the ‘automatic’ option simply generates thecodes from the data. Specifying a codelist, allows the user to supplyan additional file (usually .cdl) containing the labels attached tothe codes. These labels are used to enhance the information by \\(\\tau\\)-Arguson the screen. In both cases \\(\\tau\\)-Argus will use the codes that it findsin the datafile. Hierarchies can either be derived from the digits in the codes or froma file (usually .hrc) The RDA file Here is an example of a rda file for microdata. This has already beenshown in section [4.3.1] and is shown here forcompleteness. (Note, the dots at the bottom just means that here ashortened version of the file is presented.) Year 1 2 &lt;RECODEABLE&gt; IndustryCode 4 5 99999 &lt;RECODEABLE&gt; &lt;HIERARCHICAL&gt; &lt;HIERLEVELS&gt; 3 1 1 0 0 &lt;DISTANCE&gt; 1 3 5 7 9 Size 9 2 99 &lt;RECODEABLE&gt; &lt;TOTCODE&gt; Alles Region 12 2 &lt;RECODEABLE&gt; &lt;CODELIST&gt; \"REGION.CDL\" &lt;HIERARCHICAL&gt; &lt;HIERCODELIST&gt; \"region2.hrc\" &lt;HIERLEADSTRING&gt; \"@\" &lt;DISTANCE&gt; 2 4 4 4 4 Wgt 15 4 9999 &lt;DECIMALS&gt; 1 &lt;WEIGHT&gt; Var1 19 9 999999999 &lt;NUMERIC&gt; Var2 28 10 9999999999 &lt;NUMERIC&gt; &lt;DECIMALS&gt; 2 ……………… See also section [5.1.1] for a more detailed description τ‑argus can also read free format data files. In that case there areslight differences. You select free format in the combo box in theleft upper corner. And specify the separator used. The parameterstarting position is no longer valid and will not be visible.\n\n\n\n5.4.2 Specify | Metafile [SPSS System files]\nWhen \\(\\tau\\)-Argus works with a SPSS system file the specification of themeta data is twofold. The data is stored in the SPSS system file andalso the metadata. But the metadata available in the SPSS system fileis not enough for τ‑argus. E.g. no information on hierarchies isavailable. So the SPSS metadata is only a starting point. The metadatahas to be extended. The procedure is that τ‑argus will retrieve theSPSS meta data and then expects the user to extend the metadata, usingthe familiar window; see section [4.4.1]. However certainvariables in the metadata cannot be changed any more as we have toguarantee that the extended metadata is still applicable to the SPSSsystem file. E.g. the length of the variables cannot be modified northe number of decimals nor the name. Selecting the variables. If no RDA file but only the SPS-system file has been specified youhave to select the variables of interest running \\(\\tau\\)-Argus. At thebottom of the metadata window you will find a button “SPSS meta”. Thiswill bring you to a window showing all variables available. Make aselection.  If the RDA-file has been specified too this step is not needed. Extending the metadata Secondly the meta data has to be filled in that could not beautomatically retrieved from the system file. SPSS gives only thebasic information like variable names, field length. But northingabout SDC-specific information The working of \\(\\tau\\)-Argus when using a SPSS system file is very similarto the fixed format version, However you will see that certain fieldscannot be changed as they are implied by SPSS. This is to guaranteethat the \\(\\tau\\)-Argus metadata is still applicable to the SPSS system file. Often \\(\\tau\\)-Argus cannot decide whether a variable from SPSS is a spanningvariable or a response variable (eg AGE recoded numerically in SPSS).Also the hierarchical information has to be added. Refer to section[4.4.1]. When the metadata is ready, you can save it in the traditional way.This RDA file can also be used if you want to use this SPS system fileagain. For the rest will behave exactly as if a fixed format microdata inputfile had been used. Only if you start computing tables computing thetables \\(\\tau\\)-Argus will automatically first extract the data from SPSSbefore computing the tables. Apart from a small delay you will notnotice this.  \n\n\n5.4.3 Specify | Metafile [for tabular data]\nWhen a tabular datafile has been selected, the metadata window willhave a different form. Clicking on ‘Specify|Metafile’ gives theopportunity to either edit the metafile already read in or to enterthe metafile information directly at the computer. In section[5.1.4] a detailed description of the metafile fortabular data can be found Below is displayed the ‘Specify metafile’ window for tabular inputdata. Above the list of variables the separator used to separate thevariables in the datafile can be specified. Here, the variables can be specified or edited as required. The options are:\n\n‘Explanatory’ – The spanning variables used to produce the table.\n‘Response’– The variable used to calculate the cell total.\n‘Shadow’– The variable is used as a shadow variable.\n‘Cost’– The variable is used as the cost-variable.\n‘Lower prot .Level’ – The lower protection level\n‘Upper prot. Level’ – The upper protection level\n‘Frequency’ – This indicates the number of observations making up &gt; the cell total. If there is no frequency variable each cell is &gt; assumed to consist of a single observation.\n‘topN variable’ – This shows if this variable is defined as one of &gt; the top N contributors to the cell. The pre-defined value for TopN &gt; is 1. The first variable declared as ‘topN’ will contain the &gt; largest values in each cell, the second variable so declared will &gt; contain the second largest values etc.\n‘Status indicator’ – allows a variable in the left-hand pane to be &gt; declared as a Status Indicator. Typically cells can be declared as &gt; Safe, Unsafe or Protected.  The codelist and the hierarchy are the same as for microdata, so werefer to section [4.4.1]. For explanatory variables the code for the total has to be specified.We strongly recommend strongly that the user also provides the valuesfor the totals himself, but if needed he can ask \\(\\tau\\)-Argus to computethese totals. However it should be noted that when the option tocompute the totals by \\(\\tau\\)-Argus is selected you will lose vitalinformation as the cell status. See also section [4.4.5]In any case, \\(\\tau\\)-Argus needs these totals as they play an important roleis the structure of a table and also are important for the suppressionmodels.\n\n\n\n5.4.4 Specify | Specify Tables [for microdata]\nIn this dialog box the user can specify the tables which requireprotection. In one run of \\(\\tau\\)-Argus more than one table can bespecified, but the tables will be protected separately unless they arelinked (have at least one variable in common). In that case they canbe protected simultaneously if required. In section[4.5.2] the idea of linked tables will be discussed. Also, the user has to specify the parameters for the dominance rule orp% rule and the minimum number of contributors in a cell, etc. Atpresent \\(\\tau\\)-Argus allows up to 6-dimensional tables, but due to thecapacities of the LP-solver used (either Xpress or cplex depending onthe user’s license or the free solver) and the complexity of theoptimisations involved, tables of this complexity can only beprotected by the hypercube method (see section [2.8] inthe Theory chapter). The solutions based on optimisation are limitedto 4 dimensions. Below is a typical window obtained when specifying tables with thep%-rule applied.  In section [4.4] details of variable definitions in themetafile were explained. Now consider how the variables defined in themetafile are used to create a table along with an associated safetyrule. The explanatory (or spanning) variables On the left is the listbox with the explanatory variables. When the user clicks on ‘&gt;’ or ‘&lt;’ the selected variable istransported to the next box. From the left box with explanatoryvariables the user can select the variables that will be used as thespanning variables in the row or the column of the table. Cell items Here, is a list of variables that can be used as response, shadow orcost variables in the disclosure control. By pressing the '&gt;' or'&lt;' they can be transferred to or from the windows on the right. The response variable From the list of cell items the user can select a variable as aresponse variable. This is the variable for which the table to beprotected is calculated. If &lt;freq&gt; is selected a frequency table will be computed. As theneither dominance rule nor the p% rule are meaningful in thissituation, they cannot be used for frequency tables. The shadow variable The shadow variable is the variable that is used to apply the safetyrule. By default this is the response variable, but it is possible toselect another variable. The safety rules are built on the principleof the characteristics of the largest contributors to a cell. If avariable other than the response variable is a better indicator thisvariable can be used here; e.g. the turnover (a proxy for the size ofthe enterprise) can be a suitable variable to apply the safety rule,although the table is constructed using another (response) variable. The cost variable This variable describes the costs of suppressing each individual cell;these costs are used by the internal workings of the secondarysuppression routines. Note that the choice of the cost variable doesnot have any effect when the hypercube method is used for secondarycell suppression. See 2.7.1 for information about how cell costs aredetermined during execution of the hypercube method. With exception ofthe hypercube method, these costs are minimised when the secondarysuppressed cells are determined. By default, this is the responsevariable but two other choices are possible as well as the use of adifferent response variable. Use the frequency of the cells as a cost-function: this will minimisethe number of records contributing to the cells to be suppressed. The number of cells to be suppressed is minimised, irrespective of thesize of their contributions (Unity option). However this might lead tothe suppression of many marginal. A Box-Cox like-transformation can be applied to the individual valuesof the cost variable before minimisation of the cost function. Thesimplified Box Cox function used here is xλ where x is the costvariable and λ is the transformation parameter. For example if λ = 0.5a square root transformation is used and if λ =0 a log transformationwill be applied. Applying this to the unity-choice is rathermeaningless. Weight If the data file has a sample weight, specified in the metadata, thetable can be computed taking these weights into account. If the ‘Apply Weights’ box is ticked, the weights are applied to thecell entries as for the simple application of normal sampling weightsin a survey. In addition these weights are used in applying the safetyrules. When we have a sample the normal idea behind the sensitivityrules that the largest contributions can make a good estimate of eachother is no longer valid. The solution is that we artificially createa complete cell by assuming that each contribution is in fact as manycontributions as its sample weight. And we apply the sensitivity ruleson this cell. An example might help here. For example if there is a cell with two contributions: 100, weight 4 10, weight 7 The cell value = (4 x 100) + (7 x 10) = 470. Without considering theweights there are only two contributors to the cell 100 and 10.However by taking account of the sampling weights the cell values areapproximately 100, 100, 100, 100, 10, 10, 10, 10, 10, 10 and 10. Thelargest two contributors are now 100 and 100. These are regarded asthe largest two values for application of the safety rules. If theweights are not integers, a simple extension is applied. The safety rule The concept of safety rules is explained in section [2.2]On the left side of the window the type of rule that can be selectedalong with the value of the parameters is shown. The possible rulesare:\n\nDominance Rule\nP% Rule\nRequest Rule (this rule is described in detail later in this &gt; section) Additionally, the minimum number of contributors may be chosen (in the'minimum frequency' box). Two dominance rules and two P% rules can be applied to each table.When 2 rules are specified, for a cell to be declared non-disclosive,it must satisfy both rules. Dominance Rule This is sometimes referred to as the (n,k) rule where n is the numberof contributors to a cell contributing more than k% of the total valueof the cell (if the cell is to be defined as unsafe). A popular choicewould be to set n equal to 3 and k equal to 75%. An example of thewindow when specifying a single dominance rule is shown at the startof this section. P% rule The p% rule says that if x1 can be determined to an accuracy ofbetter than P% of the true value then it is disclosive where x1is the largest contributor to a cell. The rule can be written as: \\[{{\\sum\\limits_{i = 3}^{c}x_{i}} \\geq \\frac{p}{100}}x_{1}\\] for thecell to be non-disclosive where c is the total number ofcontributors to the cell and the intruder is a respondent in the cell. It is important to know that when entering this rule in \\(\\tau\\)-Argus thevalue of N refers to the number of intruders in coalition (who wishto group together to estimate the largest contributor). A typical example would be that the sum of all reporting unitsexcluding the largest two must be at least 10% of the value of thelargest. Therefore, in \\(\\tau\\)-Argus set p=10 and n =1 as there is just oneintruder in the coalition, respondent x2. For the dominance rule and the p%-rule the safety ranges required(as a result of applying the rule) can be derived automatically. Thetheory gives formulas for the upper limit only, but for the lowerlimit there is a symmetric range. See e.g. Loeve (2001). (This isreferenced in Section [2.2] (Theory)) As this rule focusses better on the protection of individualcontributors the \\(\\tau\\)-Argus team is convinced that the p%-rule is to bepreferred over the dominance rule. This is also the advice in Europe. Request Rule This is a special option applicable in certain countries relating toe.g. foreign trade statistics. Here, cells are protected only when thelargest contributor represents over (for example) 70% of the total andthat contributor asked for protection. Therefore, a variableindicating the request is required. This option requires an additional variable in the data, with e.g. 0representing no request for that particular business, and 1representing a request where the particular cell value is &gt; x% of thecell total. In fact there is an option for two different thresholds.The min freq is interpreted such that if a cell has at least onerequest and the cell-freq is below the freq-threshold, that cell isconsidered to be unsafe as well. Even if the request is not thelargest one. The idea is that in that case a large non requestingcontributor could reveal the smaller requesting contributor. Note that the 3 rules (dom. rule, p% rule and request rule) do notmake any sense if there are positive and negative contributions to acell. Minimum Frequency If this box is checked, a rule controlling the minimum number of****contributors to a cell will be specified. If the number ofcontributors is less than this value, the cell is considered unsafe. Freq Here, the minimum number of** contributors can be stated. This issometimes known as the threshold rule. It is also possible to specifyno safety rule apart from a minimum frequency value. Frequency-range As described above, for the dominance rule and the P%-rule safetyranges can be derived automatically. However, the theory does notprovide any safety range for the minimum frequency rule. Therefore,the user must provide a safety-range percentage required to allowsecondary suppressions to be carried out. For example, if this valuewas set to equal 30%, it would mean an attacker would not be able tocalculate an interval for this cell to within 30% of the actual valuewhen looking at the safe output. Following this, the secondarysuppressions may be carried out. Manual Safety Range When a cell is set manually unsafe (an option to discussed later),\\(\\tau\\)-Argus cannot calculate safety-ranges itself. Therefore, the usermust supply a safety-percentage for this option for the same reasonsas in the above section, to allow secondary suppressions to beapplied. Zero Unsafe If all contributions to a cell are zero, the cell value will be zerotoo. Applying sensitivity rules here has some problems. Is the sum ofthe largest 3 zeros larger than zero? Nevertheless all contributionsto this cell can be easily disclosed. If cells with totalcontributions of zero are to be regarded as unsafe, this box has to bechecked. A manual safety range will also be required, not as apercentage but as a value at the level of the cell-item. Missing = safe If one of the spanning variables of a cell has a code missing, thiscell is often no longer sensitive. The idea behind this is that therespondent in this cell is not identifiable. When this option ischecked, all cells for which at least one spanning variable has amissing value is considered safe, whatever all the sensitivity rulessay. If this option is not checked the normal procedures as for allother cells are applied. Holding Indicator** **** This section on the Holding Indicator is best read after section[4.2] In some countries, confidentiality protection is applied to businessesat different levels. For example, as in the U.K. a number of’reporting units’ (the lower level of unit) within a cell might belongto an ‘enterprise group’ (higher level). The level at which theconfidentiality rule is applied clearly matters. The holding indicatorallows such groupings to be defined and used in one or more of thesafety rules. This is now illustrated with an example looking at both the p% ruleand the threshold rule at the same time.  Consider the following dataset\n\n\n\n\n\n\n\n\n\n\n\nCell Ref\n\n\nCell Ref\n\n\nCell value\n(reporting unit)\n\n\nEnterprise group\n\n\n\n\n800\n\n\n20\n\n\n599\n\n\n1\n\n\n\n\n800\n\n\n20\n\n\n344\n\n\n1\n\n\n\n\n800\n\n\n20\n\n\n244\n\n\n1\n\n\n\n\n800\n\n\n30\n\n\n355\n\n\n1\n\n\n\n\n800\n\n\n20\n\n\n644\n\n\n2\n\n\n\n\n800\n\n\n30\n\n\n433\n\n\n2\n\n\n\n\n800\n\n\n30\n\n\n323\n\n\n3\n\n\n\n\n800\n\n\n30\n\n\n343\n\n\n3\n\n\n\n\n900\n\n\n20\n\n\n23\n\n\n4\n\n\n\n\n900\n\n\n20\n\n\n43\n\n\n5\n\n\n\n\n900\n\n\n20\n\n\n34\n\n\n5\n\n\n\n\n900\n\n\n20\n\n\n53\n\n\n5\n\n\n\n\n900\n\n\n30\n\n\n700\n\n\n6\n\n\n\n\n900\n\n\n30\n\n\n200\n\n\n6\n\n\n\n\n900\n\n\n30\n\n\n60\n\n\n7\n\n\n\n\n900\n\n\n30\n\n\n40\n\n\n8\n\n\n\n\n900\n\n\n30\n\n\n10\n\n\n9\n\n\n\n\nAssume the following safety rules\n\nThreshold rule: At least 3 enterprise groups (higher level units) in &gt; a cell\nP% rule: The sum of all the reporting units (lower level units) &gt; excluding the largest 2 must be at least 10% of the value of the &gt; largest. There are 4 cells in the table along with the margins. The cell we areinterested in here is Cellref 900,30: 5 reporting units, 4enterprise groups At the reporting unit the values are 700,200,60,40,10 At the enterprise group the values are 900,60,40,10 This rule has been designed so that when the P% rule is applied tothis cell: With reporting units the cell is safe. 10+60+40 = 110. This is greaterthan 10% of the largest value (70) so the cell is safe. With enterprise groups the cell is unsafe. 40+10 = 50. This is lessthan 10% of the largest value (90) so the cell is unsafe. Apply the threshold rule to the enterprise groups (Hold. =3) and P%rule to the reporting units. Once again a safety range percentage is required. The output from the application of this rule is shown below. Two cellsfail the threshold rule with the holding rule applied. The threshold rule has been applied correctly using the holdingindicator as the correct cells are safe (that would be unsafe if theholding indicator was not being used). After all the options have been selected compute the table When all the necessary information has been given, click '˅' totransport all the specified parameters to the ‘listwindow’ on thebottom. As many tables as required can be specified but as the size ofthe memory of a computer is restricted it is not advisable to selecttoo many tables. To modify an already made table press the ‘^’button. Click on ’Compute Tables’ to compute the tables. In case of a SPSSsystem file SPSS will first be called to export the necessarymicrodata automatically to a scratch fixed format ASCII file in theTEMP directory. When the table(s) has been computed, the first table will be shown.\n\n\n\n5.4.5 Specify | Specify tables [for tabular data]\nWhen the ‘Specify|Metafile’ option is followed the ‘Specify|Tablemetadata’ option is also available and the window is displayed here.This will allow the application of safety rules such as the DominanceRule and the P% rule. Section [4.4.4] (specifying tablesfrom microdata) will explain these safety rules and other options indetail.  In the safety rule frame, the type of rule can be selected along withthe value of the parameters. These are the dominance rule and P% rule.Additionally, the minimum number of contributors can be chosen(threshold rule), via ticking and filling-in the minimum frequencybox. If both the status and some information to apply the sensitivityrules have been supplied, both options ‘use given status’ and ‘usesafety rules’ are enabled and the user can chose which one to use. Depending one the amount of detail in the table file some options willbe disabled. If no top1 and top2 information is provided, the p%-rulecannot be used. There is an option to calculate the possibly missing marginals andtotals. This option should be used only as an emergency. It is alwaysbetter to provide τ‑argus with a full, complete table. When \\(\\tau\\)-Argushas to compute these marginals all safety information will be ignored. When all the options have been completed, pressing the ‘OK’ buttonwill invoke \\(\\tau\\)-Argus to actually compute the table requested. Now theprocess of disclosure control can begin.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-modify-menu",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-modify-menu",
    "title": "5  Description of the Menu Items",
    "section": "5.5 The Modify menu",
    "text": "5.5 The Modify menu\n\n5.5.1 Modify | Select Table\nThis dialog box enables the user to select the table they want to see.If the user has specified only one table, this table will be selectedautomatically and this option cannot be accessed. In the examplewindow shown here the first table is a 2 dimensional table (Size xRegion) followed by a 3 dimensional table (Size x Region xIndustryCode). Select the table to be processed and press theOK-button. \n\n\n5.5.2 Modify | Linked Tables\nThis option is available when the tables specified have at least oneexplanatory or spanning variable in common and have the same responsevariable. When the tables are built from micro data, the tables can be specifiedusing the screen below. See also section [4.4.4]. An example is shown.  When the tables are supplied to τ‑argus as tabular input see section[4.3.3] (Open Table set). When supplying a set of readymade tables it should be clear to τ‑argus which explanatory variablesare in fact the same dimension. They should have the same name, evenif the level of detail is different. The next step is to further define the tables. This is similar to theprocedure in Specify Tables (see section [4.4.5]). Thesame choices for the parameters etc. are applied to each table. Itwill be clear that all tables should have the same amount of detail.Otherwise the choices cannot be applied to all tables. So it is notpossible that one table just has a Status indicator and another tablehas the top-2 allowing for applying the p%-rule.  E.g. if a regional variable is an explanatory variable in two tables,but in one table it is at the level of province and in the other atthe level of municipality, they should nevertheless have the samename. If not τ‑argus will not recognise them as a link. The set of linked tables can be protected using the hypercube (seesection [2.8]) and the extended modular approach(see section [2.11]). When protecting a set of linked tables the restriction is that alltables are a sub-set of a theoretical cover table. The cover table isformed by building a table spanned by all explanatory variable fromthe individual tables and using the longest code list for eachdimension. The dimensions are decided by looking for different namesof explanatory variables. As long as the cover table does not have more than 10 dimensions andall the individual tables have not more that 4 dimensions, the linkedtables approach is possible. In the current implementation there is one restriction. For each ofthe spanning variables in the cover table the codelist and thehierarchy should be present in one of the linked tables. For all othertables the codelists and the hierarchy should be a subset of thiscover hierarchy. And of course the set of linked tables should beconsistent. The cells that are logical the same should have exactlythe same value and status. If not the protection of the cover tablewill fail. When tabular data is the starting point, it is the responsibility ofthe user that the tables are consistent. This means that the cellvalues of corresponding cells** **are the same and also the status. Ifnot this is an inconsistent situation. The modular approach is verystrict on complete additivity, as the optimisation routines behindmodular require this. The hypercube is a bit more relaxed.  The set of linked tables can now be protected by pressing ‘Suppressvia modular’ or ‘suppress via hypercube’. \\(\\tau\\)-Argus will then start anautomatic procedure. When the modular approach is selected, the subtables will be loaded inthe cover table. The cover table will then be protected via an extrabatch-run of τ‑argus and in the end the results (suppression pattern)will be transferred to the original subtables. If this procedure mightfail, information could be found in the log-file of τ‑argus. See alsosection [5.8]. Modular will ask for the selection of the singleton rules as usual.  When making the cover table \\(\\tau\\)-Argus will check for consistencies. E.gcells that are in the overlapping part of a table and who are bydefinition equal should have the same value status, protection leveletc. If \\(\\tau\\)-Argus finds some inconsistencies, it will be reported. In the example the value of cell “Total,Nr”(4373664.0) and “12,Total” (1441228.0) are not correct. In twodifferent input files the status is not equal.  When the hypercube is selected, all the input files for the hypercubewill be prepared and the linked table procedure of the hypercube willbe started to protect the set of tables. Also the hypercube does notlike inconsistencies in e.g. the status. These will be reported in thefile PROTO002 in the temp-directory.  If successful the following information will be shown:  When the protection has been completed, the linked tables procedurecan be closed and the individual protected subtables can be inspectedand stored as normal tables.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-output-menu",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-output-menu",
    "title": "5  Description of the Menu Items",
    "section": "5.6 The Output menu",
    "text": "5.6 The Output menu\n\n5.6.1 Output | Save Table\nThere are six options of saving the tables  As a CSV file. This Comma Separated file can easily be read intoExcel. Please note the Excel should interpret the comma as aseparator. If your local settings are different you could use theExcel option ‘Data|Text to Columns’, This a typical tabular outputmaintaining the appearance of the table in \\(\\tau\\)-Argus. CSV-file for a pivot table. This offers the opportunity to makeuse of the facilities of pivot table in Excel. The status of each cellcan be added here as an option (Safe, Unsafe or Protected forexample). The information for each cell is displayed on a single lineunlike standard csv format A text file in the format code-value, this is separated by commas.Here, the cell status is again an option. Also empty cells can besuppressed from the output file if required. The information for eachcell is displayed on a single line similar to the CSV file for a pivottable. There are two possibilities. Either the unsafe cells are shownas an ‘x’, as it should be in the final publication or the exactstatus can be printed in the output file in addition to the cellvalue. Optionally empty cells can be suppressed. When the status is added to the output file \\(\\tau\\)-Argus can use 14different statuses. They can also be found in the report file.\n\n\n\n\n\n\n\n\nNumber\n\n\nStatus\n\n\n\n\n1\n\n\nSafe\n\n\n\n\n2\n\n\nSafe (manual)\n\n\n\n\n3\n\n\nUnsafe\n\n\n\n\n4\n\n\nUnsafe (request)\n\n\n\n\n5\n\n\nUnsafe (Freq)\n\n\n\n\n6\n\n\nUnsafe (Zero cell)\n\n\n\n\n9\n\n\nUnsafe (manual)\n\n\n\n\n10\n\n\nProtected\n\n\n\n\n11\n\n\nSecondary\n\n\n\n\n12\n\n\nSecondary (from man.)\n\n\n\n\n13\n\n\nEmpty (non-struct.)\n\n\n\n\n14\n\n\nEmpty\n\n\n\n\nNote: 7 and 8 are no longer used. But in order to be compatible witholder versions of \\(\\tau\\)-Argus we did not change the numbers. A SBS-format file. This file contains the information required byEurostat for different surveys like the SBS-survey. Each linedescribes one cell in the table. First all the spanning variables,with the levels in the hierarchy, then the cell value, the cellfrequency, the status and the dominance percentage. If the 2 largestcontributors have been computed this percentage is the sum of thelargest two, otherwise the largest one. It will be obvious that thisoutput format is not possible if a table has been used as input, withonly the status or maybe a cell frequency. The cell status can be:\n\n\n\n\n\n\n\n\nA\n\n\nFrequency unsafe\n\n\n\n\nB\n\n\nDominance unsafe with one contributor\n\n\n\n\nC\n\n\nDominance unsafe with two contributors\n\n\n\n\nD\n\n\nSecondary unsafe\n\n\n\n\nV\n\n\nSafe\n\n\n\n\nA file in intermediate format for possible input into anotherprogram. This contains protection levels and external bounds for eachcell. This file could even be read back into \\(\\tau\\)-Argus, using the readtables option The options are:\n\nWrite only the status\nAdd the results of the audit procedure (realised lower and upper &gt; bounds)\nWrite information at the holding level, like the frequency.\nSuppress the empty cells. Of course certain options are only available if appropriate. Finally, a report will be generated to a user specified directory.This report will be shown, when the table has been written. As this isan HTML-file; it can be viewed easily later. A file in JJ-format. This is an intermediate format used inτ‑argus. See section [5.5]. Some options are applicable to several output-versions. These aregrouped together under “General Options”.\n\n\n\n5.6.2 Output | View Report\nViews the report file which has been generated with Output|SaveTable. An example of a part of the output HTML file is shown here. As can be seen the essential information, for somebody other than theuser, about which rules have been applied to make the data safe isdisplayed along with details of any recoding. If required the reportcan be printed as well.  A nicer view of the report will be obtained if you open the report ina web-browser: \n\n\n5.6.3 Output | Generate apriori\nIn many situations it is desirable to coordinate the secondarysuppressions between tables. This can be because of links betweentables. Suppressions in one table should also be suppressions on theother table. But also when protecting monthly tables it could be a good idea tocoordinate suppressions between the different months. A secondarysuppression in month 1 could be an ideal candidate for secondarysuppression in month 2. This could be achieved by changing thesuppression weights for these cells. The apriori option is the way to change the default suppressionweights etc. But this leaves the task of generating the apriori file. Via this option the protected file as generated by \\(\\tau\\)-Argus can beconverted into an apriori file. The table has to be saved in theformat code-value with the ‘Add Status’-option selected. For each status the user can select which action in the apriori filehas to be created. This can be a change of the suppression weight,give a new status, or nothing at all. The user has to specify the protected file (written in the rightformat (saved as code/value plus status) and the apriori file to begenerated. Also the correspondence between the variables must be specified. It isnot always the case that the first spanning variable is also the firstspanning variable in the apriori file. Even the number of variable canbe different. If not all variables of the safe file will be availablein the newly to be protected file, only the score for the total willbe used. This is often the case if the apriori file is generated for alinked tables problem. The separator to be used in the apriori file must be specified aswell; a comma is the default. Pressing the ‘Go’-button will generate the apriori file and the’ready’-button will bring you back to the main menu of \\(\\tau\\)-Argus. \n\n\n5.6.4 Output | Write Batch File\nThe commands used in interactive mode can be saved into a file forfuture use. \\(\\tau\\)-Argus will write a batch file containing the commandsnecessary to achieve the current situation of the \\(\\tau\\)-Argus run so far.For more information on the batch facility see section[4.3.3] For example the following shows the dominance rule (n=3, k= 75)applied to the Size by Region table with Var2 as the responsevariable. The threshold value = 5 with a safety range = 30%. Modularsecondary suppression was applied. The last line indicates that\\(\\tau\\)-Argus will not stop after these commands but become an interactiveprogram. &lt;OPENMICRODATA&gt; \"C:\\Program Files\\TauARGUS\\data\\tau_testW.asc\" &lt;OPENMETADATA&gt; \"C:\\Program Files\\TauARGUS\\data\\tau_testW.rda\" &lt;SPECIFYTABLE&gt; \"Size\"\"Region\"|\"Var2\"|\"\"|\"\" &lt;SAFETYRULE&gt; NK(3,75)|NK(0,0)|FREQ(5,30)| &lt;READMICRODATA&gt; &lt;SUPPRESS&gt; MOD(1) &lt;GOINTERACTIVE&gt;",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-help-menu",
    "href": "04_Reference_Section_-_Description_of_the_Menu_Items.html#the-help-menu",
    "title": "5  Description of the Menu Items",
    "section": "5.7 The Help menu",
    "text": "5.7 The Help menu\n\n5.7.1 Help | Contents\nThis shows the contents page of the help file and from there makes thehelp available. This program has context-sensitive help. By pressingF1, the relevant page of the manual will be shown.\n\n\n5.7.2 Help | News\nInformation on the latest developments is shown. Old friends can seehere which new extensions have been included in this version of\\(\\tau\\)-Argus and information about bugs is shown here as well.\n\n\n5.7.3 Help | Options\nThere are a number of options, which can be changed here. The coloursindicating the status of a cell can be altered. In order to make a hierarchical table more readable, the differentlevels of the hierarchy will be indicated with an increasing greybackground. If you like different colours, you can adapt this. For the modular solution the maximum computing time per subtable canbe specified. This could speed up the computations, but on the otherhand might give a less optimal solution. Also the name of the logfile (see section [5.8]) can bechanged here. By default it is Logbook.txt in the temp-directory. Finally the solver for the optimisation routines must be specified.The options are: cplex or Xpress or a free solver. \\(\\tau\\)-Argus can workwith all three solvers. If the cplex optimisation routine is being used, the location of thelicence file can be specified here. For Xpress the name of the licencefile is prescribed and fixed (XPAUTH.XPR) The Xpress licence file hasto be stored in the \\(\\tau\\)-Argus program directory. \\(\\tau\\)-Argus will store the information of all these options in theregistry and will use it in future runs. It is advisable but notnecessary to open this window at the start of a \\(\\tau\\)-Argus session toensure the correct solver has been chosen. \n\n\n5.7.4 Help | About\nShows the about box.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Description of the Menu Items</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html",
    "href": "05_Further_descriptions.html",
    "title": "6  Further descriptions",
    "section": "",
    "text": "6.1 Meta data files\nThe meta data plays a vital role in \\(\\tau\\)-Argus. The meta data is alwaysspecified and stored in a separate file. As \\(\\tau\\)-Argus can read bothmicro data as input as tabular data, the meta data descriptions willbe different as well. Nevertheless there are many similarities,especially between meta data for fixed and free format micro data. The meta data can always be changed/adapted/entered via the menu itemSpecify|Metadata, see sections [4.4.1],[4.4.2] and [4.4.3]. As no standard meta data system is available which is powerful enoughto manage the complete metadata specification necessary forStatistical Disclosure Control we had to develop something speciallyfor \\(\\tau\\)-Argus. The metadata file (default extension .RDA) has globally the samestructure for all the different file types that can be handled by\\(\\tau\\)-Argus. i.e fixed format/free format microdata, SPSS system files ortabular data. For each variable the name is specified followed by its position inthe file and possible missing values. Following this specificationadditional information can be specified. These specifications alwaysstart with a keyword enclosed by “&lt;”and”&gt;” followed by thespecifications. The metadata is always stored in a plain text file without any tabs orso. If you wish you could enter/modify the metadata file with e.g.Notepad, but not with Word. It is then your own risk that the metadatais syntactically correct. \\(\\tau\\)-Argus will check the meta data file whenit is read, but to a certain limit. The best way is to modify themetadata via the τ‑argus program. Files mentioned in meta-files are assumed to reside in the samedirectory as the meta-file. If not, the complete directory-path shouldbe specified. We will first describe in section [5.1.1]the meta datafile a fixed format micro data file. In the subsequent sections thespecial issues for the other file formats (free format and SPSS) willbe described. In section [5.1.4] the meta data fortabular data files will be dscribed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#meta-data-files",
    "href": "05_Further_descriptions.html#meta-data-files",
    "title": "6  Further descriptions",
    "section": "",
    "text": "6.1.1 Meta data for fixed format micro data\nFor fixed format for each variable the starting position and the fieldlength have to be specified. Also the possible missing values must bespecified as well as the role that a variable can play in theSDC-analysis, like spanning variable (also known as explanatoryvariable), cell item, weight, etc. Additional extra specifications canbe entered. as well, like codelists and hierarchical structures. The metafile describes the variables in the microdata file, both therecord layout and some additional information necessary to perform theSDC-process. Each variable is specified on one main line followed byone or more option lines. The first line gives the name of the variable followed by the startingposition for each record, the width of the field and optionally one ortwo missing value indicators for the record. Missing values are notrequired in \\(\\tau\\)-Argus, but they can play a role when deciding whether ornot a cell is unsafe. For fixed format microdata it is not necessary to specify all thevariables in the file. Only the variables used in τ‑argus have to bespecified. When reading the data τ‑argus will ignore the fields notdescribed. This will improve the speed of processing. The following lines explain specific characteristics of the variable:\n\n\n\n\n\n\n\n\n&lt;RECODEABLE&gt;\n\n\nThis variable can be recoded and used as an explanatory variable in a table\n\n\n\n\n&lt;CODELIST&gt;\n\n\nThis explanatory (or spanning) variable can have an associated codelist which gives labels to the codes for this particular variable. The name of the codelist file follows this &lt;CODELIST&gt; command. The default extension is .CDL. See section [5.3] |\n\n\n\n\n&lt;NUMERIC&gt;\n\n\nThis numeric variable can be used as cell-item.\n\n\n\n\n&lt;DECIMALS&gt;\n\n\nThe number of decimal places specified for this variable\n\n\n\n\n&lt;WEIGHT&gt;\n\n\nThis variable contains the weighting scheme\n\n\n\n\n&lt;HIERARCHICAL&gt;\n\n\nThis variable is hierarchical. The codings are structured so that there is a top code such as Region (N,S,E,W) and within each of these are smaller more specific areas (and possibly sub-areas). Tables may be viewed at different levels of hierarchy.\n\n\n\n\n&lt;HIERLEVELS&gt;\n\n\nThe hierarchy is derived from the digits of the codes itself. The specification is followed by a list of integers denoting the width of each level. The sum of these integers should be the width of the total code. An example is shown beneath the rda file below.\n\n\n\n\n&lt;HIERCODELIST&gt;\n\n\nThe name of the file describing the hierarchical structure. Default extension .HRC. See section [5.2]. |\n\n\n\n\n&lt;HIERLEADSTRING&gt;\n\n\nThe string/character that is used to indicate the depth of a code in the hierarchy. See section [5.2] |\n\n\n\n\n&lt;REQUEST&gt;\n\n\nThis variable contains the status denoting whether or not a respondent asked for protection\n\n\n\n\n&lt;HOLDING&gt;\n\n\nThis variable contains the indication whether a group of records belong to the same group/holding\n\n\n\n\nHere is an example of a rda file for microdata. (Note, the dots at thebottom just means that here a shortened version of the file ispresented.) YEAR 1 2 99 &lt;RECODEABLE&gt; IndustryCode 4 5 99999 &lt;RECODEABLE&gt; &lt;HIERARCHICAL&gt; &lt;HIERLEVELS&gt; 3 1 1 0 0 Size 9 2 99 &lt;RECODEABLE&gt; Region 12 2 99 &lt;RECODEABLE&gt; &lt;CODELIST&gt; Region.cdl &lt;HIERCODELIST&gt; Region2.hrc &lt;HIERLEADSTRING&gt; @ &lt;HIERARCHICAL&gt; Wgt 14 4 &lt;NUMERIC&gt; &lt;DECIMALS&gt; 1 &lt;WEIGHT&gt; Var1 19 9 999999999 &lt;NUMERIC&gt; Var2 28 10 9999999999 &lt;NUMERIC&gt; &lt;DECIMALS&gt; 2 ………… Explanation of the details of the variables ‘Year’: For this explanatory/spanning variable each record begins onposition 1, is 2 characters long and missing values are represented by99. It is also recodeable implicitly stating that it is an explanatoryor spanning variable used to create the tables. ‘IndustryCode’: For this variable each record begins on position 4and is 5 characters long. Missing values are represented by 99999. Aswell as being recodeable this variable is hierarchical and thehierarchy structure is specified. The first 3 characters are in thetop hierarchy level, the 4th character in the second level and the5th character in the lowest level. As ‘Industry’ is a 5 digitvariable there are 5 digits specified for the hierarchical structure.This is the reason for the 2 zeros at the end. ‘Size’: For this variable each record begins on position 9 and is 2characters long, and missing values are represented by 99. It is alsorecodeable. ‘Region’: For this variable each record begins on position 12 and is2 characters long. Missing values are represented by 99. Region has acodelist. See section [5.3]. Region is also ahierarchical variable. As the hierarchical structure cannot be derivedfrom the structure of the coding scheme itself the hierarchicalstructure is described in a special .HRC file. See section[5.2]. The hierarchical structure is described with anindentation structure. Therefore the indentation character(HIERLEADSTRING) has to be specified. Here an @ was chosen. ‘Wgt’: For this variable each record begins on position 14 and is 4characters in length. There is 1 decimal place for these values andthe variable is defined as a weight. A missing value is not allowedhere. Two numeric variables are also shown in the above rda file. Thesenumeric variables (not defined as weights) are those to be used ascell items i.e. response variables used in creating the table. ‘Var1’: This variable begins on position 19 and is 9 characterslong. Missing values are represented by 999999999 and it is numeric.However the missing values for numerical variables will be ignored.The missing values problem should have been solved by e.g. imputationtechniques, but it is outside of the scope of τ‑argus. ‘Var2’: This variable begins on position 28 and is 10 characterslong. Missing values are represented by 9999999999 and it is numeric.This variable has 2 decimal places. The representation in an rda file for the Request rule and HoldingIndicator are shown here for completeness. Request rule Request 99 1 &lt;REQUEST&gt; \"1\" \"2\" Here the request indicator is in column 99 and is one character long.Individuals (or companies) wishing to make use of this rule arerepresented by 1 or 2, Any other value will be interpreted as ‘norequest’. Two different parameters-sets for the request rule can bespecified, the first set will be applied to the companies where thefirst code has been specified, the second set to the companies withthe second code. The request rule is further explained in section[4.4.4]. This rule is used in foreign trade statistics and based on a specialregulation.. Holding Indicator entgroup 101 4 &lt;HOLDING&gt; Here the variable ‘entgroup’ is in column 101 and is four characterslong. This variable is to act as the holding indicator (see section4.3.1 for further explanation). The records of a holding should begrouped together in the input datafile. \\(\\tau\\)-Argus will not searchthrough the whole file to try to find all records for a holding.Before applying the sensitivity rules all records of one holding aregrouped together and treated as one contribution.\n\n\n6.1.2 Meta data for free format micro data\nFor a free-format datafile the RDA is a little bit different. Notablythe first line specifies the separator used. This indicates to \\(\\tau\\)-Argusthat the record description is for a free-format file. And for eachvariable the starting position is no longer specified, as this ismeaningless in a free-format datafile. For the rest there are nodifferences compared to the fixed format version. The example givenabove for a fixed format file will now looks as: &lt;SEPARATOR&gt; \",\" YEAR 2 99 &lt;RECODEABLE&gt; Sbi 5 99999 &lt;RECODEABLE&gt; &lt;HIERARCHICAL&gt; &lt;HIERLEVELS&gt; 3 1 1 0 0 GK 2 99 &lt;RECODEABLE&gt; Regio 2 99 &lt;RECODEABLE&gt; &lt;CODELIST&gt; REGION.CDL &lt;HIERARCHICAL&gt; &lt;HIERCODELIST&gt; region2.hrc &lt;HIERLEADSTRING&gt; @ Wgt 4 9999 &lt;NUMERIC&gt; &lt;DECIMALS&gt; 1 &lt;WEIGHT&gt; Var1 9 999999999 &lt;NUMERIC&gt; Var2 10 9999999999 &lt;NUMERIC&gt; &lt;DECIMALS&gt; 2 .. ..\n\n\n6.1.3 Meta data for SPSS system files\nWhen the microdata is stored in a SPSS System file \\(\\tau\\)-Argus can alsoread this data. However some special rules have to be taken intoaccount. It is assumed that a valid license for SPSS is available onthe computer, because \\(\\tau\\)-Argus will call SPSS to read the data from thesystemfile. Also part of the metadata will be retrieved from SPSS.However not all meta data needed for τ‑argus is available in SPSS, sothe user has to enter the additional metadata himself. See section[4.4.2] In fact \\(\\tau\\)-Argus will call SPSS to export the data and will create afixed format scratch file in the temp-directory. After that τ‑arguswill work similar to working with fixed format ASCII files. The first time you open a SPSS systemfile, no metadata file can andhas to be specified. After opening the SPSS system file in this menu option SPSS will becalled and the meta data (Variable names, field length, missingvalues) available in SPSS will be read. This is a process that takes abit of time and should not be interrupted by pressing any key or so.However no progress information can be showed on the screen. If you reopen an SPSS system file with a meta data file, \\(\\tau\\)-Argus willcheck whether all the variables in the RDA file are really availablein the system file. The RDA file is very similar to the RDA file for a fixed format ASCIIfile. One exception is that the first line will read &lt;SPSS&gt;\n\n\n6.1.4 Meta data for tabular data files\nWhen a tabular datafile has been selected, the metadata file will havea different structure. Clicking on ‘Specify|Metafile’ gives theopportunity to either edit the metafile already read in or to enterthe metafile information directly at the computer. As tabular input is always expected to be free format, first theseparator has to be specified. The variables can have the following role:\n\n\n\n\n\n\n\n\n&lt;RECODEABLE&gt;\n\n\nThe spanning variables used to produce the table. The same as for microdata input files, like hierarchical structures and codelist\n\n\n\n\n&lt;TOTCODE&gt;\n\n\nCode for the total of a codelist\n\n\n\n\n&lt;NUMERIC&gt;\n\n\nResponse Variable – The variable used to calculate the cell total.\n\n\n\n\n&lt;NUMERIC&gt; &lt;SHADOW&gt;\n\n\nShadow variable – The variable is used as a shadow variable.\n\n\n\n\n&lt;NUMERIC&gt; &lt;COST&gt;.\n\n\nCost variable – The variable is used as the cost-variable\n\n\n\n\n&lt;NUMERIC&gt; &lt;LOWERPL&gt;\n\n\nLower protection level – The lower protection level\n\n\n\n\n&lt;NUMERIC&gt; &lt;UPPERPL&gt;\n\n\nUpper protection level – The upper protection level\n\n\n\n\n&lt;FREQUENCY&gt;.\n\n\nFrequency – This indicates the number of observations making up the cell total. If there is no frequency variable each cell is assumed to consist of a single observation\n\n\n\n\n&lt;MAXSCORE&gt;\n\n\n‘topN variable’ – This shows if this variable is defined as one of the top N contributors to the cell. The pre-defined value for TopN is 1. The first variable declared as ‘topN’ will contain the largest values in each cell, the second variable so declared will contain the second largest values etc.\n\n\n\n\n&lt;STATUS&gt;\n\n\n&gt;‘Status Indicator’ – allows a variable in the left-hand pane to be declared as a Status Indicator. Typically cells can be declared as Safe, Unsafe or Protected\n\n\n\n\n&lt;SAFE&gt;\n\n\nThe code used for indicating that a cell is safe\n\n\n\n\n&lt;UNSAFE&gt;\n\n\nThe code used for indicating that a cell is unsafe\n\n\n\n\n&lt;PROTECT&gt;\n\n\nThe code used for indicating that a cell is protected and cannot be used for secondary suppression\n\n\n\n\nFor explanatory variables the code for the total has to be specified.We recommend strongly that the user also provides the values for thetotals himself, but if needed he can ask \\(\\tau\\)-Argus to compute thesetotals. In any case, \\(\\tau\\)-Argus needs these totals as they play animportant role is the structure of a table and also are important forthe suppression models. &lt;SEPARATOR&gt; “,” &lt;SAFE&gt; s &lt;UNSAFE&gt; u &lt;PROTECT&gt; p expvar1 &lt;RECODABLE&gt; &lt;TOTCODE&gt; T expvar2 &lt;RECODABLE&gt; &lt;TOTCODE&gt; T respvar &lt;NUMERIC&gt; freq &lt;FREQUENCY&gt; top1 &lt;MAXSCORE&gt; top2 &lt;MAXSCORE&gt; top3 &lt;MAXSCORE&gt; stat &lt;STATUS&gt;",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#hierarchy-file",
    "href": "05_Further_descriptions.html#hierarchy-file",
    "title": "6  Further descriptions",
    "section": "6.2 Hierarchy file",
    "text": "6.2 Hierarchy file\nHierarchical structures play an important role in \\(\\tau\\)-Argus. Thehierarchical structures can often be derived from the code itself.E.g. the NACE classification is an example of this. In othersituations the structure is not so clear. In that case the wholestructure has to be specified. A hierarchical structure is in fact atree. And a tree can be described easily by indentation. In τ‑argus ahierarchical structure can be described in a simple text-file, usingNotepad or something similar. The default extension is .HRC. One level deeper means a new sub-node in the tree. In the examplegiven below only two levels are shown, but many more levels areallowed. The indentation (an @ in this example) character has to bespecified separately in the RDA file. Note that the total code is never specified in these .HRC files, asτ‑argus always assumes that the total will be computed. Note also that in this situation the codes 1 to 9 in a fixed formatfile have a leading space. This space should be used in the HRC-fileas well. region2.hrc Nr @ 1 @ 2 @ 3 Os @ 4 @ 5 @ 6 @ 7 Ws @ 8 @ 9 @10 Zd @11 @12",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#codelist-file",
    "href": "05_Further_descriptions.html#codelist-file",
    "title": "6  Further descriptions",
    "section": "6.3 Codelist file",
    "text": "6.3 Codelist file\nCodelists can be specified for explanatory variables. The codes arestored in a separate file (default extension .CDL). However the codes are only used to enhance certain windows during theprocessing. \\(\\tau\\)-Argus itself will create the coding schemes for thevariables used during the processing of the datafile. So a code notspecified in the .CDL-file will not cause any problem, only the labelis not available. Also codes specified but not found in the data filewill be ignored. The structure of the file is simple. Each line contains a code and alabel separated by a “,” region.cdl 1,Groningen 2,Friesland 3,Drenthe 4,Overijssel 5,Flevoland 6,Gelderland 7,Utrecht 8,Noord-Holland 9,Zuid-Holland 10,Zeeland 11,Noord-Brabant 12,Limburg Nr,North Os,East Ws,West Zd,South",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#global-recode-file",
    "href": "05_Further_descriptions.html#global-recode-file",
    "title": "6  Further descriptions",
    "section": "6.4 Global recode file",
    "text": "6.4 Global recode file\nGlobal recoding is a powerful method to reduce the number of primaryunsafe cells. It reduces the size of the table, but the advantage isalso that the number of primary unsafe cells is reduced. It is aclassical balance to decide how far you should go when applying globalrecodes, but often the resulting table contains much more information,compared to a table with many, but suppressed cells. For a hierarchical coding scheme \\(\\tau\\)-Argus allows recoding viacollapsing the tree structure of the hierarchy. But for non-structuredcodelists the global recode must be specified manually The structure is always: A new code is assigned to a set of old codes.So all the old codes are collapsed into the new code. A set can beeither a list of individual codes, separated by a comma, or aninterval indicated by a lower code, dash upper code. If the upper orlower code is not specified an open interval is assumed. Examples: For a variable with the categories 1,…,182 a possible recode isthen: 1: - 49 2: 50 - 99 3: 100 – 149 4: 150 – This implies that every code below 49 will be recoded into the newcode 1,all codes between 50 and 99 will be the new code 2 etc. For a variable with the categories 01 till 10 a possible recode is: 1: 01 , 02 2: 03 , 04 3: 05 – 07 4: 08 , 09 , 10 An important point is not to forget the colon (:) if it is forgotten,the recode will not work. Recoding 3: 05,06,07 can be shortened to 3: 05-07. And the two different schemes can be combined as well 1: 02 - 06, 09 is a valid recode as well.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#the-jj-file-format",
    "href": "05_Further_descriptions.html#the-jj-file-format",
    "title": "6  Further descriptions",
    "section": "6.5 The JJ-file format",
    "text": "6.5 The JJ-file format\nThe JJ-file format has been introduced to establish a link between the(hierarchical) tables and the structures required for the optimisationroutines used in Cell-suppression etc. Basically it is a set of table-cells and a set of relations betweenthem. The layout is free-format separated by one or more spaces. The first line is a zero The second line is the number of cells. Then all cells are described. The entries on a line are:\n\nA sequence number\nThe cell value\nThe value of the cost-function\nThe status (s = safe, m = secondary suppression, u = primary unsafe, &gt; z = protected cell or empty)\nThe lower bound\nThe upper bound\nThe lower protection level\nThe upper protection level\nThe sliding protection level (never used in τ‑argus) Then the number of relations Then follow all the relations. Each relation starts with a ‘0’followed by the number of cells in thatrelations and a colon (’:’). Then the sequence-number of the totalcell (followed by a (-1) and all the sub-cells (followed by a (1). Example of a part of a JJ-file: 0 162 0 16847646.84 20000 s 0.00 25271470.26 0.0100 0.0100 0.00 1 4373664.00 5192 s 0.00 25271470.26 0.0100 0.0100 0.00 2 1986129.00 2358 s 0.00 25271470.26 0.0100 0.0100 0.00 3 1809246.00 2148 s 0.00 25271470.26 0.0100 0.0100 0.00 4 578289.00 686 s 0.00 25271470.26 0.0100 0.0100 0.00 5 3703896.00 4397 s 0.00 25271470.26 0.0100 0.0100 0.00 ... ... ... ... 63 0 9 : 0 (-1) 18 (1) 36 (1) 54 (1) 72 (1) 90 (1) 108 (1) 126 (1) 144(1) 0 9 : 1 (-1) 19 (1) 37 (1) 55 (1) 73 (1) 91 (1) 109 (1) 127 (1) 145(1) 0 9 : 2 (-1) 20 (1) 38 (1) 56 (1) 74 (1) 92 (1) 110 (1) 128 (1) 146(1) 0 9 : 3 (-1) 21 (1) 39 (1) 57 (1) 75 (1) 93 (1) 111 (1) 129 (1) 147(1) 0 9 : 4 (-1) 22 (1) 40 (1) 58 (1) 76 (1) 94 (1) 112 (1) 130 (1) 148(1) ... ... ... ...",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#the-apriori-file",
    "href": "05_Further_descriptions.html#the-apriori-file",
    "title": "6  Further descriptions",
    "section": "6.6 The apriori file",
    "text": "6.6 The apriori file\nThe apriori file can be used to modify the characteristics of a cellbefore the secondary cell suppression routines are called. You canmodify the following characteristics:\n\nCell status\nCost-function\nProtection levels The apriori file is a simple text-file that can be created withnotepad and similar programs. The layout of the apriori file issimple. First the codes of the spanning variables are given, separatedby a semicolon (“;”), then the code indicating the change requestedand the depending on the code some additional parameters\n\n\n\n\n\n\n\n\n\n\nCode\n\n\nParameters\n\n\nDescription\n\n\n\n\nS\n\n\n-\n\n\nStatus becomes safe\n\n\n\n\nU\n\n\n-\n\n\nStatus become (manually) unsafe\n\n\n\n\nP\n\n\n-\n\n\nStatus becomes protected\n\n\n\n\nC\n\n\nNew cost value\n\n\nA low cost-value will make it more likely that this cell becomes a candidate for secondary suppressions. A high value will decrease this chance.\n\n\nThis can be used to coordinate suppression patterns between successive years of a certain table\n\n\n\n\nPL\n\n\nNew protection level\n\n\nIf smaller or larger protection is required, this can be indicated here\n\n\n\n\nNote: changing the status of a cell is of course limited. E.g. aprimary unsafe cell cannot become protected, nor can a protected cellbecome unsafe. The cost function must always be positive. It is recommended to restrict the use of setting a cell status toprotected. If you want to prevent that a cell will become a secondarysuppression, give it a high cost value. If this cell is neverthelesssuppressed, there will be a good reason for this. Putting a cell toprotected, might lead to infeasible problems with all the consequencesof that. An example: Nr, 4, u Zd, 6, p 5, 5, c, 1  The apriori file allows you to feed \\(\\tau\\)-Argus a list of cells where thestatus of the standard rules can be overruled. E.g. a cell must bekept confidential or not for other reasons that just because of thesensitivity rules. By modifying the cost-function you can influencethe selection of the secondaries. E.g. the cells suppressed last yearcan get a preference for the suppression this year by giving this cella small value for the cost-function. The option ‘trivial levels’ is important. Often in a table withhierarchies, some levels in a hierarchy break down in only one lowerlevel. This implies that there are different cells in a table whichare implicitly the same. Changing the status of one of them might leadto inconsistencies and serious problems. E.g. one of the two is unsafeand the other is protected, the solution is impossible. If you selectthe option ‘Expand for trivial levels’, τ‑argus will always modify allcells that are the same if you modify one of them.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#the-batch-command-file",
    "href": "05_Further_descriptions.html#the-batch-command-file",
    "title": "6  Further descriptions",
    "section": "6.7 The Batch command file",
    "text": "6.7 The Batch command file\n\\(\\tau\\)-Argus has originally been designed as an interactive program. Acomplete menu-driven design guides you through all steps of theprocess. However a growing need for a batch version emerged afterthat. Since then \\(\\tau\\)-Argus has been extended with a batch version. Thebatch commands are stored in a separate text-file. These commands canbe executed from the command line or via the menu (File|Open Batchprocess. See section [4.3.4]. Alternatively the batch file can be used in a real batch environmentas well. Just invoke \\(\\tau\\)-Argus with the command Taupath\\TAUARGUS param1 param2 param3 param4 where Taupath is the name of the directory where you installed\\(\\tau\\)-Argus, param1 is the name of the file with batch commands; seebelow. Param2 is optional, and is the name of the logfile. If omitted\\(\\tau\\)-Argus will write a logbook in the file logbook.txt in thetemp-directory. See also section [5.8]. Param3 is theparameter specifying the temp-directory. If omitted the defaulttemp-directory will be used. Param4 specifies the batch datadirectory. When using \\(\\tau\\)-Argus interactively a batch file can be generated via themenu Output|Write Batch file. See section [4.6.4]. Butwe advise you to inspect the results of this action before using thisgenerated batch-file as certain details might have been omitted. Layout of the batch-file A file can be written in a text editor and called from this command.Lines starting with “//” will be considered as comment and will beignored. Files mentioned in batch-file are assumed to reside in the samedirectory as the batch-file. If not, the complete directory-pathshould be specified. The possible commands are shown here.\n\n\n\n\n\n\n\n\n\nCommand\n\n\nParameters\n\n\n\n\n\nLOGBOOK\n\n\nName of the logbook file; If not specified the default logbook file will be used.\n\n\n\n\n\nCOMMENT\n\n\nJust a comment for your convenience.\n\n\nThis is equal to starting a line with //\n\n\n\n\n\nOPENMICRODATA\n\n\nData file name with microdata\n\n\n\n\n\nOPENTABLEDATA\n\n\nFile name containing tabular data\n\n\n\n\n\nOPENMETADATA\n\n\nMetadata file name\n\n\n\n\n\nSPECIFYTABLE\n\n\n                                            |\n\"ExpVar1\"\"ExpVar2\"\"ExpVar3\"|\"RespVar\"| | \"ShadowVar\"|\"Costvar\"|Lambda | | For frequency tables you can specify &lt;FREQ&gt; | as Response Variable | | ShadowVar, Costvar and Lambda are optional. If | not specified then ShadowVar, Costvar equal the | Response Variable. For lambda the default is 1. | | If the cost variable is specified either a | numerical variable can be specified or ‘-1’ is | chosen for frequency or ‘-2’ for unity or -3 | for the distance function. | | (See section [4.4.4] for the | explanation for the use of lambda) |\n\n\n\n\nCLEAR\n\n\nClears all and starts a new session.\n\n\n\n\n\nSAFETYRULE\n\n\nThis command is used for primary suppression. | | All these parameters are described in the | section Specify tables, [4.4.4] | | A set of safety rule specifications separated | by a “|” | | Each safety spec starts with \"P\", \"NK\" | \"ZERO\", \"FREQ\", \"REQ\",\"WGT\",\"MIS\" or | \"MAN\" and between brackets the parameters | | P: (p,n) with the n optional. (default = | 1). So (20,3). A p% rule with p=20% and n=3 | | NK: (n,k). A n,k-dominance rule**** | ****with n = the size of the coalition and k | the max. percentage.**** | | ZERO: (ZeroSafetyRange) | | FREQ:(MinFreq, FrequencySafetyRange) | | REQ: (Percent1, Percent2, SafetyMargin) | | All rules can appear several times, | | The first two P, NK are for the individual | level; the following two for the holding level, | | The first FREQ and REQ are at the | individual level the second one is for the | holding. | | ZERO, the zero safety range parameter, can | be given only once for each safety rule. | | MIS: 0 = cells with a missing code are | unsafe if the safety-rules are violated; 1 = | these cells are always safe. (Default = 0.) | | WGT: 0 no weights are used, 1 = apply | weights for computing the tables and in the | safety rules Default = 0 | | MAN: (Manual safety margin). This margin is | used e.g. of a table with only the status is | read, or if via the apriori option a cell is | set to manually unsafe. The default value = 20. |\n\n\n\n\nREADMICRODATA\n\n\nJust reads the microdata file and calculates the table(s), no parameters are required\n\n\n\n\n\nREADTABLE\n\n\nJust reads the tabular inputfile;\n\n\nIf the only parameter = 1 the “compute missing totals” procedure will be used.\n\n\nIf the parameter = 2 then non-additivity will be allowed.\nBut this might cause problems in the further process.\n\n\nDefault: do not compute the missing totals. But an error will be reported if the totals are not correct.\n\n\n\n\n\nAPRIORI\n\n\nThis reads an a-priori file | | The parameters are: Filename, Table number, the | separator, IgnoreError, ExpandTrivial | | The Separator should now be enclosed in | double-quotes | | IgnoreError: if 1 then lines causing an error | will be ignored. | | ExpandTrivial: if 1 then a line will be applied | to all trivial levels in the hierarchy; see | also section [5.6] |\n\n\n\n\nSUPPRESS\n\n\nThis command applies the secondary suppression.\n\n\nThe possible options are:\n\n\nGH: Hypercube\n\n\nMOD: Modular\n\n\nOPT: Optimal\n\n\nNET: Network\n\n\nRND: Controlled rounding\n\n\nCTA: Controlled Tabular Adjustment\n\n\nThe parameters are a few parameters between brackets; The first parameter is always the table number.\n\n\nGH(TabNo, A priori Bounds Percentage, ModelSize, ApplySingleton)\n\n\nModelSize 0 = normal, 1 indicates the large model.\n\n\nApplySingleton: 1 = yes,0 = no; default = yes if the table has frequency-information, no if not.\n\n\nMOD(TabNo, MaxTimePerSubtable, SingleSingle, SingleMultiple, MinFreq)\n\n\nThe last 3 parameters are the singleton options. Each parameter can be 0 or 1. If 1 the option is activated.\n\n\nOPT(TabNo, MaxComputingTime)\n\n\nNET(TabNo)\n\n\nRND(TabNo, RoundingBase, Steps, MaxTime, Partitions, StopRule)\n\n\n- Steps: number of steps allowed, normally 0 (default)\n\n\n- MaxTime: Max computing time (10 = default)\n\n\n- Partitions: 0, 1 (0 = no partitioning (default), 1 = apply the partitioning procedure)\n\n\n- StopRule: 1 = Rapid only, 2 = First feasible solution, 3 = optimal solution (3 =default)\n\n\nCTA(TabNo)\n\n\n\n\n\nSOLVER\n\n\nIndicate whether you will be using cplex, | Xpress or the free solver. Only needed when the | type of solver has not yet been specified on | the computer during a previous interactive | session of \\(\\tau\\)-Argus or if you want to use a different solver. The only parameter allowed is | cplex, xpress or free. | | If you select cplex the name of the cplex | licence file can be specified here. But if you | have already made known this licence file to | \\(\\tau\\)-Argus in a previous session you can omit it here. |\n\n\n\n\nWRITETABLE\n\n\nTabNo, P1, P2,Filename | | P1: Output type: | | 1. CVS-file | | 2. CSV file for pivot table | | 3. Code, value file | | 4. SBS-output format | | 5. Intermediate file | | 6. JJ format file | | P2: Options String. This string contains a | series of 3 letter combinations, the first two | are the option and the third one can only be + | or -, indicating whether or not this option is | selected or not | | The options are: | | AR: write the audit results in an intermediate | file | | AS: write additionally the status; i.e. do not | replace the cell value by an x for unsafe | cells, but give the value and a status | indicator. This is a number between 1 and 14 | see section [4.6.1].  | For CTA and rounding this means that the | original and the modified value are written. | | FL: write variable names on the first line | | HI: write holding level information in an | intermediate file | | HL: write also the hierarchical levels in a SBS | file | | QU: embed codes in quotes | | SE: Suppress empty cells | | SO: write only the status in an intermediate | file | | TR: remove trivial levels in the output file. | | Note: not all options can be used in all | situations. Such options will simply be ignored | and do not cause an error. See the Save Table | option in the interactive mode to see which | options are valid in which situation or section | [4.6.1]. |\n\n\n\n\nVERSIONINFO\n\n\nWrites the version of τ‑argus to a file.\n\n\nThe name of the file is the only parameter of this command. Warning: An existing file will be overwritten.\n\n\n\n\n\nGOINTERACTIVE\n\n\nThis will start the GUI of τ‑argus and allows to continue interactively.\n\n\nHowever if you start the batch file interactively from the menu of τ‑ argus you will always end in the GUI.\n\n\n\n\n\nA typical batch file would look like this: (note that everything aftera // will be treated as comment) Example of a batch file using micro data //datafile &lt;OPENMICRODATA&gt; \"C:\\Program Files\\TauARGUS\\data\\tau_testW.asc\" //metafile &lt;OPENMETADATA&gt; \"C:\\Program Files\\TauARGUS\\data\\tau_testW.rda\" //Exp|resp|shadow|cost -1=unit -2=freq -3=dist &lt;SPECIFYTABLE&gt; \"Size\"\"region\"|\"var2\"|\"var3\"|\"var3\" &lt;SAFETYRULE&gt; P(15,3)|FREQ(3,20)|ZERO(10) &lt;SPECIFYTABLE&gt; \"Size\"\"Year\"|\"var2\"|\"var3\"|\"var3\" &lt;SAFETYRULE&gt; NK(3,70)|FREQ(3,20)|ZERO(20) &lt;READMICRODATA&gt; &lt;SUPPRESS&gt; GH(1,75) &lt;WRITETABLE&gt; (1,1,AS+,\"D:\\TauJava3\\Datata\\x1.csv\") &lt;SUPPRESS&gt; GH(2,75) &lt;WRITETABLE&gt; (2,2,QU+,\"D:\\TauJava3\\Datata\\y11.csv\") &lt;SUPPRESS&gt; MOD(1) &lt;WRITETABLE&gt; (1,3,AS-,\"D:\\TauJava3\\Datata\\x20.txt\") &lt;SUPPRESS&gt; MOD(2) &lt;WRITETABLE&gt; (2,4,SE+,\"D:\\TauJava3\\Datata\\y20.tab\") &lt;SUPPRESS&gt; OPT(1,5) &lt;WRITETABLE&gt; (1,1,AS+,\"D:\\TauJava3\\Datata\\x3.csv\") &lt;GOINTERACTIVE&gt; Eample of a batch file using tabular data &lt;OPENTABLEDATA&gt; \"E:\\TauArgusVB\\Datata\\Nace3Size.tab\" &lt;OPENMETADATA&gt; E:\\TauArgusVB\\Datata\\Nace3Size.RDA\" &lt;SPECIFYTABLE&gt;\"IndustryCode\"\"Size\"|\"Var2\"|\"Var2\"|\"Var2\" //&lt;SAFETYRULE&gt; &lt;READTABLE&gt; &lt;SUPPRESS&gt; MOD(1) &lt;WRITETABLE&gt; (1,3,3,\"E:\\TauArgusVB\\Datata\\Nace3SizeSafe.txt\") &lt;GOINTERACTIVE&gt; In the above example the &lt;SAFETYRULE&gt; command was disabled as inthis example it is assumed that that table already contains the statusof each cell. However if the tabular input contains more information(frequency, TopN) the safety rule command could easily be used here aswell. If more than one table has to be processed, the &lt;CLEAR&gt; commandcould make a new start in a session.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  },
  {
    "objectID": "05_Further_descriptions.html#log-file",
    "href": "05_Further_descriptions.html#log-file",
    "title": "6  Further descriptions",
    "section": "6.8 Log file",
    "text": "6.8 Log file\n\\(\\tau\\)-Argus will write a log-file. This describes among others thecommands used during the runs of \\(\\tau\\)-Argus. If gives a log of the use of\\(\\tau\\)-Argus. Especially for the batch process this file could give someinformation about the progress of the process. Notably is some errorhas occurred, as a batch version cannot inform the user interactively.Below is given a small example. Please note that new information isalways added to this file. So from time to time the user should deletethis file to clean his computer. By default the logfile is the file taulogbook.txt in thetemp-directory. In the options window the name of the logfile can bechanged for the remainder of the current session and future sessions. The Temp directory is normally something like C:\\Users\\YOURNAME\\AppData\\Local\\Temp where yourname is the name of the current user. Of course in specificcircumstances the network administrator might have a chosen differentlocation. When running in batch-mode it is possible to change the name of thelog-file with a batch command in the batch-file or as the secondparameter on the commandline. See section [4.3.4] 23-Oct-2014 16:17:27 : Start of TauArgus run 23-Oct-2014 16:17:27 : Version 4.0.1 (beta) build 3 23-Oct-2014 16:17:27 :-------------------------- 23-Oct-2014 16:17:35 : Start of batch procedure; file:D:\\TauJava3\\Datata\\manual.arb 23-Oct-2014 16:17:35 : &lt;OPENMICRODATA&gt; \"C:\\ProgramFiles\\TauARGUS\\data\\tau_testW.asc\" 23-Oct-2014 16:17:35 : &lt;OPENMETADATA&gt; \"C:\\ProgramFiles\\TauARGUS\\data\\tau_testW.rda\" 23-Oct-2014 16:17:35 : &lt;SPECIFYTABLE&gt;\"Size\"\"region\"|\"var2\"|\"var3\"|\"var3\" 23-Oct-2014 16:17:35 : &lt;SAFETYRULE&gt; P(20,3)|FREQ(3,30)|ZERO(20) 23-Oct-2014 16:17:35 : &lt;SPECIFYTABLE&gt;\"Size\"\"Year\"|\"var2\"|\"var3\"|\"var3\" 23-Oct-2014 16:17:35 : &lt;SAFETYRULE&gt; NK(3,70)|FREQ(3,30)|ZERO(20) 23-Oct-2014 16:17:35 : &lt;READMICRODATA&gt; 23-Oct-2014 16:17:35 : Start explore file: C:\\ProgramFiles\\TauARGUS\\data\\tau_testW.asc 23-Oct-2014 16:17:35 : Start computing tables 23-Oct-2014 16:17:36 : Table: Size x Region | Var2 has been specified 23-Oct-2014 16:17:36 : Table: Size x Year | Var2 has been specified 23-Oct-2014 16:17:36 : Tables have been computed 23-Oct-2014 16:17:36 : Micro data file read; processing time 1 seconds 23-Oct-2014 16:17:36 : Tables from microdata have been read 23-Oct-2014 16:17:36 : &lt;SUPPRESS&gt; GH(1,75) 23-Oct-2014 16:17:36 : Start of the hypercube protection for tableSize x Region | Var2 23-Oct-2014 16:17:37 : End of hypercube protection. Time used 1seconds Number of suppressions: 10 23-Oct-2014 16:17:37 : The hypercube procedure has been applied 10 cells have been suppressed 23-Oct-2014 16:17:37 : &lt;WRITETABLE&gt;(1,1,AS+,\"D:\\TauJava3\\Datata\\x1.csv\") 23-Oct-2014 16:17:37 : Table: Size x Region | Var2 has been written Output file name: D:\\TauJava3\\Datata\\x1.csv 23-Oct-2014 16:17:37 : &lt;SUPPRESS&gt; GH(2,75) 23-Oct-2014 16:17:37 : Start of the hypercube protection for tableSize x Year | Var2 23-Oct-2014 16:17:39 : End of hypercube protection. Time used 1seconds Number of suppressions: 5 23-Oct-2014 16:17:39 : The hypercube procedure has been applied 5 cells have been suppressed 23-Oct-2014 16:17:39 : &lt;WRITETABLE&gt;(2,2,QU+,\"D:\\TauJava3\\Datata\\y11.csv\") 23-Oct-2014 16:17:39 : Table: Size x Year | Var2 has been written Output file name: D:\\TauJava3\\Datata\\y11.csv 23-Oct-2014 16:17:39 : &lt;SUPPRESS&gt; MOD(1) 23-Oct-2014 16:17:39 : Start of the modular protection for table Sizex Region | Var2 23-Oct-2014 16:17:39 : End of modular protection. Time used 0 seconds Number of suppressions: 10 23-Oct-2014 16:17:40 : &lt;WRITETABLE&gt;(1,3,AS-,\"D:\\TauJava3\\Datata\\x20.txt\") 23-Oct-2014 16:17:40 : Table: Size x Region | Var2 has been written Output file name: D:\\TauJava3\\Datata\\x20.txt 23-Oct-2014 16:17:40 : &lt;SUPPRESS&gt; MOD(2) 23-Oct-2014 16:17:40 : Start of the modular protection for table Sizex Year | Var2 23-Oct-2014 16:17:40 : End of modular protection. Time used 0 seconds Number of suppressions: 5 23-Oct-2014 16:17:41 : &lt;WRITETABLE&gt;(2,4,SE+,\"D:\\TauJava3\\Datata\\y20.tab\") 23-Oct-2014 16:17:41 : Table: Size x Year | Var2 has been written Output file name: D:\\TauJava3\\Datata\\y20.tab 23-Oct-2014 16:17:41 : &lt;SUPPRESS&gt; OPT(1,5) 23-Oct-2014 16:17:41 : End of Optimal protection. Time used 0 seconds Number of suppressions: 12 23-Oct-2014 16:17:42 : &lt;WRITETABLE&gt;(1,1,AS+,\"D:\\TauJava3\\Datata\\x3.csv\") 23-Oct-2014 16:17:42 : Table: Size x Region | Var2 has been written Output file name: D:\\TauJava3\\Datata\\x3.csv 23-Oct-2014 16:17:42 : &lt;GOINTERACTIVE&gt;",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Further descriptions</span>"
    ]
  }
]